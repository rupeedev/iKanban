{
  "version": 3,
  "sources": ["../../@tanstack/pacer-lite/src/lite-debouncer.ts", "../../@tanstack/pacer-lite/src/lite-queuer.ts", "../../@tanstack/pacer-lite/src/lite-throttler.ts"],
  "sourcesContent": ["import type { AnyFunction } from '@tanstack/pacer/types'\n\n/**\n * Options for configuring a lite debounced function\n */\nexport interface LiteDebouncerOptions<TFn extends AnyFunction = AnyFunction> {\n  /**\n   * Whether to execute on the leading edge of the timeout.\n   * The first call will execute immediately and the rest will wait the delay.\n   * Defaults to false.\n   */\n  leading?: boolean\n  /**\n   * Callback function that is called after the function is executed\n   */\n  onExecute?: (args: Parameters<TFn>, debouncer: LiteDebouncer<TFn>) => void\n  /**\n   * Whether to execute on the trailing edge of the timeout.\n   * Defaults to true.\n   */\n  trailing?: boolean\n  /**\n   * Delay in milliseconds before executing the function.\n   */\n  wait: number\n}\n\n/**\n * A lightweight class that creates a debounced function.\n *\n * This is an alternative to the Debouncer in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core Debouncer,\n * this version does not use TanStack Store for state management, has no devtools integration,\n * and provides only essential debouncing functionality.\n *\n * Debouncing ensures that a function is only executed after a certain amount of time has passed\n * since its last invocation. This is useful for handling frequent events like window resizing,\n * scroll events, or input changes where you want to limit the rate of execution.\n *\n * The debounced function can be configured to execute either at the start of the delay period\n * (leading edge) or at the end (trailing edge, default). Each new call during the wait period\n * will reset the timer.\n *\n * Features:\n * - Zero dependencies - no external libraries required\n * - Minimal API surface - only essential methods (maybeExecute, flush, cancel)\n * - Simple state management - uses basic private properties instead of reactive stores\n * - Callback support for monitoring execution events\n * - Lightweight - designed for use in npm packages where bundle size matters\n *\n * @example\n * ```ts\n * const debouncer = new LiteDebouncer((value: string) => {\n *   saveToDatabase(value);\n * }, {\n *   wait: 500,\n *   onExecute: (args, debouncer) => {\n *     console.log('Saved value:', args[0]);\n *   }\n * });\n *\n * // Will only save after 500ms of no new input\n * inputElement.addEventListener('input', () => {\n *   debouncer.maybeExecute(inputElement.value);\n * });\n * ```\n */\nexport class LiteDebouncer<TFn extends AnyFunction> {\n  private timeoutId: NodeJS.Timeout | undefined\n  private lastArgs: Parameters<TFn> | undefined\n  private canLeadingExecute = true\n\n  constructor(\n    public fn: TFn,\n    public options: LiteDebouncerOptions<TFn>,\n  ) {\n    // Default trailing to true if neither leading nor trailing is specified\n    if (\n      this.options.leading === undefined &&\n      this.options.trailing === undefined\n    ) {\n      this.options.trailing = true\n    }\n  }\n\n  /**\n   * Attempts to execute the debounced function.\n   * If leading is true and this is the first call, executes immediately.\n   * Otherwise, queues the execution for after the wait time.\n   * Each new call resets the timer.\n   */\n  maybeExecute = (...args: Parameters<TFn>): void => {\n    let didLeadingExecute = false\n\n    if (this.options.leading && this.canLeadingExecute) {\n      this.canLeadingExecute = false\n      didLeadingExecute = true\n      this.fn(...args)\n      this.options.onExecute?.(args, this)\n    }\n\n    this.lastArgs = args\n\n    if (this.timeoutId) {\n      clearTimeout(this.timeoutId)\n    }\n\n    this.timeoutId = setTimeout(() => {\n      this.canLeadingExecute = true\n      if (this.options.trailing && !didLeadingExecute && this.lastArgs) {\n        this.fn(...this.lastArgs)\n        this.options.onExecute?.(this.lastArgs, this)\n      }\n      this.lastArgs = undefined\n    }, this.options.wait)\n  }\n\n  /**\n   * Processes the current pending execution immediately.\n   * If there's a pending execution, it will be executed right away\n   * and the timeout will be cleared.\n   */\n  flush = (): void => {\n    if (this.timeoutId && this.lastArgs) {\n      clearTimeout(this.timeoutId)\n      this.timeoutId = undefined\n      const args = this.lastArgs\n      this.fn(...args)\n      this.options.onExecute?.(args, this)\n      this.lastArgs = undefined\n      this.canLeadingExecute = true\n    }\n  }\n\n  /**\n   * Cancels any pending execution.\n   * Clears the timeout and resets the internal state.\n   */\n  cancel = (): void => {\n    if (this.timeoutId) {\n      clearTimeout(this.timeoutId)\n      this.timeoutId = undefined\n    }\n    this.lastArgs = undefined\n    this.canLeadingExecute = true\n  }\n}\n\n/**\n * Creates a lightweight debounced function that delays invoking the provided function until after a specified wait time.\n * Multiple calls during the wait period will cancel previous pending invocations and reset the timer.\n *\n * This is an alternative to the debounce function in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core version,\n * this function creates a debouncer with no external dependencies, devtools integration, or reactive state.\n *\n * If leading option is true, the function will execute immediately on the first call, then wait the delay\n * before allowing another execution.\n *\n * @example\n * ```ts\n * const debouncedSave = liteDebounce(() => {\n *   saveChanges();\n * }, { wait: 1000 });\n *\n * // Called repeatedly but executes at most once per second\n * inputElement.addEventListener('input', debouncedSave);\n * ```\n *\n * @example\n * ```ts\n * // Leading edge execution - fires immediately then waits\n * const debouncedSearch = liteDebounce((query: string) => {\n *   performSearch(query);\n * }, { wait: 300, leading: true });\n * ```\n */\nexport function liteDebounce<TFn extends AnyFunction>(\n  fn: TFn,\n  options: LiteDebouncerOptions<TFn>,\n): (...args: Parameters<TFn>) => void {\n  const debouncer = new LiteDebouncer(fn, options)\n  return debouncer.maybeExecute\n}\n", "/**\n * Position type for addItem and getNextItem operations.\n *\n * - 'front': Operate on the front of the queue (FIFO for getNextItem)\n * - 'back': Operate on the back of the queue (LIFO for getNextItem)\n */\nexport type QueuePosition = 'front' | 'back'\n\n/**\n * Options for configuring a lite queuer instance\n */\nexport interface LiteQueuerOptions<TValue> {\n  /**\n   * Default position to add items to the queue\n   * @default 'back'\n   */\n  addItemsTo?: QueuePosition\n  /**\n   * Default position to get items from during processing\n   * @default 'front'\n   */\n  getItemsFrom?: QueuePosition\n  /**\n   * Function to determine priority of items in the queue\n   * Higher priority items will be processed first\n   * Return undefined for items that should use positional ordering\n   */\n  getPriority?: (item: TValue) => number | undefined\n  /**\n   * Initial items to populate the queue with\n   */\n  initialItems?: Array<TValue>\n  /**\n   * Maximum number of items allowed in the queue\n   */\n  maxSize?: number\n  /**\n   * Whether the queuer should start processing items immediately\n   * @default true\n   */\n  started?: boolean\n  /**\n   * Time in milliseconds to wait between processing items\n   * @default 0\n   */\n  wait?: number\n}\n\n/**\n * A lightweight class that creates a queue for processing items.\n *\n * This is an alternative to the Queuer in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core Queuer,\n * this version does not use TanStack Store for state management, has no devtools integration,\n * no callbacks, and provides only essential queueing functionality.\n *\n * The queuer supports FIFO (First In First Out), LIFO (Last In First Out), and priority-based\n * processing of items. Items can be processed automatically with configurable wait times\n * between executions, or processed manually using the execute methods.\n *\n * Features included:\n * - Automatic or manual processing of items\n * - FIFO, LIFO, and priority-based ordering\n * - Queue size limits with item rejection\n * - Configurable wait times between processing\n * - Batch processing capabilities\n * - Start/stop processing control\n * - Callback support for monitoring execution, rejection, and state change events\n *\n * Features NOT included (compared to core Queuer):\n * - No TanStack Store state management\n * - No devtools integration\n * - No item expiration functionality (no onExpire callback)\n * - No dynamic options updates (setOptions)\n * - No detailed state tracking (execution counts, etc.)\n *\n * Queue behavior:\n * - Default: FIFO (add to back, process from front)\n * - LIFO: Configure addItemsTo: 'back', getItemsFrom: 'back'\n * - Priority: Provide getPriority function; higher values processed first\n *\n * @example\n * ```ts\n * // Basic FIFO queue\n * const queue = new LiteQueuer((item: string) => {\n *   console.log('Processing:', item);\n * }, { wait: 100 });\n *\n * queue.addItem('task1');\n * queue.addItem('task2');\n * // Processes: task1, then task2 after 100ms delay\n * ```\n *\n * @example\n * ```ts\n * // Priority queue\n * const priorityQueue = new LiteQueuer((item: Task) => {\n *   processTask(item);\n * }, {\n *   getPriority: task => task.priority,\n *   wait: 500\n * });\n *\n * priorityQueue.addItem({ name: 'low', priority: 1 });\n * priorityQueue.addItem({ name: 'high', priority: 10 });\n * // Processes high priority task first\n * ```\n */\nexport class LiteQueuer<TValue> {\n  private items: Array<TValue> = []\n  private timeoutId: NodeJS.Timeout | null = null\n  private isRunning = true\n  private pendingTick = false\n\n  constructor(\n    public fn: (item: TValue) => void,\n    public options: LiteQueuerOptions<TValue> = {},\n  ) {\n    // Set defaults\n    this.options.addItemsTo = this.options.addItemsTo ?? 'back'\n    this.options.getItemsFrom = this.options.getItemsFrom ?? 'front'\n    this.options.maxSize = this.options.maxSize ?? Infinity\n    this.options.started = this.options.started ?? true\n    this.options.wait = this.options.wait ?? 0\n\n    this.isRunning = this.options.started\n\n    // Add initial items if provided\n    if (this.options.initialItems) {\n      for (const item of this.options.initialItems) {\n        this.addItem(item, this.options.addItemsTo, false)\n      }\n    }\n\n    // Start processing if enabled and has items\n    if (this.isRunning && this.items.length > 0) {\n      this.tick()\n    }\n  }\n\n  /**\n   * Number of items currently in the queue\n   */\n  get size(): number {\n    return this.items.length\n  }\n\n  /**\n   * Whether the queue is empty\n   */\n  get isEmpty(): boolean {\n    return this.items.length === 0\n  }\n\n  /**\n   * Whether the queue is currently running (auto-processing items)\n   */\n  get isQueueRunning(): boolean {\n    return this.isRunning\n  }\n\n  /**\n   * Adds an item to the queue. If the queue is full, the item is rejected.\n   * Items can be inserted at the front or back, and priority ordering is applied if getPriority is configured.\n   *\n   * Returns true if the item was added, false if the queue is full.\n   *\n   * @example\n   * ```ts\n   * queue.addItem('task1');           // Add to default position (back)\n   * queue.addItem('task2', 'front');  // Add to front\n   * ```\n   */\n  addItem = (\n    item: TValue,\n    position: QueuePosition = this.options.addItemsTo!,\n    startProcessing: boolean = true,\n  ): boolean => {\n    // Check size limit\n    if (this.items.length >= this.options.maxSize!) {\n      return false\n    }\n\n    // Handle priority insertion\n    if (this.options.getPriority) {\n      const priority = this.options.getPriority(item)\n      if (priority !== undefined) {\n        // Find insertion point for priority\n        const insertIndex = this.items.findIndex((existing) => {\n          const existingPriority = this.options.getPriority!(existing)\n          // Treat undefined priority as negative infinity for comparison\n          const effectivePriority = existingPriority ?? -Infinity\n          return effectivePriority < priority\n        })\n\n        if (insertIndex === -1) {\n          this.items.push(item)\n        } else {\n          this.items.splice(insertIndex, 0, item)\n        }\n      } else {\n        // No priority, use position\n        this.insertAtPosition(item, position)\n      }\n    } else {\n      // No priority function, use position\n      this.insertAtPosition(item, position)\n    }\n\n    // Start processing if running and not already processing\n    if (startProcessing && this.isRunning && !this.pendingTick) {\n      this.tick()\n    }\n\n    return true\n  }\n\n  private insertAtPosition = (item: TValue, position: QueuePosition): void => {\n    if (position === 'front') {\n      this.items.unshift(item)\n    } else {\n      this.items.push(item)\n    }\n  }\n\n  /**\n   * Removes and returns the next item from the queue without executing the function.\n   * Use for manual queue management. Normally, use execute() to process items.\n   *\n   * @example\n   * ```ts\n   * const nextItem = queue.getNextItem();        // Get from default position (front)\n   * const lastItem = queue.getNextItem('back');  // Get from back (LIFO)\n   * ```\n   */\n  getNextItem = (\n    position: QueuePosition = this.options.getItemsFrom!,\n  ): TValue | undefined => {\n    if (this.items.length === 0) {\n      return undefined\n    }\n\n    let item: TValue | undefined\n\n    // When priority function is provided, always get from front (highest priority)\n    if (this.options.getPriority || position === 'front') {\n      item = this.items.shift()\n    } else {\n      item = this.items.pop()\n    }\n\n    return item\n  }\n\n  /**\n   * Removes and returns the next item from the queue and processes it using the provided function.\n   *\n   * @example\n   * ```ts\n   * queue.execute();        // Execute from default position\n   * queue.execute('back');  // Execute from back (LIFO)\n   * ```\n   */\n  execute = (position?: QueuePosition): TValue | undefined => {\n    const item = this.getNextItem(position)\n    if (item !== undefined) {\n      this.fn(item)\n    }\n    return item\n  }\n\n  /**\n   * Internal method that processes items in the queue with wait intervals\n   */\n  private tick = (): void => {\n    if (!this.isRunning) {\n      this.pendingTick = false\n      return\n    }\n\n    this.pendingTick = true\n\n    // Process items while queue is not empty\n    while (this.items.length > 0) {\n      const item = this.execute(this.options.getItemsFrom)\n      if (item === undefined) {\n        break\n      }\n\n      const wait = this.options.wait!\n      if (wait > 0) {\n        // Schedule next processing after wait time\n        this.timeoutId = setTimeout(() => this.tick(), wait)\n        return\n      }\n\n      // No wait time, continue processing immediately\n    }\n\n    this.pendingTick = false\n  }\n\n  /**\n   * Starts processing items in the queue. If already running, does nothing.\n   */\n  start = (): void => {\n    this.isRunning = true\n    if (!this.pendingTick && this.items.length > 0) {\n      this.tick()\n    }\n  }\n\n  /**\n   * Stops processing items in the queue. Does not clear the queue.\n   */\n  stop = (): void => {\n    this.clearTimeout()\n    this.isRunning = false\n    this.pendingTick = false\n  }\n\n  /**\n   * Clears any pending timeout\n   */\n  private clearTimeout = (): void => {\n    if (this.timeoutId) {\n      clearTimeout(this.timeoutId)\n      this.timeoutId = null\n    }\n  }\n\n  /**\n   * Returns the next item in the queue without removing it.\n   *\n   * @example\n   * ```ts\n   * const next = queue.peekNextItem();        // Peek at front\n   * const last = queue.peekNextItem('back');  // Peek at back\n   * ```\n   */\n  peekNextItem = (position: QueuePosition = 'front'): TValue | undefined => {\n    if (this.items.length === 0) {\n      return undefined\n    }\n\n    if (this.options.getPriority || position === 'front') {\n      return this.items[0]\n    } else {\n      return this.items[this.items.length - 1]\n    }\n  }\n\n  /**\n   * Returns a copy of all items in the queue.\n   */\n  peekAllItems = (): Array<TValue> => {\n    return [...this.items]\n  }\n\n  /**\n   * Processes a specified number of items immediately with no wait time.\n   * If no numberOfItems is provided, all items will be processed.\n   *\n   * @example\n   * ```ts\n   * queue.flush();     // Process all items immediately\n   * queue.flush(3);    // Process next 3 items immediately\n   * ```\n   */\n  flush = (\n    numberOfItems: number = this.items.length,\n    position?: QueuePosition,\n  ): void => {\n    this.clearTimeout() // Clear any pending timeout\n    for (let i = 0; i < numberOfItems && this.items.length > 0; i++) {\n      this.execute(position)\n    }\n    // Restart normal processing if still running and has items\n    if (this.isRunning && this.items.length > 0 && !this.pendingTick) {\n      this.tick()\n    }\n  }\n\n  /**\n   * Processes all items in the queue as a batch using the provided function.\n   * The queue is cleared after processing.\n   *\n   * @example\n   * ```ts\n   * queue.flushAsBatch((items) => {\n   *   console.log('Processing batch:', items);\n   *   // Process all items together\n   * });\n   * ```\n   */\n  flushAsBatch = (batchFunction: (items: Array<TValue>) => void): void => {\n    const items = this.peekAllItems()\n    this.clear()\n    batchFunction(items)\n  }\n\n  /**\n   * Removes all items from the queue. Does not affect items being processed.\n   */\n  clear = (): void => {\n    this.items = []\n  }\n}\n\n/**\n * Creates a lightweight queue that processes items using the provided function.\n *\n * This is an alternative to the queue function in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core version,\n * this function creates a queuer with no external dependencies, devtools integration, or reactive state.\n *\n * @example\n * ```ts\n * const processItem = liteQueue((item: string) => {\n *   console.log('Processing:', item);\n * }, { wait: 1000 });\n *\n * processItem('task1');\n * processItem('task2');\n * // Processes each item with 1 second delay between them\n * ```\n */\nexport function liteQueue<TValue>(\n  fn: (item: TValue) => void,\n  options: LiteQueuerOptions<TValue> = {},\n): (item: TValue) => boolean {\n  const queuer = new LiteQueuer(fn, options)\n  return (item: TValue) => queuer.addItem(item)\n}\n", "import type { AnyFunction } from '@tanstack/pacer/types'\n\n/**\n * Options for configuring a lite throttled function\n */\nexport interface LiteThrottlerOptions<TFn extends AnyFunction = AnyFunction> {\n  /**\n   * Whether to execute on the leading edge of the timeout.\n   * Defaults to true.\n   */\n  leading?: boolean\n  /**\n   * Callback function that is called after the function is executed\n   */\n  onExecute?: (args: Parameters<TFn>, throttler: LiteThrottler<TFn>) => void\n  /**\n   * Whether to execute on the trailing edge of the timeout.\n   * Defaults to true.\n   */\n  trailing?: boolean\n  /**\n   * Time window in milliseconds during which the function can only be executed once.\n   */\n  wait: number\n}\n\n/**\n * A lightweight class that creates a throttled function.\n *\n * This is an alternative to the Throttler in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core Throttler,\n * this version does not use TanStack Store for state management, has no devtools integration,\n * and provides only essential throttling functionality.\n *\n * Throttling ensures a function is called at most once within a specified time window.\n * Unlike debouncing which waits for a pause in calls, throttling guarantees consistent\n * execution timing regardless of call frequency.\n *\n * Supports both leading and trailing edge execution:\n * - Leading: Execute immediately on first call (default: true)\n * - Trailing: Execute after wait period if called during throttle (default: true)\n *\n * Features:\n * - Zero dependencies - no external libraries required\n * - Minimal API surface - only essential methods (maybeExecute, flush, cancel)\n * - Simple state management - uses basic private properties instead of reactive stores\n * - Callback support for monitoring execution events\n * - Lightweight - designed for use in npm packages where bundle size matters\n *\n * @example\n * ```ts\n * const throttler = new LiteThrottler((scrollY: number) => {\n *   updateScrollPosition(scrollY);\n * }, {\n *   wait: 100,\n *   onExecute: (args, throttler) => {\n *     console.log('Updated scroll position:', args[0]);\n *   }\n * });\n *\n * // Will execute at most once per 100ms\n * window.addEventListener('scroll', () => {\n *   throttler.maybeExecute(window.scrollY);\n * });\n * ```\n */\nexport class LiteThrottler<TFn extends AnyFunction> {\n  private timeoutId: NodeJS.Timeout | undefined\n  private lastArgs: Parameters<TFn> | undefined\n  private lastExecutionTime = 0\n  private isPending = false\n\n  constructor(\n    public fn: TFn,\n    public options: LiteThrottlerOptions<TFn>,\n  ) {\n    // Default both leading and trailing to true if neither is specified\n    if (\n      this.options.leading === undefined &&\n      this.options.trailing === undefined\n    ) {\n      this.options.leading = true\n      this.options.trailing = true\n    }\n  }\n\n  /**\n   * Attempts to execute the throttled function. The execution behavior depends on the throttler options:\n   *\n   * - If enough time has passed since the last execution (>= wait period):\n   *   - With leading=true: Executes immediately\n   *   - With leading=false: Waits for the next trailing execution\n   *\n   * - If within the wait period:\n   *   - With trailing=true: Schedules execution for end of wait period\n   *   - With trailing=false: Drops the execution\n   */\n  maybeExecute = (...args: Parameters<TFn>): void => {\n    const now = Date.now()\n    const timeSinceLastExecution = now - this.lastExecutionTime\n\n    // Handle leading execution\n    if (this.options.leading && timeSinceLastExecution >= this.options.wait) {\n      this.execute(...args)\n    } else {\n      // Store the most recent arguments for potential trailing execution\n      this.lastArgs = args\n\n      // Set up trailing execution if not already scheduled\n      if (!this.timeoutId && this.options.trailing) {\n        const timeoutDuration = this.options.wait - timeSinceLastExecution\n        this.isPending = true\n        this.timeoutId = setTimeout(() => {\n          if (this.lastArgs !== undefined) {\n            this.execute(...this.lastArgs)\n          }\n        }, timeoutDuration)\n      }\n    }\n  }\n\n  private execute = (...args: Parameters<TFn>): void => {\n    this.fn(...args)\n    this.options.onExecute?.(args, this)\n    this.lastExecutionTime = Date.now()\n    this.clearTimeout()\n    this.lastArgs = undefined\n    this.isPending = false\n  }\n\n  /**\n   * Processes the current pending execution immediately.\n   * If there's a pending execution, it will be executed right away\n   * and the timeout will be cleared.\n   */\n  flush = (): void => {\n    if (this.isPending && this.lastArgs) {\n      this.execute(...this.lastArgs)\n    }\n  }\n\n  /**\n   * Cancels any pending trailing execution and clears internal state.\n   * If a trailing execution is scheduled, this will prevent that execution from occurring.\n   */\n  cancel = (): void => {\n    this.clearTimeout()\n    this.lastArgs = undefined\n    this.isPending = false\n  }\n\n  private clearTimeout = (): void => {\n    if (this.timeoutId) {\n      clearTimeout(this.timeoutId)\n      this.timeoutId = undefined\n    }\n  }\n}\n\n/**\n * Creates a lightweight throttled function that limits how often the provided function can execute.\n *\n * This is an alternative to the throttle function in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core version,\n * this function creates a throttler with no external dependencies, devtools integration, or reactive state.\n *\n * Throttling ensures a function executes at most once within a specified time window,\n * regardless of how many times it is called. This is useful for rate-limiting\n * expensive operations or UI updates.\n *\n * @example\n * ```ts\n * const throttledScroll = liteThrottle(() => {\n *   updateScrollIndicator();\n * }, { wait: 100 });\n *\n * // Will execute at most once per 100ms\n * window.addEventListener('scroll', throttledScroll);\n * ```\n *\n * @example\n * ```ts\n * // Leading edge execution - fires immediately then throttles\n * const throttledResize = liteThrottle(() => {\n *   recalculateLayout();\n * }, { wait: 250, leading: true, trailing: false });\n * ```\n */\nexport function liteThrottle<TFn extends AnyFunction>(\n  fn: TFn,\n  options: LiteThrottlerOptions<TFn>,\n): (...args: Parameters<TFn>) => void {\n  const throttler = new LiteThrottler(fn, options)\n  return throttler.maybeExecute\n}\n"],
  "mappings": ";AAmEA,IAAa,gBAAb,MAAoD;EAKlD,YACSA,IACAC,SACP;AAFO,SAAA,KAAA;AACA,SAAA,UAAA;6BAJmB;4BAqBT,SAAgC;;AACjD,UAAI,oBAAoB;AAExB,UAAI,KAAK,QAAQ,WAAW,KAAK,mBAAmB;AAClD,aAAK,oBAAoB;AACzB,4BAAoB;AACpB,aAAK,GAAG,GAAG,IAAA;AACX,yBAAK,SAAQ,cAAb,4BAAyB,MAAM;;AAGjC,WAAK,WAAW;AAEhB,UAAI,KAAK,UACP,cAAa,KAAK,SAAA;AAGpB,WAAK,YAAY,WAAA,MAAiB;;AAChC,aAAK,oBAAoB;AACzB,YAAI,KAAK,QAAQ,YAAY,CAAC,qBAAqB,KAAK,UAAU;AAChE,eAAK,GAAG,GAAG,KAAK,QAAA;AAChB,WAAAC,OAAAC,MAAA,KAAK,SAAQ,cAAb,gBAAAD,IAAA,KAAAC,KAAyB,KAAK,UAAU;;AAE1C,aAAK,WAAW;SACf,KAAK,QAAQ,IAAA;;uBAQE;;AAClB,UAAI,KAAK,aAAa,KAAK,UAAU;AACnC,qBAAa,KAAK,SAAA;AAClB,aAAK,YAAY;AACjB,cAAM,OAAO,KAAK;AAClB,aAAK,GAAG,GAAG,IAAA;AACX,yBAAK,SAAQ,cAAb,4BAAyB,MAAM;AAC/B,aAAK,WAAW;AAChB,aAAK,oBAAoB;;;wBAQR;AACnB,UAAI,KAAK,WAAW;AAClB,qBAAa,KAAK,SAAA;AAClB,aAAK,YAAY;;AAEnB,WAAK,WAAW;AAChB,WAAK,oBAAoB;;AAnEzB,QACE,KAAK,QAAQ,YAAY,UACzB,KAAK,QAAQ,aAAa,OAE1B,MAAK,QAAQ,WAAW;;;;;AC2B9B,IAAa,aAAb,MAAgC;EAM9B,YACSC,IACAC,UAAqC,CAAA,GAC5C;AAFO,SAAA,KAAA;AACA,SAAA,UAAA;iBAPsB,CAAA;qBACY;qBACvB;uBACE;oBA8DpB,MACA,WAA0B,KAAK,QAAQ,YACvC,kBAA2B,SACf;AAEZ,UAAI,KAAK,MAAM,UAAU,KAAK,QAAQ,QACpC,QAAO;AAIT,UAAI,KAAK,QAAQ,aAAa;AAC5B,cAAM,WAAW,KAAK,QAAQ,YAAY,IAAA;AAC1C,YAAI,aAAa,QAAW;AAE1B,gBAAM,cAAc,KAAK,MAAM,UAAA,CAAW,aAAa;AAIrD,oBAHyB,KAAK,QAAQ,YAAa,QAAA,KAEL,aACnB;;AAG7B,cAAI,gBAAgB,GAClB,MAAK,MAAM,KAAK,IAAA;cAEhB,MAAK,MAAM,OAAO,aAAa,GAAG,IAAA;cAIpC,MAAK,iBAAiB,MAAM,QAAA;YAI9B,MAAK,iBAAiB,MAAM,QAAA;AAI9B,UAAI,mBAAmB,KAAK,aAAa,CAAC,KAAK,YAC7C,MAAK,KAAA;AAGP,aAAO;;6BAGmB,MAAc,aAAkC;AAC1E,UAAI,aAAa,QACf,MAAK,MAAM,QAAQ,IAAA;UAEnB,MAAK,MAAM,KAAK,IAAA;;wBAelB,WAA0B,KAAK,QAAQ,iBAChB;AACvB,UAAI,KAAK,MAAM,WAAW,EACxB;AAGF,UAAIC;AAGJ,UAAI,KAAK,QAAQ,eAAe,aAAa,QAC3C,QAAO,KAAK,MAAM,MAAA;UAElB,QAAO,KAAK,MAAM,IAAA;AAGpB,aAAO;;oBAYE,aAAiD;AAC1D,YAAM,OAAO,KAAK,YAAY,QAAA;AAC9B,UAAI,SAAS,OACX,MAAK,GAAG,IAAA;AAEV,aAAO;;sBAMkB;AACzB,UAAI,CAAC,KAAK,WAAW;AACnB,aAAK,cAAc;AACnB;;AAGF,WAAK,cAAc;AAGnB,aAAO,KAAK,MAAM,SAAS,GAAG;AAE5B,YADa,KAAK,QAAQ,KAAK,QAAQ,YAAA,MAC1B,OACX;AAGF,cAAM,OAAO,KAAK,QAAQ;AAC1B,YAAI,OAAO,GAAG;AAEZ,eAAK,YAAY,WAAA,MAAiB,KAAK,KAAA,GAAQ,IAAA;AAC/C;;;AAMJ,WAAK,cAAc;;uBAMD;AAClB,WAAK,YAAY;AACjB,UAAI,CAAC,KAAK,eAAe,KAAK,MAAM,SAAS,EAC3C,MAAK,KAAA;;sBAOU;AACjB,WAAK,aAAA;AACL,WAAK,YAAY;AACjB,WAAK,cAAc;;8BAMc;AACjC,UAAI,KAAK,WAAW;AAClB,qBAAa,KAAK,SAAA;AAClB,aAAK,YAAY;;;yBAaL,WAA0B,YAAgC;AACxE,UAAI,KAAK,MAAM,WAAW,EACxB;AAGF,UAAI,KAAK,QAAQ,eAAe,aAAa,QAC3C,QAAO,KAAK,MAAM,CAAA;UAElB,QAAO,KAAK,MAAM,KAAK,MAAM,SAAS,CAAA;;8BAON;AAClC,aAAO,CAAC,GAAG,KAAK,KAAA;;kBAchB,gBAAwB,KAAK,MAAM,QACnC,aACS;AACT,WAAK,aAAA;AACL,eAAS,IAAI,GAAG,IAAI,iBAAiB,KAAK,MAAM,SAAS,GAAG,IAC1D,MAAK,QAAQ,QAAA;AAGf,UAAI,KAAK,aAAa,KAAK,MAAM,SAAS,KAAK,CAAC,KAAK,YACnD,MAAK,KAAA;;yBAgBO,kBAAwD;AACtE,YAAM,QAAQ,KAAK,aAAA;AACnB,WAAK,MAAA;AACL,oBAAc,KAAA;;uBAMI;AAClB,WAAK,QAAQ,CAAA;;AA9Rb,SAAK,QAAQ,aAAa,KAAK,QAAQ,cAAc;AACrD,SAAK,QAAQ,eAAe,KAAK,QAAQ,gBAAgB;AACzD,SAAK,QAAQ,UAAU,KAAK,QAAQ,WAAW;AAC/C,SAAK,QAAQ,UAAU,KAAK,QAAQ,WAAW;AAC/C,SAAK,QAAQ,OAAO,KAAK,QAAQ,QAAQ;AAEzC,SAAK,YAAY,KAAK,QAAQ;AAG9B,QAAI,KAAK,QAAQ,aACf,YAAW,QAAQ,KAAK,QAAQ,aAC9B,MAAK,QAAQ,MAAM,KAAK,QAAQ,YAAY,KAAA;AAKhD,QAAI,KAAK,aAAa,KAAK,MAAM,SAAS,EACxC,MAAK,KAAA;;;;;EAOT,IAAI,OAAe;AACjB,WAAO,KAAK,MAAM;;;;;EAMpB,IAAI,UAAmB;AACrB,WAAO,KAAK,MAAM,WAAW;;;;;EAM/B,IAAI,iBAA0B;AAC5B,WAAO,KAAK;;;;;AC5FhB,IAAa,gBAAb,MAAoD;EAMlD,YACSC,IACAC,SACP;AAFO,SAAA,KAAA;AACA,SAAA,UAAA;6BALmB;qBACR;4BA2BD,SAAgC;AAEjD,YAAM,yBADM,KAAK,IAAA,IACoB,KAAK;AAG1C,UAAI,KAAK,QAAQ,WAAW,0BAA0B,KAAK,QAAQ,KACjE,MAAK,QAAQ,GAAG,IAAA;WACX;AAEL,aAAK,WAAW;AAGhB,YAAI,CAAC,KAAK,aAAa,KAAK,QAAQ,UAAU;AAC5C,gBAAM,kBAAkB,KAAK,QAAQ,OAAO;AAC5C,eAAK,YAAY;AACjB,eAAK,YAAY,WAAA,MAAiB;AAChC,gBAAI,KAAK,aAAa,OACpB,MAAK,QAAQ,GAAG,KAAK,QAAA;aAEtB,eAAA;;;;uBAKa,SAAgC;;AACpD,WAAK,GAAG,GAAG,IAAA;AACX,uBAAK,SAAQ,cAAb,4BAAyB,MAAM;AAC/B,WAAK,oBAAoB,KAAK,IAAA;AAC9B,WAAK,aAAA;AACL,WAAK,WAAW;AAChB,WAAK,YAAY;;uBAQC;AAClB,UAAI,KAAK,aAAa,KAAK,SACzB,MAAK,QAAQ,GAAG,KAAK,QAAA;;wBAQJ;AACnB,WAAK,aAAA;AACL,WAAK,WAAW;AAChB,WAAK,YAAY;;8BAGgB;AACjC,UAAI,KAAK,WAAW;AAClB,qBAAa,KAAK,SAAA;AAClB,aAAK,YAAY;;;AA7EnB,QACE,KAAK,QAAQ,YAAY,UACzB,KAAK,QAAQ,aAAa,QAC1B;AACA,WAAK,QAAQ,UAAU;AACvB,WAAK,QAAQ,WAAW;;;;AA0G9B,SAAgB,aACd,IACA,SACoC;AAEpC,SADkB,IAAI,cAAc,IAAI,OAAA,EACvB;;",
  "names": ["fn: TFn", "options: LiteDebouncerOptions<TFn>", "_b", "_a", "fn: (item: TValue) => void", "options: LiteQueuerOptions<TValue>", "item: TValue | undefined", "fn: TFn", "options: LiteThrottlerOptions<TFn>"]
}
