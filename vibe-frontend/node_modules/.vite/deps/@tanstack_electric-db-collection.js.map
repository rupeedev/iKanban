{
  "version": 3,
  "sources": ["../../@microsoft/fetch-event-source/src/parse.ts", "../../@microsoft/fetch-event-source/src/fetch.ts", "../../@electric-sql/client/src/error.ts", "../../@electric-sql/client/src/parser.ts", "../../@electric-sql/client/src/column-mapper.ts", "../../@electric-sql/client/src/helpers.ts", "../../@electric-sql/client/src/constants.ts", "../../@electric-sql/client/src/fetch.ts", "../../@electric-sql/client/src/expression-compiler.ts", "../../@electric-sql/client/src/client.ts", "../../@electric-sql/client/src/expired-shapes-cache.ts", "../../@electric-sql/client/src/up-to-date-tracker.ts", "../../@electric-sql/client/src/snapshot-tracker.ts", "../../@electric-sql/client/src/shape.ts", "../../@tanstack/electric-db-collection/src/errors.ts", "../../@tanstack/electric-db-collection/src/pg-serializer.ts", "../../@tanstack/electric-db-collection/src/sql-compiler.ts", "../../@tanstack/electric-db-collection/src/tag-index.ts", "../../@tanstack/electric-db-collection/src/electric.ts"],
  "sourcesContent": [null, null, "export class FetchError extends Error {\n  status: number\n  text?: string\n  json?: object\n  headers: Record<string, string>\n\n  constructor(\n    status: number,\n    text: string | undefined,\n    json: object | undefined,\n    headers: Record<string, string>,\n    public url: string,\n    message?: string\n  ) {\n    super(\n      message ||\n        `HTTP Error ${status} at ${url}: ${text ?? JSON.stringify(json)}`\n    )\n    this.name = `FetchError`\n    this.status = status\n    this.text = text\n    this.json = json\n    this.headers = headers\n  }\n\n  static async fromResponse(\n    response: Response,\n    url: string\n  ): Promise<FetchError> {\n    const status = response.status\n    const headers = Object.fromEntries([...response.headers.entries()])\n    let text: string | undefined = undefined\n    let json: object | undefined = undefined\n\n    const contentType = response.headers.get(`content-type`)\n    if (!response.bodyUsed) {\n      if (contentType && contentType.includes(`application/json`)) {\n        json = (await response.json()) as object\n      } else {\n        text = await response.text()\n      }\n    }\n\n    return new FetchError(status, text, json, headers, url)\n  }\n}\n\nexport class FetchBackoffAbortError extends Error {\n  constructor() {\n    super(`Fetch with backoff aborted`)\n    this.name = `FetchBackoffAbortError`\n  }\n}\n\nexport class InvalidShapeOptionsError extends Error {\n  constructor(message: string) {\n    super(message)\n    this.name = `InvalidShapeOptionsError`\n  }\n}\n\nexport class MissingShapeUrlError extends Error {\n  constructor() {\n    super(`Invalid shape options: missing required url parameter`)\n    this.name = `MissingShapeUrlError`\n  }\n}\n\nexport class InvalidSignalError extends Error {\n  constructor() {\n    super(`Invalid signal option. It must be an instance of AbortSignal.`)\n    this.name = `InvalidSignalError`\n  }\n}\n\nexport class MissingShapeHandleError extends Error {\n  constructor() {\n    super(\n      `shapeHandle is required if this isn't an initial fetch (i.e. offset > -1)`\n    )\n    this.name = `MissingShapeHandleError`\n  }\n}\n\nexport class ReservedParamError extends Error {\n  constructor(reservedParams: string[]) {\n    super(\n      `Cannot use reserved Electric parameter names in custom params: ${reservedParams.join(`, `)}`\n    )\n    this.name = `ReservedParamError`\n  }\n}\n\nexport class ParserNullValueError extends Error {\n  constructor(columnName: string) {\n    super(`Column \"${columnName ?? `unknown`}\" does not allow NULL values`)\n    this.name = `ParserNullValueError`\n  }\n}\n\nexport class ShapeStreamAlreadyRunningError extends Error {\n  constructor() {\n    super(`ShapeStream is already running`)\n    this.name = `ShapeStreamAlreadyRunningError`\n  }\n}\n\nexport class MissingHeadersError extends Error {\n  constructor(url: string, missingHeaders: Array<string>) {\n    let msg = `The response for the shape request to ${url} didn't include the following required headers:\\n`\n    missingHeaders.forEach((h) => {\n      msg += `- ${h}\\n`\n    })\n    msg += `\\nThis is often due to a proxy not setting CORS correctly so that all Electric headers can be read by the client.`\n    msg += `\\nFor more information visit the troubleshooting guide: /docs/guides/troubleshooting/missing-headers`\n    super(msg)\n  }\n}\n", "import { ColumnInfo, GetExtensions, Row, Schema, Value } from './types'\nimport { ParserNullValueError } from './error'\n\ntype Token = string\ntype NullableToken = Token | null\nexport type ParseFunction<Extensions = never> = (\n  value: Token,\n  additionalInfo?: Omit<ColumnInfo, `type` | `dims`>\n) => Value<Extensions>\ntype NullableParseFunction<Extensions = never> = (\n  value: NullableToken,\n  additionalInfo?: Omit<ColumnInfo, `type` | `dims`>\n) => Value<Extensions>\n/**\n * @typeParam Extensions - Additional types that can be parsed by this parser beyond the standard SQL types.\n *                         Defaults to no additional types.\n */\nexport type Parser<Extensions = never> = {\n  [key: string]: ParseFunction<Extensions>\n}\n\nexport type TransformFunction<Extensions = never> = (\n  message: Row<Extensions>\n) => Row<Extensions>\n\nconst parseNumber = (value: string) => Number(value)\nconst parseBool = (value: string) => value === `true` || value === `t`\nconst parseBigInt = (value: string) => BigInt(value)\nconst parseJson = (value: string) => JSON.parse(value)\nconst identityParser: ParseFunction = (v: string) => v\n\nexport const defaultParser: Parser = {\n  int2: parseNumber,\n  int4: parseNumber,\n  int8: parseBigInt,\n  bool: parseBool,\n  float4: parseNumber,\n  float8: parseNumber,\n  json: parseJson,\n  jsonb: parseJson,\n}\n\n// Taken from: https://github.com/electric-sql/pglite/blob/main/packages/pglite/src/types.ts#L233-L279\nexport function pgArrayParser<Extensions>(\n  value: Token,\n  parser?: NullableParseFunction<Extensions>\n): Value<Extensions> {\n  let i = 0\n  let char = null\n  let str = ``\n  let quoted = false\n  let last = 0\n  let p: string | undefined = undefined\n\n  function extractValue(x: Token, start: number, end: number) {\n    let val: Token | null = x.slice(start, end)\n    val = val === `NULL` ? null : val\n    return parser ? parser(val) : val\n  }\n\n  function loop(x: string): Array<Value<Extensions>> {\n    const xs = []\n    for (; i < x.length; i++) {\n      char = x[i]\n      if (quoted) {\n        if (char === `\\\\`) {\n          str += x[++i]\n        } else if (char === `\"`) {\n          xs.push(parser ? parser(str) : str)\n          str = ``\n          quoted = x[i + 1] === `\"`\n          last = i + 2\n        } else {\n          str += char\n        }\n      } else if (char === `\"`) {\n        quoted = true\n      } else if (char === `{`) {\n        last = ++i\n        xs.push(loop(x))\n      } else if (char === `}`) {\n        quoted = false\n        last < i && xs.push(extractValue(x, last, i))\n        last = i + 1\n        break\n      } else if (char === `,` && p !== `}` && p !== `\"`) {\n        xs.push(extractValue(x, last, i))\n        last = i + 1\n      }\n      p = char\n    }\n    last < i && xs.push(xs.push(extractValue(x, last, i + 1)))\n    return xs\n  }\n\n  return loop(value)[0]\n}\n\nexport class MessageParser<T extends Row<unknown>> {\n  private parser: Parser<GetExtensions<T>>\n  private transformer?: TransformFunction<GetExtensions<T>>\n  constructor(\n    parser?: Parser<GetExtensions<T>>,\n    transformer?: TransformFunction<GetExtensions<T>>\n  ) {\n    // Merge the provided parser with the default parser\n    // to use the provided parser whenever defined\n    // and otherwise fall back to the default parser\n    this.parser = { ...defaultParser, ...parser }\n    this.transformer = transformer\n  }\n\n  parse<Result>(messages: string, schema: Schema): Result {\n    return JSON.parse(messages, (key, value) => {\n      // typeof value === `object` && value !== null\n      // is needed because there could be a column named `value`\n      // and the value associated to that column will be a string or null.\n      // But `typeof null === 'object'` so we need to make an explicit check.\n      // We also parse the `old_value`, which appears on updates when `replica=full`.\n      if (\n        (key === `value` || key === `old_value`) &&\n        typeof value === `object` &&\n        value !== null\n      ) {\n        return this.transformMessageValue(value, schema)\n      }\n      return value\n    }) as Result\n  }\n\n  /**\n   * Parse an array of ChangeMessages from a snapshot response.\n   * Applies type parsing and transformations to the value and old_value properties.\n   */\n  parseSnapshotData<Result>(\n    messages: Array<unknown>,\n    schema: Schema\n  ): Array<Result> {\n    return messages.map((message) => {\n      const msg = message as Record<string, unknown>\n\n      // Transform the value property if it exists\n      if (msg.value && typeof msg.value === `object` && msg.value !== null) {\n        msg.value = this.transformMessageValue(msg.value, schema)\n      }\n\n      // Transform the old_value property if it exists\n      if (\n        msg.old_value &&\n        typeof msg.old_value === `object` &&\n        msg.old_value !== null\n      ) {\n        msg.old_value = this.transformMessageValue(msg.old_value, schema)\n      }\n\n      return msg as Result\n    })\n  }\n\n  /**\n   * Transform a message value or old_value object by parsing its columns.\n   */\n  private transformMessageValue(\n    value: unknown,\n    schema: Schema\n  ): Row<GetExtensions<T>> {\n    const row = value as Record<string, Value<GetExtensions<T>>>\n    Object.keys(row).forEach((key) => {\n      row[key] = this.parseRow(key, row[key] as NullableToken, schema)\n    })\n\n    return this.transformer ? this.transformer(row) : row\n  }\n\n  // Parses the message values using the provided parser based on the schema information\n  private parseRow(\n    key: string,\n    value: NullableToken,\n    schema: Schema\n  ): Value<GetExtensions<T>> {\n    const columnInfo = schema[key]\n    if (!columnInfo) {\n      // We don't have information about the value\n      // so we just return it\n      return value\n    }\n\n    // Copy the object but don't include `dimensions` and `type`\n    const { type: typ, dims: dimensions, ...additionalInfo } = columnInfo\n\n    // Pick the right parser for the type\n    // and support parsing null values if needed\n    // if no parser is provided for the given type, just return the value as is\n    const typeParser = this.parser[typ] ?? identityParser\n    const parser = makeNullableParser(typeParser, columnInfo, key)\n\n    if (dimensions && dimensions > 0) {\n      // It's an array\n      const nullablePgArrayParser = makeNullableParser(\n        (value, _) => pgArrayParser(value, parser),\n        columnInfo,\n        key\n      )\n      return nullablePgArrayParser(value)\n    }\n\n    return parser(value, additionalInfo)\n  }\n}\n\nfunction makeNullableParser<Extensions>(\n  parser: ParseFunction<Extensions>,\n  columnInfo: ColumnInfo,\n  columnName?: string\n): NullableParseFunction<Extensions> {\n  const isNullable = !(columnInfo.not_null ?? false)\n  // The sync service contains `null` value for a column whose value is NULL\n  // but if the column value is an array that contains a NULL value\n  // then it will be included in the array string as `NULL`, e.g.: `\"{1,NULL,3}\"`\n  return (value: NullableToken) => {\n    if (value === null) {\n      if (!isNullable) {\n        throw new ParserNullValueError(columnName ?? `unknown`)\n      }\n      return null\n    }\n    return parser(value, columnInfo)\n  }\n}\n", "import { Schema } from './types'\n\ntype DbColumnName = string\ntype AppColumnName = string\n\n/**\n * Quote a PostgreSQL identifier for safe use in query parameters.\n *\n * Wraps the identifier in double quotes and escapes any internal\n * double quotes by doubling them. This ensures identifiers with\n * special characters (commas, spaces, etc.) are handled correctly.\n *\n * @param identifier - The identifier to quote\n * @returns The quoted identifier\n *\n * @example\n * ```typescript\n * quoteIdentifier('user_id')        // '\"user_id\"'\n * quoteIdentifier('foo,bar')        // '\"foo,bar\"'\n * quoteIdentifier('has\"quote')      // '\"has\"\"quote\"'\n * ```\n *\n * @internal\n */\nexport function quoteIdentifier(identifier: string): string {\n  // Escape internal double quotes by doubling them\n  const escaped = identifier.replace(/\"/g, `\"\"`)\n  return `\"${escaped}\"`\n}\n\n/**\n * A bidirectional column mapper that handles transforming column **names**\n * between database format (e.g., snake_case) and application format (e.g., camelCase).\n *\n * **Important**: ColumnMapper only transforms column names, not column values or types.\n * For type conversions (e.g., string → Date), use the `parser` option.\n * For value transformations (e.g., encryption), use the `transformer` option.\n *\n * @example\n * ```typescript\n * const mapper = snakeCamelMapper()\n * mapper.decode('user_id') // 'userId'\n * mapper.encode('userId') // 'user_id'\n * ```\n */\nexport interface ColumnMapper {\n  /**\n   * Transform a column name from database format to application format.\n   * Applied to column names in query results.\n   */\n  decode: (dbColumnName: DbColumnName) => AppColumnName\n\n  /**\n   * Transform a column name from application format to database format.\n   * Applied to column names in WHERE clauses and other query parameters.\n   */\n  encode: (appColumnName: AppColumnName) => DbColumnName\n}\n\n/**\n * Converts a snake_case string to camelCase.\n *\n * Handles edge cases:\n * - Preserves leading underscores: `_user_id` → `_userId`\n * - Preserves trailing underscores: `user_id_` → `userId_`\n * - Collapses multiple underscores: `user__id` → `userId`\n * - Normalizes to lowercase first: `user_Column` → `userColumn`\n *\n * @example\n * snakeToCamel('user_id') // 'userId'\n * snakeToCamel('project_id') // 'projectId'\n * snakeToCamel('created_at') // 'createdAt'\n * snakeToCamel('_private') // '_private'\n * snakeToCamel('user__id') // 'userId'\n * snakeToCamel('user_id_') // 'userId_'\n */\nexport function snakeToCamel(str: string): string {\n  // Preserve leading underscores\n  const leadingUnderscores = str.match(/^_+/)?.[0] ?? ``\n  const withoutLeading = str.slice(leadingUnderscores.length)\n\n  // Preserve trailing underscores for round-trip safety\n  const trailingUnderscores = withoutLeading.match(/_+$/)?.[0] ?? ``\n  const core = trailingUnderscores\n    ? withoutLeading.slice(\n        0,\n        withoutLeading.length - trailingUnderscores.length\n      )\n    : withoutLeading\n\n  // Convert to lowercase\n  const normalized = core.toLowerCase()\n\n  // Convert snake_case to camelCase (handling multiple underscores)\n  const camelCased = normalized.replace(/_+([a-z])/g, (_, letter) =>\n    letter.toUpperCase()\n  )\n\n  return leadingUnderscores + camelCased + trailingUnderscores\n}\n\n/**\n * Converts a camelCase string to snake_case.\n *\n * Handles consecutive capitals (acronyms) properly:\n * - `userID` → `user_id`\n * - `userHTTPSURL` → `user_https_url`\n *\n * @example\n * camelToSnake('userId') // 'user_id'\n * camelToSnake('projectId') // 'project_id'\n * camelToSnake('createdAt') // 'created_at'\n * camelToSnake('userID') // 'user_id'\n * camelToSnake('parseHTMLString') // 'parse_html_string'\n */\nexport function camelToSnake(str: string): string {\n  return (\n    str\n      // Insert underscore before uppercase letters that follow lowercase letters\n      // e.g., userId -> user_Id\n      .replace(/([a-z])([A-Z])/g, `$1_$2`)\n      // Insert underscore before uppercase letters that are followed by lowercase letters\n      // This handles acronyms: userID -> user_ID, but parseHTMLString -> parse_HTML_String\n      .replace(/([A-Z]+)([A-Z][a-z])/g, `$1_$2`)\n      .toLowerCase()\n  )\n}\n\n/**\n * Creates a column mapper from an explicit mapping of database columns to application columns.\n *\n * @param mapping - Object mapping database column names (keys) to application column names (values)\n * @returns A ColumnMapper that can encode and decode column names bidirectionally\n *\n * @example\n * const mapper = createColumnMapper({\n *   user_id: 'userId',\n *   project_id: 'projectId',\n *   created_at: 'createdAt'\n * })\n *\n * // Use with ShapeStream\n * const stream = new ShapeStream({\n *   url: 'http://localhost:3000/v1/shape',\n *   params: { table: 'todos' },\n *   columnMapper: mapper\n * })\n */\nexport function createColumnMapper(\n  mapping: Record<string, string>\n): ColumnMapper {\n  // Build reverse mapping: app name -> db name\n  const reverseMapping: Record<string, string> = {}\n  for (const [dbName, appName] of Object.entries(mapping)) {\n    reverseMapping[appName] = dbName\n  }\n\n  return {\n    decode: (dbColumnName: string) => {\n      return mapping[dbColumnName] ?? dbColumnName\n    },\n\n    encode: (appColumnName: string) => {\n      return reverseMapping[appColumnName] ?? appColumnName\n    },\n  }\n}\n\n/**\n * Encodes column names in a WHERE clause using the provided encoder function.\n * Uses regex to identify column references and replace them.\n *\n * Handles common SQL patterns:\n * - Simple comparisons: columnName = $1\n * - Function calls: LOWER(columnName)\n * - Qualified names: table.columnName\n * - Operators: columnName IS NULL, columnName IN (...)\n * - Quoted strings: Preserves string literals unchanged\n *\n * Note: This uses regex-based replacement which works for most common cases\n * but may not handle all complex SQL expressions perfectly. For complex queries,\n * test thoroughly or use database column names directly in WHERE clauses.\n *\n * @param whereClause - The WHERE clause string to encode\n * @param encode - Optional encoder function. If undefined, returns whereClause unchanged.\n * @returns The encoded WHERE clause\n *\n * @internal\n */\nexport function encodeWhereClause(\n  whereClause: string | undefined,\n  encode?: (columnName: string) => string\n): string {\n  if (!whereClause || !encode) return whereClause ?? ``\n\n  // SQL keywords that should not be transformed (common ones)\n  const sqlKeywords = new Set([\n    `SELECT`,\n    `FROM`,\n    `WHERE`,\n    `AND`,\n    `OR`,\n    `NOT`,\n    `IN`,\n    `IS`,\n    `NULL`,\n    `NULLS`,\n    `FIRST`,\n    `LAST`,\n    `TRUE`,\n    `FALSE`,\n    `LIKE`,\n    `ILIKE`,\n    `BETWEEN`,\n    `ASC`,\n    `DESC`,\n    `LIMIT`,\n    `OFFSET`,\n    `ORDER`,\n    `BY`,\n    `GROUP`,\n    `HAVING`,\n    `DISTINCT`,\n    `AS`,\n    `ON`,\n    `JOIN`,\n    `LEFT`,\n    `RIGHT`,\n    `INNER`,\n    `OUTER`,\n    `CROSS`,\n    `CASE`,\n    `WHEN`,\n    `THEN`,\n    `ELSE`,\n    `END`,\n    `CAST`,\n    `LOWER`,\n    `UPPER`,\n    `COALESCE`,\n    `NULLIF`,\n  ])\n\n  // Track positions of quoted strings and double-quoted identifiers to skip them\n  const quotedRanges: Array<{ start: number; end: number }> = []\n\n  // Find all single-quoted strings and double-quoted identifiers\n  let pos = 0\n  while (pos < whereClause.length) {\n    const ch = whereClause[pos]\n    if (ch === `'` || ch === `\"`) {\n      const start = pos\n      const quoteChar = ch\n      pos++ // Skip opening quote\n      // Find closing quote, handling escaped quotes ('' or \"\")\n      while (pos < whereClause.length) {\n        if (whereClause[pos] === quoteChar) {\n          if (whereClause[pos + 1] === quoteChar) {\n            pos += 2 // Skip escaped quote\n          } else {\n            pos++ // Skip closing quote\n            break\n          }\n        } else {\n          pos++\n        }\n      }\n      quotedRanges.push({ start, end: pos })\n    } else {\n      pos++\n    }\n  }\n\n  // Helper to check if position is within a quoted string or double-quoted identifier\n  const isInQuotedString = (pos: number): boolean => {\n    return quotedRanges.some((range) => pos >= range.start && pos < range.end)\n  }\n\n  // Pattern explanation:\n  // (?<![a-zA-Z0-9_]) - negative lookbehind: not preceded by identifier char\n  // ([a-zA-Z_][a-zA-Z0-9_]*) - capture: valid SQL identifier\n  // (?![a-zA-Z0-9_]) - negative lookahead: not followed by identifier char\n  //\n  // This avoids matching:\n  // - Parts of longer identifiers\n  // - SQL keywords (handled by checking if result differs from input)\n  const identifierPattern =\n    /(?<![a-zA-Z0-9_])([a-zA-Z_][a-zA-Z0-9_]*)(?![a-zA-Z0-9_])/g\n\n  return whereClause.replace(identifierPattern, (match, _p1, offset) => {\n    // Don't transform if inside quoted string\n    if (isInQuotedString(offset)) {\n      return match\n    }\n\n    // Don't transform SQL keywords\n    if (sqlKeywords.has(match.toUpperCase())) {\n      return match\n    }\n\n    // Don't transform parameter placeholders ($1, $2, etc.)\n    // This regex won't match them anyway, but being explicit\n    if (match.startsWith(`$`)) {\n      return match\n    }\n\n    // Apply encoding\n    const encoded = encode(match)\n    return encoded\n  })\n}\n\n/**\n * Creates a column mapper that automatically converts between snake_case and camelCase.\n * This is the most common use case for column mapping.\n *\n * When a schema is provided, it will only map columns that exist in the schema.\n * Otherwise, it will map any column name it encounters.\n *\n * **⚠️ Limitations and Edge Cases:**\n * - **WHERE clause encoding**: Uses regex-based parsing which may not handle all complex\n *   SQL expressions. Test thoroughly with your queries, especially those with:\n *   - Complex nested expressions\n *   - Custom operators or functions\n *   - Column names that conflict with SQL keywords\n *   - Quoted identifiers (e.g., `\"$price\"`, `\"user-id\"`) - not supported\n *   - Column names with special characters (non-alphanumeric except underscore)\n * - **Acronym ambiguity**: `userID` → `user_id` → `userId` (ID becomes Id after roundtrip)\n *   Use `createColumnMapper()` with explicit mapping if you need exact control\n * - **Type conversion**: This only renames columns, not values. Use `parser` for type conversion\n *\n * **When to use explicit mapping instead:**\n * - You have column names that don't follow snake_case/camelCase patterns\n * - You need exact control over mappings (e.g., `id` → `identifier`)\n * - Your WHERE clauses are complex and automatic encoding fails\n * - You have quoted identifiers or column names with special characters\n *\n * @param schema - Optional database schema to constrain mapping to known columns\n * @returns A ColumnMapper for snake_case ↔ camelCase conversion\n *\n * @example\n * // Basic usage\n * const mapper = snakeCamelMapper()\n *\n * // With schema - only maps columns in schema (recommended)\n * const mapper = snakeCamelMapper(schema)\n *\n * // Use with ShapeStream\n * const stream = new ShapeStream({\n *   url: 'http://localhost:3000/v1/shape',\n *   params: { table: 'todos' },\n *   columnMapper: snakeCamelMapper()\n * })\n *\n * @example\n * // If automatic encoding fails, fall back to manual column names in WHERE clauses:\n * stream.requestSnapshot({\n *   where: \"user_id = $1\", // Use database column names directly if needed\n *   params: { \"1\": \"123\" }\n * })\n */\nexport function snakeCamelMapper(schema?: Schema): ColumnMapper {\n  // If schema provided, build explicit mapping\n  if (schema) {\n    const mapping: Record<string, string> = {}\n    for (const dbColumn of Object.keys(schema)) {\n      mapping[dbColumn] = snakeToCamel(dbColumn)\n    }\n    return createColumnMapper(mapping)\n  }\n\n  // Otherwise, map dynamically\n  return {\n    decode: (dbColumnName: string) => {\n      return snakeToCamel(dbColumnName)\n    },\n\n    encode: (appColumnName: string) => {\n      return camelToSnake(appColumnName)\n    },\n  }\n}\n", "import {\n  ChangeMessage,\n  ControlMessage,\n  Message,\n  NormalizedPgSnapshot,\n  Offset,\n  PostgresSnapshot,\n  Row,\n} from './types'\n\n/**\n * Type guard for checking {@link Message} is {@link ChangeMessage}.\n *\n * See [TS docs](https://www.typescriptlang.org/docs/handbook/advanced-types.html#user-defined-type-guards)\n * for information on how to use type guards.\n *\n * @param message - the message to check\n * @returns true if the message is a {@link ChangeMessage}\n *\n * @example\n * ```ts\n * if (isChangeMessage(message)) {\n *   const msgChng: ChangeMessage = message // Ok\n *   const msgCtrl: ControlMessage = message // Err, type mismatch\n * }\n * ```\n */\nexport function isChangeMessage<T extends Row<unknown> = Row>(\n  message: Message<T>\n): message is ChangeMessage<T> {\n  return `key` in message\n}\n\n/**\n * Type guard for checking {@link Message} is {@link ControlMessage}.\n *\n * See [TS docs](https://www.typescriptlang.org/docs/handbook/advanced-types.html#user-defined-type-guards)\n * for information on how to use type guards.\n *\n * @param message - the message to check\n * @returns true if the message is a {@link ControlMessage}\n *\n *  * @example\n * ```ts\n * if (isControlMessage(message)) {\n *   const msgChng: ChangeMessage = message // Err, type mismatch\n *   const msgCtrl: ControlMessage = message // Ok\n * }\n * ```\n */\nexport function isControlMessage<T extends Row<unknown> = Row>(\n  message: Message<T>\n): message is ControlMessage {\n  return !isChangeMessage(message)\n}\n\nexport function isUpToDateMessage<T extends Row<unknown> = Row>(\n  message: Message<T>\n): message is ControlMessage & { up_to_date: true } {\n  return isControlMessage(message) && message.headers.control === `up-to-date`\n}\n\n/**\n * Parses the LSN from the up-to-date message and turns it into an offset.\n * The LSN is only present in the up-to-date control message when in SSE mode.\n * If we are not in SSE mode this function will return undefined.\n */\nexport function getOffset(message: ControlMessage): Offset | undefined {\n  if (message.headers.control != `up-to-date`) return\n  const lsn = message.headers.global_last_seen_lsn\n  return lsn ? (`${lsn}_0` as Offset) : undefined\n}\n\n/**\n * Checks if a transaction is visible in a snapshot.\n *\n * @param txid - the transaction id to check\n * @param snapshot - the information about the snapshot\n * @returns true if the transaction is visible in the snapshot\n */\nexport function isVisibleInSnapshot(\n  txid: number | bigint | `${bigint}`,\n  snapshot: PostgresSnapshot | NormalizedPgSnapshot\n): boolean {\n  const xid = BigInt(txid)\n  const xmin = BigInt(snapshot.xmin)\n  const xmax = BigInt(snapshot.xmax)\n  const xip = snapshot.xip_list.map(BigInt)\n\n  // If the transaction id is less than the minimum transaction id, it is visible in the snapshot.\n  // If the transaction id is less than the maximum transaction id and not in the list of active\n  //   transactions at the time of the snapshot, it has been committed before the snapshot was taken\n  //   and is therefore visible in the snapshot.\n  // Otherwise, it is not visible in the snapshot.\n\n  return xid < xmin || (xid < xmax && !xip.includes(xid))\n}\n", "export const LIVE_CACHE_BUSTER_HEADER = `electric-cursor`\nexport const SHAPE_HANDLE_HEADER = `electric-handle`\nexport const CHUNK_LAST_OFFSET_HEADER = `electric-offset`\nexport const SHAPE_SCHEMA_HEADER = `electric-schema`\nexport const CHUNK_UP_TO_DATE_HEADER = `electric-up-to-date`\nexport const COLUMNS_QUERY_PARAM = `columns`\nexport const LIVE_CACHE_BUSTER_QUERY_PARAM = `cursor`\nexport const EXPIRED_HANDLE_QUERY_PARAM = `expired_handle`\nexport const SHAPE_HANDLE_QUERY_PARAM = `handle`\nexport const LIVE_QUERY_PARAM = `live`\nexport const OFFSET_QUERY_PARAM = `offset`\nexport const TABLE_QUERY_PARAM = `table`\nexport const WHERE_QUERY_PARAM = `where`\nexport const REPLICA_PARAM = `replica`\nexport const WHERE_PARAMS_PARAM = `params`\n/**\n * @deprecated Use {@link LIVE_SSE_QUERY_PARAM} instead.\n */\nexport const EXPERIMENTAL_LIVE_SSE_QUERY_PARAM = `experimental_live_sse`\nexport const LIVE_SSE_QUERY_PARAM = `live_sse`\nexport const FORCE_DISCONNECT_AND_REFRESH = `force-disconnect-and-refresh`\nexport const PAUSE_STREAM = `pause-stream`\nexport const LOG_MODE_QUERY_PARAM = `log`\nexport const SUBSET_PARAM_WHERE = `subset__where`\nexport const SUBSET_PARAM_LIMIT = `subset__limit`\nexport const SUBSET_PARAM_OFFSET = `subset__offset`\nexport const SUBSET_PARAM_ORDER_BY = `subset__order_by`\nexport const SUBSET_PARAM_WHERE_PARAMS = `subset__params`\nexport const SUBSET_PARAM_WHERE_EXPR = `subset__where_expr`\nexport const SUBSET_PARAM_ORDER_BY_EXPR = `subset__order_by_expr`\n\n// Query parameters that should be passed through when proxying Electric requests\nexport const ELECTRIC_PROTOCOL_QUERY_PARAMS: Array<string> = [\n  LIVE_QUERY_PARAM,\n  LIVE_SSE_QUERY_PARAM,\n  SHAPE_HANDLE_QUERY_PARAM,\n  OFFSET_QUERY_PARAM,\n  LIVE_CACHE_BUSTER_QUERY_PARAM,\n  EXPIRED_HANDLE_QUERY_PARAM,\n  LOG_MODE_QUERY_PARAM,\n  SUBSET_PARAM_WHERE,\n  SUBSET_PARAM_LIMIT,\n  SUBSET_PARAM_OFFSET,\n  SUBSET_PARAM_ORDER_BY,\n  SUBSET_PARAM_WHERE_PARAMS,\n  SUBSET_PARAM_WHERE_EXPR,\n  SUBSET_PARAM_ORDER_BY_EXPR,\n]\n", "import {\n  CHUNK_LAST_OFFSET_HEADER,\n  CHUNK_UP_TO_DATE_HEADER,\n  EXPIRED_HANDLE_QUERY_PARAM,\n  LIVE_QUERY_PARAM,\n  OFFSET_QUERY_PARAM,\n  SHAPE_HANDLE_HEADER,\n  SHAPE_HANDLE_QUERY_PARAM,\n  SUBSET_PARAM_LIMIT,\n  SUBSET_PARAM_OFFSET,\n  SUBSET_PARAM_ORDER_BY,\n  SUBSET_PARAM_WHERE,\n  SUBSET_PARAM_WHERE_PARAMS,\n} from './constants'\nimport {\n  FetchError,\n  FetchBackoffAbortError,\n  MissingHeadersError,\n} from './error'\n\n// Some specific 4xx and 5xx HTTP status codes that we definitely\n// want to retry\nconst HTTP_RETRY_STATUS_CODES = [429]\n\nexport interface BackoffOptions {\n  /**\n   * Initial delay before retrying in milliseconds\n   */\n  initialDelay: number\n  /**\n   * Maximum retry delay in milliseconds\n   * After reaching this, delay stays constant (e.g., retry every 60s)\n   */\n  maxDelay: number\n  multiplier: number\n  onFailedAttempt?: () => void\n  debug?: boolean\n  /**\n   * Maximum number of retry attempts before giving up.\n   * Set to Infinity (default) for indefinite retries - needed for offline scenarios\n   * where clients may go offline and come back later.\n   */\n  maxRetries?: number\n}\n\nexport const BackoffDefaults = {\n  initialDelay: 100,\n  maxDelay: 60_000, // Cap at 60s - reasonable for long-lived connections\n  multiplier: 1.3,\n  maxRetries: Infinity, // Retry forever - clients may go offline and come back\n}\n\n/**\n * Parse Retry-After header value and return delay in milliseconds\n * Supports both delta-seconds format and HTTP-date format\n * Returns 0 if header is not present or invalid\n */\nexport function parseRetryAfterHeader(retryAfter: string | undefined): number {\n  if (!retryAfter) return 0\n\n  // Try parsing as seconds (delta-seconds format)\n  const retryAfterSec = Number(retryAfter)\n  if (Number.isFinite(retryAfterSec) && retryAfterSec > 0) {\n    return retryAfterSec * 1000\n  }\n\n  // Try parsing as HTTP-date\n  const retryDate = Date.parse(retryAfter)\n  if (!isNaN(retryDate)) {\n    // Handle clock skew: clamp to non-negative, cap at reasonable max\n    const deltaMs = retryDate - Date.now()\n    return Math.max(0, Math.min(deltaMs, 3600_000)) // Cap at 1 hour\n  }\n\n  return 0\n}\n\nexport function createFetchWithBackoff(\n  fetchClient: typeof fetch,\n  backoffOptions: BackoffOptions = BackoffDefaults\n): typeof fetch {\n  const {\n    initialDelay,\n    maxDelay,\n    multiplier,\n    debug = false,\n    onFailedAttempt,\n    maxRetries = Infinity,\n  } = backoffOptions\n  return async (...args: Parameters<typeof fetch>): Promise<Response> => {\n    const url = args[0]\n    const options = args[1]\n\n    let delay = initialDelay\n    let attempt = 0\n\n    while (true) {\n      try {\n        const result = await fetchClient(...args)\n        if (result.ok) {\n          return result\n        }\n\n        const err = await FetchError.fromResponse(result, url.toString())\n\n        throw err\n      } catch (e) {\n        onFailedAttempt?.()\n        if (options?.signal?.aborted) {\n          throw new FetchBackoffAbortError()\n        } else if (\n          e instanceof FetchError &&\n          !HTTP_RETRY_STATUS_CODES.includes(e.status) &&\n          e.status >= 400 &&\n          e.status < 500\n        ) {\n          // Any client errors cannot be backed off on, leave it to the caller to handle.\n          throw e\n        } else {\n          // Check max retries\n          attempt++\n          if (attempt > maxRetries) {\n            if (debug) {\n              console.log(\n                `Max retries reached (${attempt}/${maxRetries}), giving up`\n              )\n            }\n            throw e\n          }\n\n          // Calculate wait time honoring server-driven backoff as a floor\n          // Precedence: max(serverMinimum, min(clientMaxDelay, backoffWithJitter))\n\n          // 1. Parse server-provided Retry-After (if present)\n          const serverMinimumMs =\n            e instanceof FetchError && e.headers\n              ? parseRetryAfterHeader(e.headers[`retry-after`])\n              : 0\n\n          // 2. Calculate client backoff with full jitter strategy\n          // Full jitter: random_between(0, min(cap, exponential_backoff))\n          // See: https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/\n          const jitter = Math.random() * delay // random value between 0 and current delay\n          const clientBackoffMs = Math.min(jitter, maxDelay) // cap at maxDelay\n\n          // 3. Server minimum is the floor, client cap is the ceiling\n          const waitMs = Math.max(serverMinimumMs, clientBackoffMs)\n\n          if (debug) {\n            const source = serverMinimumMs > 0 ? `server+client` : `client`\n            console.log(\n              `Retry attempt #${attempt} after ${waitMs}ms (${source}, serverMin=${serverMinimumMs}ms, clientBackoff=${clientBackoffMs}ms)`\n            )\n          }\n\n          // Wait for the calculated duration\n          await new Promise((resolve) => setTimeout(resolve, waitMs))\n\n          // Increase the delay for the next attempt (capped at maxDelay)\n          delay = Math.min(delay * multiplier, maxDelay)\n        }\n      }\n    }\n  }\n}\n\nconst NO_BODY_STATUS_CODES = [201, 204, 205]\n\n// Ensure body can actually be read in its entirety\nexport function createFetchWithConsumedMessages(fetchClient: typeof fetch) {\n  return async (...args: Parameters<typeof fetch>): Promise<Response> => {\n    const url = args[0]\n    const res = await fetchClient(...args)\n    try {\n      if (res.status < 200 || NO_BODY_STATUS_CODES.includes(res.status)) {\n        return res\n      }\n\n      const text = await res.text()\n      return new Response(text, res)\n    } catch (err) {\n      if (args[1]?.signal?.aborted) {\n        throw new FetchBackoffAbortError()\n      }\n\n      throw new FetchError(\n        res.status,\n        undefined,\n        undefined,\n        Object.fromEntries([...res.headers.entries()]),\n        url.toString(),\n        err instanceof Error\n          ? err.message\n          : typeof err === `string`\n            ? err\n            : `failed to read body`\n      )\n    }\n  }\n}\n\ninterface ChunkPrefetchOptions {\n  maxChunksToPrefetch: number\n}\n\nconst ChunkPrefetchDefaults = {\n  maxChunksToPrefetch: 2,\n}\n\n/**\n * Creates a fetch client that prefetches subsequent log chunks for\n * consumption by the shape stream without waiting for the chunk bodies\n * themselves to be loaded.\n *\n * @param fetchClient the client to wrap\n * @param prefetchOptions options to configure prefetching\n * @returns wrapped client with prefetch capabilities\n */\nexport function createFetchWithChunkBuffer(\n  fetchClient: typeof fetch,\n  prefetchOptions: ChunkPrefetchOptions = ChunkPrefetchDefaults\n): typeof fetch {\n  const { maxChunksToPrefetch } = prefetchOptions\n\n  let prefetchQueue: PrefetchQueue | undefined\n\n  const prefetchClient = async (...args: Parameters<typeof fetchClient>) => {\n    const url = args[0].toString()\n\n    // try to consume from the prefetch queue first, and if request is\n    // not present abort the prefetch queue as it must no longer be valid\n    const prefetchedRequest = prefetchQueue?.consume(...args)\n    if (prefetchedRequest) {\n      return prefetchedRequest\n    }\n\n    // Clear the prefetch queue after aborting to prevent returning\n    // stale/aborted requests on future calls with the same URL\n    prefetchQueue?.abort()\n    prefetchQueue = undefined\n\n    // perform request and fire off prefetch queue if request is eligible\n    const response = await fetchClient(...args)\n    const nextUrl = getNextChunkUrl(url, response)\n    if (nextUrl) {\n      prefetchQueue = new PrefetchQueue({\n        fetchClient,\n        maxPrefetchedRequests: maxChunksToPrefetch,\n        url: nextUrl,\n        requestInit: args[1],\n      })\n    }\n\n    return response\n  }\n\n  return prefetchClient\n}\n\nexport const requiredElectricResponseHeaders = [\n  `electric-offset`,\n  `electric-handle`,\n]\n\nexport const requiredLiveResponseHeaders = [`electric-cursor`]\n\nexport const requiredNonLiveResponseHeaders = [`electric-schema`]\n\nexport function createFetchWithResponseHeadersCheck(\n  fetchClient: typeof fetch\n): typeof fetch {\n  return async (...args: Parameters<typeof fetchClient>) => {\n    const response = await fetchClient(...args)\n\n    if (response.ok) {\n      // Check that the necessary Electric headers are present on the response\n      const headers = response.headers\n      const missingHeaders: Array<string> = []\n\n      const addMissingHeaders = (requiredHeaders: Array<string>) =>\n        missingHeaders.push(...requiredHeaders.filter((h) => !headers.has(h)))\n\n      const input = args[0]\n      const urlString = input.toString()\n      const url = new URL(urlString)\n\n      // Snapshot responses (subset params) return a JSON object and do not include Electric chunk headers\n      const isSnapshotRequest = [\n        SUBSET_PARAM_WHERE,\n        SUBSET_PARAM_WHERE_PARAMS,\n        SUBSET_PARAM_LIMIT,\n        SUBSET_PARAM_OFFSET,\n        SUBSET_PARAM_ORDER_BY,\n      ].some((p) => url.searchParams.has(p))\n      if (isSnapshotRequest) {\n        return response\n      }\n\n      addMissingHeaders(requiredElectricResponseHeaders)\n      if (url.searchParams.get(LIVE_QUERY_PARAM) === `true`) {\n        addMissingHeaders(requiredLiveResponseHeaders)\n      }\n\n      if (\n        !url.searchParams.has(LIVE_QUERY_PARAM) ||\n        url.searchParams.get(LIVE_QUERY_PARAM) === `false`\n      ) {\n        addMissingHeaders(requiredNonLiveResponseHeaders)\n      }\n\n      if (missingHeaders.length > 0) {\n        throw new MissingHeadersError(urlString, missingHeaders)\n      }\n    }\n\n    return response\n  }\n}\n\nclass PrefetchQueue {\n  readonly #fetchClient: typeof fetch\n  readonly #maxPrefetchedRequests: number\n  readonly #prefetchQueue = new Map<\n    string,\n    [Promise<Response>, AbortController]\n  >()\n  #queueHeadUrl: string | void\n  #queueTailUrl: string | void\n\n  constructor(options: {\n    url: Parameters<typeof fetch>[0]\n    requestInit: Parameters<typeof fetch>[1]\n    maxPrefetchedRequests: number\n    fetchClient?: typeof fetch\n  }) {\n    this.#fetchClient =\n      options.fetchClient ??\n      ((...args: Parameters<typeof fetch>) => fetch(...args))\n    this.#maxPrefetchedRequests = options.maxPrefetchedRequests\n    this.#queueHeadUrl = options.url.toString()\n    this.#queueTailUrl = this.#queueHeadUrl\n    this.#prefetch(options.url, options.requestInit)\n  }\n\n  abort(): void {\n    this.#prefetchQueue.forEach(([_, aborter]) => aborter.abort())\n    this.#prefetchQueue.clear()\n  }\n\n  consume(...args: Parameters<typeof fetch>): Promise<Response> | void {\n    const url = args[0].toString()\n\n    const entry = this.#prefetchQueue.get(url)\n    // only consume if request is in queue and is the queue \"head\"\n    // if request is in the queue but not the head, the queue is being\n    // consumed out of order and should be restarted\n    if (!entry || url !== this.#queueHeadUrl) return\n\n    const [request, aborter] = entry\n    // Don't return aborted requests - they will reject with AbortError\n    if (aborter.signal.aborted) {\n      this.#prefetchQueue.delete(url)\n      return\n    }\n    this.#prefetchQueue.delete(url)\n\n    // fire off new prefetch since request has been consumed\n    request\n      .then((response) => {\n        const nextUrl = getNextChunkUrl(url, response)\n        this.#queueHeadUrl = nextUrl\n        if (\n          this.#queueTailUrl &&\n          !this.#prefetchQueue.has(this.#queueTailUrl)\n        ) {\n          this.#prefetch(this.#queueTailUrl, args[1])\n        }\n      })\n      .catch(() => {})\n\n    return request\n  }\n\n  #prefetch(...args: Parameters<typeof fetch>): void {\n    const url = args[0].toString()\n\n    // only prefetch when queue is not full\n    if (this.#prefetchQueue.size >= this.#maxPrefetchedRequests) return\n\n    // initialize aborter per request, to avoid aborting consumed requests that\n    // are still streaming their bodies to the consumer\n    const aborter = new AbortController()\n\n    try {\n      const { signal, cleanup } = chainAborter(aborter, args[1]?.signal)\n      const request = this.#fetchClient(url, { ...(args[1] ?? {}), signal })\n      this.#prefetchQueue.set(url, [request, aborter])\n      request\n        .then((response) => {\n          // only keep prefetching if response chain is uninterrupted\n          if (!response.ok || aborter.signal.aborted) return\n\n          const nextUrl = getNextChunkUrl(url, response)\n\n          // only prefetch when there is a next URL\n          if (!nextUrl || nextUrl === url) {\n            this.#queueTailUrl = undefined\n            return\n          }\n\n          this.#queueTailUrl = nextUrl\n          return this.#prefetch(nextUrl, args[1])\n        })\n        .catch(() => {})\n        .finally(cleanup)\n    } catch (_) {\n      // ignore prefetch errors\n    }\n  }\n}\n\n/**\n * Generate the next chunk's URL if the url and response are valid\n */\nfunction getNextChunkUrl(url: string, res: Response): string | void {\n  const shapeHandle = res.headers.get(SHAPE_HANDLE_HEADER)\n  const lastOffset = res.headers.get(CHUNK_LAST_OFFSET_HEADER)\n  const isUpToDate = res.headers.has(CHUNK_UP_TO_DATE_HEADER)\n\n  // only prefetch if shape handle and offset for next chunk are available, and\n  // response is not already up-to-date\n  if (!shapeHandle || !lastOffset || isUpToDate) return\n\n  const nextUrl = new URL(url)\n\n  // don't prefetch live requests, rushing them will only\n  // potentially miss more recent data\n  if (nextUrl.searchParams.has(LIVE_QUERY_PARAM)) return\n\n  // don't prefetch if the response handle is the expired handle from the request\n  // this can happen when a proxy serves a stale cached response despite the\n  // expired_handle cache buster parameter\n  const expiredHandle = nextUrl.searchParams.get(EXPIRED_HANDLE_QUERY_PARAM)\n  if (expiredHandle && shapeHandle === expiredHandle) {\n    console.warn(\n      `[Electric] Received stale cached response with expired shape handle. ` +\n        `This should not happen and indicates a proxy/CDN caching misconfiguration. ` +\n        `The response contained handle \"${shapeHandle}\" which was previously marked as expired. ` +\n        `Check that your proxy includes all query parameters (especially 'handle' and 'offset') in its cache key. ` +\n        `Skipping prefetch to prevent infinite 409 loop.`\n    )\n    return\n  }\n\n  nextUrl.searchParams.set(SHAPE_HANDLE_QUERY_PARAM, shapeHandle)\n  nextUrl.searchParams.set(OFFSET_QUERY_PARAM, lastOffset)\n  nextUrl.searchParams.sort()\n  return nextUrl.toString()\n}\n\n/**\n * Chains an abort controller on an optional source signal's\n * aborted state - if the source signal is aborted, the provided abort\n * controller will also abort\n */\nfunction chainAborter(\n  aborter: AbortController,\n  sourceSignal?: AbortSignal | null\n): {\n  signal: AbortSignal\n  cleanup: () => void\n} {\n  let cleanup = noop\n  if (!sourceSignal) {\n    // no-op, nothing to chain to\n  } else if (sourceSignal.aborted) {\n    // source signal is already aborted, abort immediately\n    aborter.abort()\n  } else {\n    // chain to source signal abort event, and add callback to unlink\n    // the aborter to avoid memory leaks\n    const abortParent = () => aborter.abort()\n    sourceSignal.addEventListener(`abort`, abortParent, {\n      once: true,\n      signal: aborter.signal,\n    })\n    cleanup = () => sourceSignal.removeEventListener(`abort`, abortParent)\n  }\n\n  return {\n    signal: aborter.signal,\n    cleanup,\n  }\n}\n\nfunction noop() {}\n", "import { SerializedExpression, SerializedOrderByClause } from './types'\nimport { quoteIdentifier } from './column-mapper'\n\n/**\n * Compiles a serialized expression into a SQL string.\n * Applies columnMapper transformations to column references.\n *\n * @param expr - The serialized expression to compile\n * @param columnMapper - Optional function to transform column names (e.g., camelCase to snake_case)\n * @returns The compiled SQL string\n *\n * @example\n * ```typescript\n * const expr = { type: 'ref', column: 'userId' }\n * compileExpression(expr, camelToSnake) // '\"user_id\"'\n * ```\n */\nexport function compileExpression(\n  expr: SerializedExpression,\n  columnMapper?: (col: string) => string\n): string {\n  switch (expr.type) {\n    case `ref`: {\n      // Apply columnMapper, then quote\n      const mappedColumn = columnMapper\n        ? columnMapper(expr.column)\n        : expr.column\n      return quoteIdentifier(mappedColumn)\n    }\n    case `val`:\n      return `$${expr.paramIndex}`\n    case `func`:\n      return compileFunction(expr, columnMapper)\n    default: {\n      // TypeScript exhaustiveness check\n      const _exhaustive: never = expr\n      throw new Error(`Unknown expression type: ${JSON.stringify(_exhaustive)}`)\n    }\n  }\n}\n\n/**\n * Compiles a function expression into SQL.\n */\nfunction compileFunction(\n  expr: { type: `func`; name: string; args: SerializedExpression[] },\n  columnMapper?: (col: string) => string\n): string {\n  const args = expr.args.map((arg) => compileExpression(arg, columnMapper))\n\n  switch (expr.name) {\n    // Binary comparison operators\n    case `eq`:\n      return `${args[0]} = ${args[1]}`\n    case `gt`:\n      return `${args[0]} > ${args[1]}`\n    case `gte`:\n      return `${args[0]} >= ${args[1]}`\n    case `lt`:\n      return `${args[0]} < ${args[1]}`\n    case `lte`:\n      return `${args[0]} <= ${args[1]}`\n\n    // Logical operators\n    case `and`:\n      return args.map((a) => `(${a})`).join(` AND `)\n    case `or`:\n      return args.map((a) => `(${a})`).join(` OR `)\n    case `not`:\n      return `NOT (${args[0]})`\n\n    // Special operators\n    case `in`:\n      return `${args[0]} = ANY(${args[1]})`\n    case `like`:\n      return `${args[0]} LIKE ${args[1]}`\n    case `ilike`:\n      return `${args[0]} ILIKE ${args[1]}`\n    case `isNull`:\n    case `isUndefined`:\n      return `${args[0]} IS NULL`\n\n    // String functions\n    case `upper`:\n      return `UPPER(${args[0]})`\n    case `lower`:\n      return `LOWER(${args[0]})`\n    case `length`:\n      return `LENGTH(${args[0]})`\n    case `concat`:\n      return `CONCAT(${args.join(`, `)})`\n\n    // Other functions\n    case `coalesce`:\n      return `COALESCE(${args.join(`, `)})`\n\n    default:\n      throw new Error(`Unknown function: ${expr.name}`)\n  }\n}\n\n/**\n * Compiles serialized ORDER BY clauses into a SQL string.\n * Applies columnMapper transformations to column references.\n *\n * @param clauses - The serialized ORDER BY clauses to compile\n * @param columnMapper - Optional function to transform column names\n * @returns The compiled SQL ORDER BY string\n *\n * @example\n * ```typescript\n * const clauses = [{ column: 'createdAt', direction: 'desc', nulls: 'first' }]\n * compileOrderBy(clauses, camelToSnake) // '\"created_at\" DESC NULLS FIRST'\n * ```\n */\nexport function compileOrderBy(\n  clauses: SerializedOrderByClause[],\n  columnMapper?: (col: string) => string\n): string {\n  return clauses\n    .map((clause) => {\n      const mappedColumn = columnMapper\n        ? columnMapper(clause.column)\n        : clause.column\n      let sql = quoteIdentifier(mappedColumn)\n      if (clause.direction === `desc`) sql += ` DESC`\n      if (clause.nulls === `first`) sql += ` NULLS FIRST`\n      if (clause.nulls === `last`) sql += ` NULLS LAST`\n      return sql\n    })\n    .join(`, `)\n}\n", "import {\n  Message,\n  Offset,\n  Schema,\n  Row,\n  MaybePromise,\n  GetExtensions,\n  ChangeMessage,\n  SnapshotMetadata,\n  SubsetParams,\n} from './types'\nimport { MessageParser, Parser, TransformFunction } from './parser'\nimport {\n  ColumnMapper,\n  encodeWhereClause,\n  quoteIdentifier,\n} from './column-mapper'\nimport { getOffset, isUpToDateMessage, isChangeMessage } from './helpers'\nimport {\n  FetchError,\n  FetchBackoffAbortError,\n  MissingShapeUrlError,\n  InvalidSignalError,\n  MissingShapeHandleError,\n  ReservedParamError,\n  MissingHeadersError,\n} from './error'\nimport {\n  BackoffDefaults,\n  BackoffOptions,\n  createFetchWithBackoff,\n  createFetchWithChunkBuffer,\n  createFetchWithConsumedMessages,\n  createFetchWithResponseHeadersCheck,\n} from './fetch'\nimport {\n  CHUNK_LAST_OFFSET_HEADER,\n  LIVE_CACHE_BUSTER_HEADER,\n  LIVE_CACHE_BUSTER_QUERY_PARAM,\n  EXPIRED_HANDLE_QUERY_PARAM,\n  COLUMNS_QUERY_PARAM,\n  LIVE_QUERY_PARAM,\n  OFFSET_QUERY_PARAM,\n  SHAPE_HANDLE_HEADER,\n  SHAPE_HANDLE_QUERY_PARAM,\n  SHAPE_SCHEMA_HEADER,\n  WHERE_QUERY_PARAM,\n  WHERE_PARAMS_PARAM,\n  TABLE_QUERY_PARAM,\n  REPLICA_PARAM,\n  FORCE_DISCONNECT_AND_REFRESH,\n  PAUSE_STREAM,\n  EXPERIMENTAL_LIVE_SSE_QUERY_PARAM,\n  LIVE_SSE_QUERY_PARAM,\n  ELECTRIC_PROTOCOL_QUERY_PARAMS,\n  LOG_MODE_QUERY_PARAM,\n  SUBSET_PARAM_WHERE,\n  SUBSET_PARAM_WHERE_PARAMS,\n  SUBSET_PARAM_LIMIT,\n  SUBSET_PARAM_OFFSET,\n  SUBSET_PARAM_ORDER_BY,\n  SUBSET_PARAM_WHERE_EXPR,\n  SUBSET_PARAM_ORDER_BY_EXPR,\n} from './constants'\nimport { compileExpression, compileOrderBy } from './expression-compiler'\nimport {\n  EventSourceMessage,\n  fetchEventSource,\n} from '@microsoft/fetch-event-source'\nimport { expiredShapesCache } from './expired-shapes-cache'\nimport { upToDateTracker } from './up-to-date-tracker'\nimport { SnapshotTracker } from './snapshot-tracker'\n\nconst RESERVED_PARAMS: Set<ReservedParamKeys> = new Set([\n  LIVE_CACHE_BUSTER_QUERY_PARAM,\n  SHAPE_HANDLE_QUERY_PARAM,\n  LIVE_QUERY_PARAM,\n  OFFSET_QUERY_PARAM,\n])\n\ntype Replica = `full` | `default`\nexport type LogMode = `changes_only` | `full`\n\n/**\n * PostgreSQL-specific shape parameters that can be provided externally\n */\nexport interface PostgresParams<T extends Row<unknown> = Row> {\n  /** The root table for the shape. Not required if you set the table in your proxy. */\n  table?: string\n\n  /**\n   * The columns to include in the shape.\n   * Must include primary keys, and can only include valid columns.\n   * Defaults to all columns of the type `T`. If provided, must include primary keys, and can only include valid columns.\n\n   */\n  columns?: (keyof T)[]\n\n  /** The where clauses for the shape */\n  where?: string\n\n  /**\n   * Positional where clause paramater values. These will be passed to the server\n   * and will substitute `$i` parameters in the where clause.\n   *\n   * It can be an array (note that positional arguments start at 1, the array will be mapped\n   * accordingly), or an object with keys matching the used positional parameters in the where clause.\n   *\n   * If where clause is `id = $1 or id = $2`, params must have keys `\"1\"` and `\"2\"`, or be an array with length 2.\n   */\n  params?: Record<`${number}`, string> | string[]\n\n  /**\n   * If `replica` is `default` (the default) then Electric will only send the\n   * changed columns in an update.\n   *\n   * If it's `full` Electric will send the entire row with both changed and\n   * unchanged values. `old_value` will also be present on update messages,\n   * containing the previous value for changed columns.\n   *\n   * Setting `replica` to `full` will result in higher bandwidth\n   * usage and so is not generally recommended.\n   */\n  replica?: Replica\n}\ntype SerializableParamValue = string | string[] | Record<string, string>\ntype ParamValue =\n  | SerializableParamValue\n  | (() => SerializableParamValue | Promise<SerializableParamValue>)\n\n/**\n * External params type - what users provide.\n * Excludes reserved parameters to prevent dynamic variations that could cause stream shape changes.\n */\nexport type ExternalParamsRecord<T extends Row<unknown> = Row> = {\n  [K in string]: ParamValue | undefined\n} & Partial<PostgresParams<T>> & { [K in ReservedParamKeys]?: never }\n\ntype ReservedParamKeys =\n  | typeof LIVE_CACHE_BUSTER_QUERY_PARAM\n  | typeof SHAPE_HANDLE_QUERY_PARAM\n  | typeof LIVE_QUERY_PARAM\n  | typeof OFFSET_QUERY_PARAM\n  | `subset__${string}`\n\n/**\n * External headers type - what users provide.\n * Allows string or function values for any header.\n */\nexport type ExternalHeadersRecord = {\n  [key: string]: string | (() => string | Promise<string>)\n}\n\n/**\n * Internal params type - used within the library.\n * All values are converted to strings.\n */\ntype InternalParamsRecord = {\n  [K in string as K extends ReservedParamKeys ? never : K]:\n    | string\n    | Record<string, string>\n}\n\n/**\n * Helper function to resolve a function or value to its final value\n */\nexport async function resolveValue<T>(\n  value: T | (() => T | Promise<T>)\n): Promise<T> {\n  if (typeof value === `function`) {\n    return (value as () => T | Promise<T>)()\n  }\n  return value\n}\n\n/**\n * Helper function to convert external params to internal format\n */\nasync function toInternalParams(\n  params: ExternalParamsRecord<Row>\n): Promise<InternalParamsRecord> {\n  const entries = Object.entries(params)\n  const resolvedEntries = await Promise.all(\n    entries.map(async ([key, value]) => {\n      if (value === undefined) return [key, undefined]\n      const resolvedValue = await resolveValue(value)\n      return [\n        key,\n        Array.isArray(resolvedValue) ? resolvedValue.join(`,`) : resolvedValue,\n      ]\n    })\n  )\n\n  return Object.fromEntries(\n    resolvedEntries.filter(([_, value]) => value !== undefined)\n  )\n}\n\n/**\n * Helper function to resolve headers\n */\nasync function resolveHeaders(\n  headers?: ExternalHeadersRecord\n): Promise<Record<string, string>> {\n  if (!headers) return {}\n\n  const entries = Object.entries(headers)\n  const resolvedEntries = await Promise.all(\n    entries.map(async ([key, value]) => [key, await resolveValue(value)])\n  )\n\n  return Object.fromEntries(resolvedEntries)\n}\n\ntype RetryOpts = {\n  params?: ExternalParamsRecord\n  headers?: ExternalHeadersRecord\n}\n\ntype ShapeStreamErrorHandler = (\n  error: Error\n) => void | RetryOpts | Promise<void | RetryOpts>\n\n/**\n * Options for constructing a ShapeStream.\n */\nexport interface ShapeStreamOptions<T = never> {\n  /**\n   * The full URL to where the Shape is served. This can either be the Electric server\n   * directly or a proxy. E.g. for a local Electric instance, you might set `http://localhost:3000/v1/shape`\n   */\n  url: string\n\n  /**\n   * The \"offset\" on the shape log. This is typically not set as the ShapeStream\n   * will handle this automatically. A common scenario where you might pass an offset\n   * is if you're maintaining a local cache of the log. If you've gone offline\n   * and are re-starting a ShapeStream to catch-up to the latest state of the Shape,\n   * you'd pass in the last offset and shapeHandle you'd seen from the Electric server\n   * so it knows at what point in the shape to catch you up from.\n   */\n  offset?: Offset\n\n  /**\n   * Similar to `offset`, this isn't typically used unless you're maintaining\n   * a cache of the shape log.\n   */\n  handle?: string\n\n  /**\n   * HTTP headers to attach to requests made by the client.\n   * Values can be strings or functions (sync or async) that return strings.\n   * Function values are resolved in parallel when needed, making this useful\n   * for authentication tokens or other dynamic headers.\n   */\n  headers?: ExternalHeadersRecord\n\n  /**\n   * Additional request parameters to attach to the URL.\n   * Values can be strings, string arrays, or functions (sync or async) that return these types.\n   * Function values are resolved in parallel when needed, making this useful\n   * for user-specific parameters or dynamic filters.\n   *\n   * These will be merged with Electric's standard parameters.\n   * Note: You cannot use Electric's reserved parameter names\n   * (offset, handle, live, cursor).\n   *\n   * PostgreSQL-specific options like table, where, columns, and replica\n   * should be specified here.\n   */\n  params?: ExternalParamsRecord\n\n  /**\n   * Automatically fetch updates to the Shape. If you just want to sync the current\n   * shape and stop, pass false.\n   */\n  subscribe?: boolean\n\n  /**\n   * @deprecated No longer experimental, use {@link liveSse} instead.\n   */\n  experimentalLiveSse?: boolean\n\n  /**\n   * Use Server-Sent Events (SSE) for live updates.\n   */\n  liveSse?: boolean\n\n  /**\n   * Initial data loading mode\n   */\n  log?: LogMode\n\n  signal?: AbortSignal\n  fetchClient?: typeof fetch\n  backoffOptions?: BackoffOptions\n  parser?: Parser<T>\n\n  /**\n   * Function to transform rows after parsing (e.g., for encryption, type coercion).\n   * Applied to data received from Electric.\n   *\n   * **Note**: If you're using `transformer` solely for column name transformation\n   * (e.g., snake_case → camelCase), consider using `columnMapper` instead, which\n   * provides bidirectional transformation and automatically encodes WHERE clauses.\n   *\n   * **Execution order** when both are provided:\n   * 1. `columnMapper.decode` runs first (renames columns)\n   * 2. `transformer` runs second (transforms values)\n   *\n   * @example\n   * ```typescript\n   * // For column renaming only - use columnMapper\n   * import { snakeCamelMapper } from '@electric-sql/client'\n   * const stream = new ShapeStream({ columnMapper: snakeCamelMapper() })\n   * ```\n   *\n   * @example\n   * ```typescript\n   * // For value transformation (encryption, etc.) - use transformer\n   * const stream = new ShapeStream({\n   *   transformer: (row) => ({\n   *     ...row,\n   *     encrypted_field: decrypt(row.encrypted_field)\n   *   })\n   * })\n   * ```\n   *\n   * @example\n   * ```typescript\n   * // Use both together\n   * const stream = new ShapeStream({\n   *   columnMapper: snakeCamelMapper(), // Runs first: renames columns\n   *   transformer: (row) => ({         // Runs second: transforms values\n   *     ...row,\n   *     encryptedData: decrypt(row.encryptedData)\n   *   })\n   * })\n   * ```\n   */\n  transformer?: TransformFunction<T>\n\n  /**\n   * Bidirectional column name mapper for transforming between database column names\n   * (e.g., snake_case) and application column names (e.g., camelCase).\n   *\n   * The mapper handles both:\n   * - **Decoding**: Database → Application (applied to query results)\n   * - **Encoding**: Application → Database (applied to WHERE clauses)\n   *\n   * @example\n   * ```typescript\n   * // Most common case: snake_case ↔ camelCase\n   * import { snakeCamelMapper } from '@electric-sql/client'\n   *\n   * const stream = new ShapeStream({\n   *   url: 'http://localhost:3000/v1/shape',\n   *   params: { table: 'todos' },\n   *   columnMapper: snakeCamelMapper()\n   * })\n   * ```\n   *\n   * @example\n   * ```typescript\n   * // Custom mapping\n   * import { createColumnMapper } from '@electric-sql/client'\n   *\n   * const stream = new ShapeStream({\n   *   columnMapper: createColumnMapper({\n   *     user_id: 'userId',\n   *     project_id: 'projectId',\n   *     created_at: 'createdAt'\n   *   })\n   * })\n   * ```\n   */\n  columnMapper?: ColumnMapper\n\n  /**\n   * A function for handling shapestream errors.\n   *\n   * **Automatic retries**: The client automatically retries 5xx server errors, network\n   * errors, and 429 rate limits with exponential backoff. The `onError` callback is\n   * only invoked after these automatic retries are exhausted, or for non-retryable\n   * errors like 4xx client errors.\n   *\n   * When not provided, non-retryable errors will be thrown and syncing will stop.\n   *\n   * **Return value behavior**:\n   * - Return an **object** (RetryOpts or empty `{}`) to retry syncing:\n   *   - `{}` - Retry with the same params and headers\n   *   - `{ params }` - Retry with modified params\n   *   - `{ headers }` - Retry with modified headers (e.g., refreshed auth token)\n   *   - `{ params, headers }` - Retry with both modified\n   * - Return **void** or **undefined** to stop the stream permanently\n   *\n   * **Important**: If you want syncing to continue after an error (e.g., to retry\n   * on network failures), you MUST return at least an empty object `{}`. Simply\n   * logging the error and returning nothing will stop syncing.\n   *\n   * Supports async functions that return `Promise<void | RetryOpts>`.\n   *\n   * @example\n   * ```typescript\n   * // Retry on network errors, stop on others\n   * onError: (error) => {\n   *   console.error('Stream error:', error)\n   *   if (error instanceof FetchError && error.status >= 500) {\n   *     return {} // Retry with same params\n   *   }\n   *   // Return void to stop on other errors\n   * }\n   * ```\n   *\n   * @example\n   * ```typescript\n   * // Refresh auth token on 401\n   * onError: async (error) => {\n   *   if (error instanceof FetchError && error.status === 401) {\n   *     const newToken = await refreshAuthToken()\n   *     return { headers: { Authorization: `Bearer ${newToken}` } }\n   *   }\n   *   return {} // Retry other errors\n   * }\n   * ```\n   */\n  onError?: ShapeStreamErrorHandler\n}\n\nexport interface ShapeStreamInterface<T extends Row<unknown> = Row> {\n  subscribe(\n    callback: (\n      messages: Message<T>[]\n    ) => MaybePromise<void> | { columns?: (keyof T)[] },\n    onError?: (error: FetchError | Error) => void\n  ): () => void\n  unsubscribeAll(): void\n\n  isLoading(): boolean\n  lastSyncedAt(): number | undefined\n  lastSynced(): number\n  isConnected(): boolean\n  hasStarted(): boolean\n\n  isUpToDate: boolean\n  lastOffset: Offset\n  shapeHandle?: string\n  error?: unknown\n  mode: LogMode\n\n  forceDisconnectAndRefresh(): Promise<void>\n\n  requestSnapshot(params: SubsetParams): Promise<{\n    metadata: SnapshotMetadata\n    data: Array<Message<T>>\n  }>\n\n  fetchSnapshot(opts: SubsetParams): Promise<{\n    metadata: SnapshotMetadata\n    data: Array<ChangeMessage<T>>\n  }>\n}\n\n/**\n * Creates a canonical shape key from a URL excluding only Electric protocol parameters\n */\nfunction canonicalShapeKey(url: URL): string {\n  const cleanUrl = new URL(url.origin + url.pathname)\n\n  // Copy all params except Electric protocol ones that vary between requests\n  for (const [key, value] of url.searchParams) {\n    if (!ELECTRIC_PROTOCOL_QUERY_PARAMS.includes(key)) {\n      cleanUrl.searchParams.set(key, value)\n    }\n  }\n\n  cleanUrl.searchParams.sort()\n  return cleanUrl.toString()\n}\n\n/**\n * Reads updates to a shape from Electric using HTTP requests and long polling or\n * Server-Sent Events (SSE).\n * Notifies subscribers when new messages come in. Doesn't maintain any history of the\n * log but does keep track of the offset position and is the best way\n * to consume the HTTP `GET /v1/shape` api.\n *\n * @constructor\n * @param {ShapeStreamOptions} options - configure the shape stream\n * @example\n * Register a callback function to subscribe to the messages.\n * ```\n * const stream = new ShapeStream(options)\n * stream.subscribe(messages => {\n *   // messages is 1 or more row updates\n * })\n * ```\n *\n * To use Server-Sent Events (SSE) for real-time updates:\n * ```\n * const stream = new ShapeStream({\n *   url: `http://localhost:3000/v1/shape`,\n *   liveSse: true\n * })\n * ```\n *\n * To abort the stream, abort the `signal`\n * passed in via the `ShapeStreamOptions`.\n * ```\n * const aborter = new AbortController()\n * const issueStream = new ShapeStream({\n *   url: `${BASE_URL}/${table}`\n *   subscribe: true,\n *   signal: aborter.signal,\n * })\n * // Later...\n * aborter.abort()\n * ```\n */\n\nexport class ShapeStream<T extends Row<unknown> = Row>\n  implements ShapeStreamInterface<T>\n{\n  static readonly Replica = {\n    FULL: `full` as Replica,\n    DEFAULT: `default` as Replica,\n  }\n\n  readonly options: ShapeStreamOptions<GetExtensions<T>>\n  #error: unknown = null\n\n  readonly #fetchClient: typeof fetch\n  readonly #sseFetchClient: typeof fetch\n  readonly #messageParser: MessageParser<T>\n\n  readonly #subscribers = new Map<\n    number,\n    [\n      (messages: Message<T>[]) => MaybePromise<void>,\n      ((error: Error) => void) | undefined,\n    ]\n  >()\n\n  #started = false\n  #state = `active` as `active` | `pause-requested` | `paused`\n  #lastOffset: Offset\n  #liveCacheBuster: string // Seconds since our Electric Epoch 😎\n  #lastSyncedAt?: number // unix time\n  #isUpToDate: boolean = false\n  #isMidStream: boolean = true\n  #connected: boolean = false\n  #shapeHandle?: string\n  #mode: LogMode\n  #schema?: Schema\n  #onError?: ShapeStreamErrorHandler\n  #requestAbortController?: AbortController\n  #isRefreshing = false\n  #tickPromise?: Promise<void>\n  #tickPromiseResolver?: () => void\n  #tickPromiseRejecter?: (reason?: unknown) => void\n  #messageChain = Promise.resolve<void[]>([]) // promise chain for incoming messages\n  #snapshotTracker = new SnapshotTracker()\n  #activeSnapshotRequests = 0 // counter for concurrent snapshot requests\n  #midStreamPromise?: Promise<void>\n  #midStreamPromiseResolver?: () => void\n  #lastSeenCursor?: string // Last seen cursor from previous session (used to detect cached responses)\n  #currentFetchUrl?: URL // Current fetch URL for computing shape key\n  #lastSseConnectionStartTime?: number\n  #minSseConnectionDuration = 1000 // Minimum expected SSE connection duration (1 second)\n  #consecutiveShortSseConnections = 0\n  #maxShortSseConnections = 3 // Fall back to long polling after this many short connections\n  #sseFallbackToLongPolling = false\n  #sseBackoffBaseDelay = 100 // Base delay for exponential backoff (ms)\n  #sseBackoffMaxDelay = 5000 // Maximum delay cap (ms)\n  #unsubscribeFromVisibilityChanges?: () => void\n\n  // Derived state: we're in replay mode if we have a last seen cursor\n  get #replayMode(): boolean {\n    return this.#lastSeenCursor !== undefined\n  }\n\n  constructor(options: ShapeStreamOptions<GetExtensions<T>>) {\n    this.options = { subscribe: true, ...options }\n    validateOptions(this.options)\n    this.#lastOffset = this.options.offset ?? `-1`\n    this.#liveCacheBuster = ``\n    this.#shapeHandle = this.options.handle\n\n    // Build transformer chain: columnMapper.decode -> transformer\n    // columnMapper transforms column names, transformer transforms values\n    let transformer: TransformFunction<GetExtensions<T>> | undefined\n\n    if (options.columnMapper) {\n      const applyColumnMapper = (\n        row: Row<GetExtensions<T>>\n      ): Row<GetExtensions<T>> => {\n        const result: Record<string, unknown> = {}\n        for (const [dbKey, value] of Object.entries(row)) {\n          const appKey = options.columnMapper!.decode(dbKey)\n          result[appKey] = value\n        }\n        return result as Row<GetExtensions<T>>\n      }\n\n      transformer = options.transformer\n        ? (row: Row<GetExtensions<T>>) =>\n            options.transformer!(applyColumnMapper(row))\n        : applyColumnMapper\n    } else {\n      transformer = options.transformer\n    }\n\n    this.#messageParser = new MessageParser<T>(options.parser, transformer)\n\n    this.#onError = this.options.onError\n    this.#mode = this.options.log ?? `full`\n\n    const baseFetchClient =\n      options.fetchClient ??\n      ((...args: Parameters<typeof fetch>) => fetch(...args))\n\n    const backOffOpts = {\n      ...(options.backoffOptions ?? BackoffDefaults),\n      onFailedAttempt: () => {\n        this.#connected = false\n        options.backoffOptions?.onFailedAttempt?.()\n      },\n    }\n    const fetchWithBackoffClient = createFetchWithBackoff(\n      baseFetchClient,\n      backOffOpts\n    )\n\n    this.#sseFetchClient = createFetchWithResponseHeadersCheck(\n      createFetchWithChunkBuffer(fetchWithBackoffClient)\n    )\n\n    this.#fetchClient = createFetchWithConsumedMessages(this.#sseFetchClient)\n\n    this.#subscribeToVisibilityChanges()\n  }\n\n  get shapeHandle() {\n    return this.#shapeHandle\n  }\n\n  get error() {\n    return this.#error\n  }\n\n  get isUpToDate() {\n    return this.#isUpToDate\n  }\n\n  get lastOffset() {\n    return this.#lastOffset\n  }\n\n  get mode() {\n    return this.#mode\n  }\n\n  async #start(): Promise<void> {\n    this.#started = true\n\n    try {\n      await this.#requestShape()\n    } catch (err) {\n      this.#error = err\n\n      // Check if onError handler wants to retry\n      if (this.#onError) {\n        const retryOpts = await this.#onError(err as Error)\n        // Guard against null (typeof null === \"object\" in JavaScript)\n        if (retryOpts && typeof retryOpts === `object`) {\n          // Update params/headers but don't reset offset\n          // We want to continue from where we left off, not refetch everything\n          if (retryOpts.params) {\n            // Merge new params with existing params to preserve other parameters\n            this.options.params = {\n              ...(this.options.params ?? {}),\n              ...retryOpts.params,\n            }\n          }\n\n          if (retryOpts.headers) {\n            // Merge new headers with existing headers to preserve other headers\n            this.options.headers = {\n              ...(this.options.headers ?? {}),\n              ...retryOpts.headers,\n            }\n          }\n\n          // Clear the error since we're retrying\n          this.#error = null\n\n          // Restart from current offset\n          this.#started = false\n          await this.#start()\n          return\n        }\n        // onError returned void, meaning it doesn't want to retry\n        // This is an unrecoverable error, notify subscribers\n        if (err instanceof Error) {\n          this.#sendErrorToSubscribers(err)\n        }\n        this.#connected = false\n        this.#tickPromiseRejecter?.()\n        return\n      }\n\n      // No onError handler provided, this is an unrecoverable error\n      // Notify subscribers and throw\n      if (err instanceof Error) {\n        this.#sendErrorToSubscribers(err)\n      }\n      this.#connected = false\n      this.#tickPromiseRejecter?.()\n      throw err\n    }\n\n    // Normal completion, clean up\n    this.#connected = false\n    this.#tickPromiseRejecter?.()\n  }\n\n  async #requestShape(): Promise<void> {\n    if (this.#state === `pause-requested`) {\n      this.#state = `paused`\n      return\n    }\n\n    if (\n      !this.options.subscribe &&\n      (this.options.signal?.aborted || this.#isUpToDate)\n    ) {\n      return\n    }\n\n    const resumingFromPause = this.#state === `paused`\n    this.#state = `active`\n\n    const { url, signal } = this.options\n    const { fetchUrl, requestHeaders } = await this.#constructUrl(\n      url,\n      resumingFromPause\n    )\n    const abortListener = await this.#createAbortListener(signal)\n    const requestAbortController = this.#requestAbortController! // we know that it is not undefined because it is set by `this.#createAbortListener`\n\n    try {\n      await this.#fetchShape({\n        fetchUrl,\n        requestAbortController,\n        headers: requestHeaders,\n        resumingFromPause,\n      })\n    } catch (e) {\n      // Handle abort error triggered by refresh\n      if (\n        (e instanceof FetchError || e instanceof FetchBackoffAbortError) &&\n        requestAbortController.signal.aborted &&\n        requestAbortController.signal.reason === FORCE_DISCONNECT_AND_REFRESH\n      ) {\n        // Start a new request\n        return this.#requestShape()\n      }\n\n      if (e instanceof FetchBackoffAbortError) {\n        // Check current state - it may have changed due to concurrent pause/resume calls\n        // from the visibility change handler during the async fetch operation.\n        // TypeScript's flow analysis doesn't account for concurrent state changes.\n        const currentState = this.#state as\n          | `active`\n          | `pause-requested`\n          | `paused`\n        if (\n          requestAbortController.signal.aborted &&\n          requestAbortController.signal.reason === PAUSE_STREAM &&\n          currentState === `pause-requested`\n        ) {\n          this.#state = `paused`\n        }\n        return // interrupted\n      }\n      if (!(e instanceof FetchError)) throw e // should never happen\n\n      if (e.status == 409) {\n        // Upon receiving a 409, we should start from scratch\n        // with the newly provided shape handle, or a fallback\n        // pseudo-handle based on the current one to act as a\n        // consistent cache buster\n\n        // Store the current shape URL as expired to avoid future 409s\n        if (this.#shapeHandle) {\n          const shapeKey = canonicalShapeKey(fetchUrl)\n          expiredShapesCache.markExpired(shapeKey, this.#shapeHandle)\n        }\n\n        const newShapeHandle =\n          e.headers[SHAPE_HANDLE_HEADER] || `${this.#shapeHandle!}-next`\n        this.#reset(newShapeHandle)\n\n        // must refetch control message might be in a list or not depending\n        // on whether it came from an SSE request or long poll - handle both\n        // cases for safety here but worth revisiting 409 handling\n        await this.#publish(\n          (Array.isArray(e.json) ? e.json : [e.json]) as Message<T>[]\n        )\n        return this.#requestShape()\n      } else {\n        // errors that have reached this point are not actionable without\n        // additional user input, such as 400s or failures to read the\n        // body of a response, so we exit the loop and let #start handle it\n        // Note: We don't notify subscribers here because onError might recover\n        throw e\n      }\n    } finally {\n      if (abortListener && signal) {\n        signal.removeEventListener(`abort`, abortListener)\n      }\n      this.#requestAbortController = undefined\n    }\n\n    this.#tickPromiseResolver?.()\n    return this.#requestShape()\n  }\n\n  async #constructUrl(\n    url: string,\n    resumingFromPause: boolean,\n    subsetParams?: SubsetParams\n  ) {\n    // Resolve headers and params in parallel\n    const [requestHeaders, params] = await Promise.all([\n      resolveHeaders(this.options.headers),\n      this.options.params\n        ? toInternalParams(convertWhereParamsToObj(this.options.params))\n        : undefined,\n    ])\n\n    // Validate params after resolution\n    if (params) validateParams(params)\n\n    const fetchUrl = new URL(url)\n\n    // Add PostgreSQL-specific parameters\n    if (params) {\n      if (params.table) setQueryParam(fetchUrl, TABLE_QUERY_PARAM, params.table)\n      if (params.where && typeof params.where === `string`) {\n        const encodedWhere = encodeWhereClause(\n          params.where,\n          this.options.columnMapper?.encode\n        )\n        setQueryParam(fetchUrl, WHERE_QUERY_PARAM, encodedWhere)\n      }\n      if (params.columns) {\n        // Get original columns array from options (before toInternalParams converted to string)\n        const originalColumns = await resolveValue(this.options.params?.columns)\n        if (Array.isArray(originalColumns)) {\n          // Apply columnMapper encoding if present\n          let encodedColumns = originalColumns.map(String)\n          if (this.options.columnMapper) {\n            encodedColumns = encodedColumns.map(\n              this.options.columnMapper.encode\n            )\n          }\n          // Quote each column name to handle special characters (commas, etc.)\n          const serializedColumns = encodedColumns\n            .map(quoteIdentifier)\n            .join(`,`)\n          setQueryParam(fetchUrl, COLUMNS_QUERY_PARAM, serializedColumns)\n        } else {\n          // Fallback: columns was already a string\n          setQueryParam(fetchUrl, COLUMNS_QUERY_PARAM, params.columns)\n        }\n      }\n      if (params.replica) setQueryParam(fetchUrl, REPLICA_PARAM, params.replica)\n      if (params.params)\n        setQueryParam(fetchUrl, WHERE_PARAMS_PARAM, params.params)\n\n      // Add any remaining custom parameters\n      const customParams = { ...params }\n      delete customParams.table\n      delete customParams.where\n      delete customParams.columns\n      delete customParams.replica\n      delete customParams.params\n\n      for (const [key, value] of Object.entries(customParams)) {\n        setQueryParam(fetchUrl, key, value)\n      }\n    }\n\n    if (subsetParams) {\n      // Prefer structured expressions when available (allows proper columnMapper application)\n      // Fall back to legacy string format for backwards compatibility\n      if (subsetParams.whereExpr) {\n        // Compile structured expression with columnMapper applied\n        const compiledWhere = compileExpression(\n          subsetParams.whereExpr,\n          this.options.columnMapper?.encode\n        )\n        setQueryParam(fetchUrl, SUBSET_PARAM_WHERE, compiledWhere)\n        // Also send the structured expression for servers that support it\n        fetchUrl.searchParams.set(\n          SUBSET_PARAM_WHERE_EXPR,\n          JSON.stringify(subsetParams.whereExpr)\n        )\n      } else if (subsetParams.where && typeof subsetParams.where === `string`) {\n        // Legacy string format (no columnMapper applied to already-compiled SQL)\n        const encodedWhere = encodeWhereClause(\n          subsetParams.where,\n          this.options.columnMapper?.encode\n        )\n        setQueryParam(fetchUrl, SUBSET_PARAM_WHERE, encodedWhere)\n      }\n\n      if (subsetParams.params)\n        // Serialize params as JSON to keep the parameter name constant for proxy configs\n        fetchUrl.searchParams.set(\n          SUBSET_PARAM_WHERE_PARAMS,\n          JSON.stringify(subsetParams.params)\n        )\n      if (subsetParams.limit)\n        setQueryParam(fetchUrl, SUBSET_PARAM_LIMIT, subsetParams.limit)\n      if (subsetParams.offset)\n        setQueryParam(fetchUrl, SUBSET_PARAM_OFFSET, subsetParams.offset)\n\n      // Prefer structured ORDER BY expressions when available\n      if (subsetParams.orderByExpr) {\n        // Compile structured ORDER BY with columnMapper applied\n        const compiledOrderBy = compileOrderBy(\n          subsetParams.orderByExpr,\n          this.options.columnMapper?.encode\n        )\n        setQueryParam(fetchUrl, SUBSET_PARAM_ORDER_BY, compiledOrderBy)\n        // Also send the structured expression for servers that support it\n        fetchUrl.searchParams.set(\n          SUBSET_PARAM_ORDER_BY_EXPR,\n          JSON.stringify(subsetParams.orderByExpr)\n        )\n      } else if (\n        subsetParams.orderBy &&\n        typeof subsetParams.orderBy === `string`\n      ) {\n        // Legacy string format\n        const encodedOrderBy = encodeWhereClause(\n          subsetParams.orderBy,\n          this.options.columnMapper?.encode\n        )\n        setQueryParam(fetchUrl, SUBSET_PARAM_ORDER_BY, encodedOrderBy)\n      }\n    }\n\n    // Add Electric's internal parameters\n    fetchUrl.searchParams.set(OFFSET_QUERY_PARAM, this.#lastOffset)\n    fetchUrl.searchParams.set(LOG_MODE_QUERY_PARAM, this.#mode)\n\n    // Snapshot requests (with subsetParams) should never use live polling\n    const isSnapshotRequest = subsetParams !== undefined\n\n    if (this.#isUpToDate && !isSnapshotRequest) {\n      // If we are resuming from a paused state, we don't want to perform a live request\n      // because it could be a long poll that holds for 20sec\n      // and during all that time `isConnected` will be false\n      if (!this.#isRefreshing && !resumingFromPause) {\n        fetchUrl.searchParams.set(LIVE_QUERY_PARAM, `true`)\n      }\n      fetchUrl.searchParams.set(\n        LIVE_CACHE_BUSTER_QUERY_PARAM,\n        this.#liveCacheBuster\n      )\n    }\n\n    if (this.#shapeHandle) {\n      // This should probably be a header for better cache breaking?\n      fetchUrl.searchParams.set(SHAPE_HANDLE_QUERY_PARAM, this.#shapeHandle!)\n    }\n\n    // Add cache buster for shapes known to be expired to prevent 409s\n    const shapeKey = canonicalShapeKey(fetchUrl)\n    const expiredHandle = expiredShapesCache.getExpiredHandle(shapeKey)\n    if (expiredHandle) {\n      fetchUrl.searchParams.set(EXPIRED_HANDLE_QUERY_PARAM, expiredHandle)\n    }\n\n    // sort query params in-place for stable URLs and improved cache hits\n    fetchUrl.searchParams.sort()\n\n    return {\n      fetchUrl,\n      requestHeaders,\n    }\n  }\n\n  async #createAbortListener(signal?: AbortSignal) {\n    // Create a new AbortController for this request\n    this.#requestAbortController = new AbortController()\n\n    // If user provided a signal, listen to it and pass on the reason for the abort\n    if (signal) {\n      const abortListener = () => {\n        this.#requestAbortController?.abort(signal.reason)\n      }\n\n      signal.addEventListener(`abort`, abortListener, { once: true })\n\n      if (signal.aborted) {\n        // If the signal is already aborted, abort the request immediately\n        this.#requestAbortController?.abort(signal.reason)\n      }\n\n      return abortListener\n    }\n  }\n\n  async #onInitialResponse(response: Response) {\n    const { headers, status } = response\n    const shapeHandle = headers.get(SHAPE_HANDLE_HEADER)\n    if (shapeHandle) {\n      // Don't accept a handle we know is expired - this can happen if a\n      // proxy serves a stale cached response despite the expired_handle\n      // cache buster parameter\n      const shapeKey = this.#currentFetchUrl\n        ? canonicalShapeKey(this.#currentFetchUrl)\n        : null\n      const expiredHandle = shapeKey\n        ? expiredShapesCache.getExpiredHandle(shapeKey)\n        : null\n      if (shapeHandle !== expiredHandle) {\n        this.#shapeHandle = shapeHandle\n      } else {\n        console.warn(\n          `[Electric] Received stale cached response with expired shape handle. ` +\n            `This should not happen and indicates a proxy/CDN caching misconfiguration. ` +\n            `The response contained handle \"${shapeHandle}\" which was previously marked as expired. ` +\n            `Check that your proxy includes all query parameters (especially 'handle' and 'offset') in its cache key. ` +\n            `Ignoring the stale handle and continuing with handle \"${this.#shapeHandle}\".`\n        )\n      }\n    }\n\n    const lastOffset = headers.get(CHUNK_LAST_OFFSET_HEADER)\n    if (lastOffset) {\n      this.#lastOffset = lastOffset as Offset\n    }\n\n    const liveCacheBuster = headers.get(LIVE_CACHE_BUSTER_HEADER)\n    if (liveCacheBuster) {\n      this.#liveCacheBuster = liveCacheBuster\n    }\n\n    this.#schema = this.#schema ?? getSchemaFromHeaders(headers)\n\n    // NOTE: 204s are deprecated, the Electric server should not\n    // send these in latest versions but this is here for backwards\n    // compatibility\n    if (status === 204) {\n      // There's no content so we are live and up to date\n      this.#lastSyncedAt = Date.now()\n    }\n  }\n\n  async #onMessages(batch: Array<Message<T>>, isSseMessage = false) {\n    // Update isUpToDate\n    if (batch.length > 0) {\n      // Set isMidStream to true when we receive any data\n      this.#isMidStream = true\n\n      const lastMessage = batch[batch.length - 1]\n      if (isUpToDateMessage(lastMessage)) {\n        if (isSseMessage) {\n          // Only use the offset from the up-to-date message if this was an SSE message.\n          // If we would use this offset from a regular fetch, then it will be wrong\n          // and we will get an \"offset is out of bounds for this shape\" error\n          const offset = getOffset(lastMessage)\n          if (offset) {\n            this.#lastOffset = offset\n          }\n        }\n        this.#lastSyncedAt = Date.now()\n        this.#isUpToDate = true\n        // Set isMidStream to false when we see an up-to-date message\n        this.#isMidStream = false\n        // Resolve the promise waiting for mid-stream to end\n        this.#midStreamPromiseResolver?.()\n\n        // Check if we should suppress this up-to-date notification\n        // to prevent multiple renders from cached responses\n        if (this.#replayMode && !isSseMessage) {\n          // We're in replay mode (replaying cached responses during initial sync).\n          // Check if the cursor has changed - cursors are time-based and always\n          // increment, so a new cursor means fresh data from the server.\n          const currentCursor = this.#liveCacheBuster\n\n          if (currentCursor === this.#lastSeenCursor) {\n            // Same cursor = still replaying cached responses\n            // Suppress this up-to-date notification\n            return\n          }\n        }\n\n        // We're either:\n        // 1. Not in replay mode (normal operation), or\n        // 2. This is a live/SSE message (always fresh), or\n        // 3. Cursor has changed (exited replay mode with fresh data)\n        // In all cases, notify subscribers and record the up-to-date.\n        this.#lastSeenCursor = undefined // Exit replay mode\n\n        if (this.#currentFetchUrl) {\n          const shapeKey = canonicalShapeKey(this.#currentFetchUrl)\n          upToDateTracker.recordUpToDate(shapeKey, this.#liveCacheBuster)\n        }\n      }\n\n      // Filter messages using snapshot tracker\n      const messagesToProcess = batch.filter((message) => {\n        if (isChangeMessage(message)) {\n          return !this.#snapshotTracker.shouldRejectMessage(message)\n        }\n        return true // Always process control messages\n      })\n\n      await this.#publish(messagesToProcess)\n    }\n  }\n\n  /**\n   * Fetches the shape from the server using either long polling or SSE.\n   * Upon receiving a successfull response, the #onInitialResponse method is called.\n   * Afterwards, the #onMessages method is called for all the incoming updates.\n   * @param opts - The options for the request.\n   * @returns A promise that resolves when the request is complete (i.e. the long poll receives a response or the SSE connection is closed).\n   */\n  async #fetchShape(opts: {\n    fetchUrl: URL\n    requestAbortController: AbortController\n    headers: Record<string, string>\n    resumingFromPause?: boolean\n  }): Promise<void> {\n    // Store current fetch URL for shape key computation\n    this.#currentFetchUrl = opts.fetchUrl\n\n    // Check if we should enter replay mode (replaying cached responses)\n    // This happens when we're starting fresh (offset=-1 or before first up-to-date)\n    // and there's a recent up-to-date in localStorage (< 60s)\n    if (!this.#isUpToDate && !this.#replayMode) {\n      const shapeKey = canonicalShapeKey(opts.fetchUrl)\n      const lastSeenCursor = upToDateTracker.shouldEnterReplayMode(shapeKey)\n      if (lastSeenCursor) {\n        // Enter replay mode and store the last seen cursor\n        this.#lastSeenCursor = lastSeenCursor\n      }\n    }\n\n    const useSse = this.options.liveSse ?? this.options.experimentalLiveSse\n    if (\n      this.#isUpToDate &&\n      useSse &&\n      !this.#isRefreshing &&\n      !opts.resumingFromPause &&\n      !this.#sseFallbackToLongPolling\n    ) {\n      opts.fetchUrl.searchParams.set(EXPERIMENTAL_LIVE_SSE_QUERY_PARAM, `true`)\n      opts.fetchUrl.searchParams.set(LIVE_SSE_QUERY_PARAM, `true`)\n      return this.#requestShapeSSE(opts)\n    }\n\n    return this.#requestShapeLongPoll(opts)\n  }\n\n  async #requestShapeLongPoll(opts: {\n    fetchUrl: URL\n    requestAbortController: AbortController\n    headers: Record<string, string>\n  }): Promise<void> {\n    const { fetchUrl, requestAbortController, headers } = opts\n    const response = await this.#fetchClient(fetchUrl.toString(), {\n      signal: requestAbortController.signal,\n      headers,\n    })\n\n    this.#connected = true\n    await this.#onInitialResponse(response)\n\n    const schema = this.#schema! // we know that it is not undefined because it is set by `this.#onInitialResponse`\n    const res = await response.text()\n    const messages = res || `[]`\n    const batch = this.#messageParser.parse<Array<Message<T>>>(messages, schema)\n\n    await this.#onMessages(batch)\n  }\n\n  async #requestShapeSSE(opts: {\n    fetchUrl: URL\n    requestAbortController: AbortController\n    headers: Record<string, string>\n  }): Promise<void> {\n    const { fetchUrl, requestAbortController, headers } = opts\n    const fetch = this.#sseFetchClient\n\n    // Track when the SSE connection starts\n    this.#lastSseConnectionStartTime = Date.now()\n\n    // Add Accept header for SSE requests\n    const sseHeaders = {\n      ...headers,\n      Accept: `text/event-stream`,\n    }\n\n    try {\n      let buffer: Array<Message<T>> = []\n      await fetchEventSource(fetchUrl.toString(), {\n        headers: sseHeaders,\n        fetch,\n        onopen: async (response: Response) => {\n          this.#connected = true\n          await this.#onInitialResponse(response)\n        },\n        onmessage: (event: EventSourceMessage) => {\n          if (event.data) {\n            // event.data is a single JSON object\n            const schema = this.#schema! // we know that it is not undefined because it is set in onopen when we call this.#onInitialResponse\n            const message = this.#messageParser.parse<Message<T>>(\n              event.data,\n              schema\n            )\n            buffer.push(message)\n\n            if (isUpToDateMessage(message)) {\n              // Flush the buffer on up-to-date message.\n              // Ensures that we only process complete batches of operations.\n              this.#onMessages(buffer, true)\n              buffer = []\n            }\n          }\n        },\n        onerror: (error: Error) => {\n          // rethrow to close the SSE connection\n          throw error\n        },\n        signal: requestAbortController.signal,\n      })\n    } catch (error) {\n      if (requestAbortController.signal.aborted) {\n        // During an SSE request, the fetch might have succeeded\n        // and we are parsing the incoming stream.\n        // If the abort happens while we're parsing the stream,\n        // then it won't be caught by our `createFetchWithBackoff` wrapper\n        // and instead we will get a raw AbortError here\n        // which we need to turn into a `FetchBackoffAbortError`\n        // such that #start handles it correctly.`\n        throw new FetchBackoffAbortError()\n      }\n      throw error\n    } finally {\n      // Check if the SSE connection closed too quickly\n      // This can happen when responses are cached or when the proxy/server\n      // is misconfigured for SSE and closes the connection immediately\n      const connectionDuration = Date.now() - this.#lastSseConnectionStartTime!\n      const wasAborted = requestAbortController.signal.aborted\n\n      if (connectionDuration < this.#minSseConnectionDuration && !wasAborted) {\n        // Connection was too short - likely a cached response or misconfiguration\n        this.#consecutiveShortSseConnections++\n\n        if (\n          this.#consecutiveShortSseConnections >= this.#maxShortSseConnections\n        ) {\n          // Too many short connections - fall back to long polling\n          this.#sseFallbackToLongPolling = true\n          console.warn(\n            `[Electric] SSE connections are closing immediately (possibly due to proxy buffering or misconfiguration). ` +\n              `Falling back to long polling. ` +\n              `Your proxy must support streaming SSE responses (not buffer the complete response). ` +\n              `Configuration: Nginx add 'X-Accel-Buffering: no', Caddy add 'flush_interval -1' to reverse_proxy. ` +\n              `Note: Do NOT disable caching entirely - Electric uses cache headers to enable request collapsing for efficiency.`\n          )\n        } else {\n          // Add exponential backoff with full jitter to prevent tight infinite loop\n          // Formula: random(0, min(cap, base * 2^attempt))\n          const maxDelay = Math.min(\n            this.#sseBackoffMaxDelay,\n            this.#sseBackoffBaseDelay *\n              Math.pow(2, this.#consecutiveShortSseConnections)\n          )\n          const delayMs = Math.floor(Math.random() * maxDelay)\n          await new Promise((resolve) => setTimeout(resolve, delayMs))\n        }\n      } else if (connectionDuration >= this.#minSseConnectionDuration) {\n        // Connection was healthy - reset counter\n        this.#consecutiveShortSseConnections = 0\n      }\n    }\n  }\n\n  #pause() {\n    if (this.#started && this.#state === `active`) {\n      this.#state = `pause-requested`\n      this.#requestAbortController?.abort(PAUSE_STREAM)\n    }\n  }\n\n  #resume() {\n    if (\n      this.#started &&\n      (this.#state === `paused` || this.#state === `pause-requested`)\n    ) {\n      // Don't resume if the user's signal is already aborted\n      // This can happen if the signal was aborted while we were paused\n      // (e.g., TanStack DB collection was GC'd)\n      if (this.options.signal?.aborted) {\n        return\n      }\n\n      // If we're resuming from pause-requested state, we need to set state back to active\n      // to prevent the pause from completing\n      if (this.#state === `pause-requested`) {\n        this.#state = `active`\n      }\n      this.#start()\n    }\n  }\n\n  subscribe(\n    callback: (messages: Message<T>[]) => MaybePromise<void>,\n    onError: (error: Error) => void = () => {}\n  ) {\n    const subscriptionId = Math.random()\n\n    this.#subscribers.set(subscriptionId, [callback, onError])\n    if (!this.#started) this.#start()\n\n    return () => {\n      this.#subscribers.delete(subscriptionId)\n    }\n  }\n\n  unsubscribeAll(): void {\n    this.#subscribers.clear()\n    this.#unsubscribeFromVisibilityChanges?.()\n  }\n\n  /** Unix time at which we last synced. Undefined when `isLoading` is true. */\n  lastSyncedAt(): number | undefined {\n    return this.#lastSyncedAt\n  }\n\n  /** Time elapsed since last sync (in ms). Infinity if we did not yet sync. */\n  lastSynced(): number {\n    if (this.#lastSyncedAt === undefined) return Infinity\n    return Date.now() - this.#lastSyncedAt\n  }\n\n  /** Indicates if we are connected to the Electric sync service. */\n  isConnected(): boolean {\n    return this.#connected\n  }\n\n  /** True during initial fetch. False afterwise.  */\n  isLoading(): boolean {\n    return !this.#isUpToDate\n  }\n\n  hasStarted(): boolean {\n    return this.#started\n  }\n\n  isPaused(): boolean {\n    return this.#state === `paused`\n  }\n\n  /** Await the next tick of the request loop */\n  async #nextTick() {\n    if (this.#tickPromise) {\n      return this.#tickPromise\n    }\n    this.#tickPromise = new Promise((resolve, reject) => {\n      this.#tickPromiseResolver = resolve\n      this.#tickPromiseRejecter = reject\n    })\n    this.#tickPromise.finally(() => {\n      this.#tickPromise = undefined\n      this.#tickPromiseResolver = undefined\n      this.#tickPromiseRejecter = undefined\n    })\n    return this.#tickPromise\n  }\n\n  /** Await until we're not in the middle of a stream (i.e., until we see an up-to-date message) */\n  async #waitForStreamEnd() {\n    if (!this.#isMidStream) {\n      return\n    }\n    if (this.#midStreamPromise) {\n      return this.#midStreamPromise\n    }\n    this.#midStreamPromise = new Promise((resolve) => {\n      this.#midStreamPromiseResolver = resolve\n    })\n    this.#midStreamPromise.finally(() => {\n      this.#midStreamPromise = undefined\n      this.#midStreamPromiseResolver = undefined\n    })\n    return this.#midStreamPromise\n  }\n\n  /**\n   * Refreshes the shape stream.\n   * This preemptively aborts any ongoing long poll and reconnects without\n   * long polling, ensuring that the stream receives an up to date message with the\n   * latest LSN from Postgres at that point in time.\n   */\n  async forceDisconnectAndRefresh(): Promise<void> {\n    this.#isRefreshing = true\n    if (this.#isUpToDate && !this.#requestAbortController?.signal.aborted) {\n      // If we are \"up to date\", any current request will be a \"live\" request\n      // and needs to be aborted\n      this.#requestAbortController?.abort(FORCE_DISCONNECT_AND_REFRESH)\n    }\n    await this.#nextTick()\n    this.#isRefreshing = false\n  }\n\n  async #publish(messages: Message<T>[]): Promise<void[]> {\n    // We process messages asynchronously\n    // but SSE's `onmessage` handler is synchronous.\n    // We use a promise chain to ensure that the handlers\n    // execute sequentially in the order the messages were received.\n    this.#messageChain = this.#messageChain.then(() =>\n      Promise.all(\n        Array.from(this.#subscribers.values()).map(async ([callback, __]) => {\n          try {\n            await callback(messages)\n          } catch (err) {\n            queueMicrotask(() => {\n              throw err\n            })\n          }\n        })\n      )\n    )\n\n    return this.#messageChain\n  }\n\n  #sendErrorToSubscribers(error: Error) {\n    this.#subscribers.forEach(([_, errorFn]) => {\n      errorFn?.(error)\n    })\n  }\n\n  #subscribeToVisibilityChanges() {\n    if (\n      typeof document === `object` &&\n      typeof document.hidden === `boolean` &&\n      typeof document.addEventListener === `function`\n    ) {\n      const visibilityHandler = () => {\n        if (document.hidden) {\n          this.#pause()\n        } else {\n          this.#resume()\n        }\n      }\n\n      document.addEventListener(`visibilitychange`, visibilityHandler)\n\n      // Store cleanup function to remove the event listener\n      this.#unsubscribeFromVisibilityChanges = () => {\n        document.removeEventListener(`visibilitychange`, visibilityHandler)\n      }\n    }\n  }\n\n  /**\n   * Resets the state of the stream, optionally with a provided\n   * shape handle\n   */\n  #reset(handle?: string) {\n    this.#lastOffset = `-1`\n    this.#liveCacheBuster = ``\n    this.#shapeHandle = handle\n    this.#isUpToDate = false\n    this.#isMidStream = true\n    this.#connected = false\n    this.#schema = undefined\n    this.#activeSnapshotRequests = 0\n    // Reset SSE fallback state to try SSE again after reset\n    this.#consecutiveShortSseConnections = 0\n    this.#sseFallbackToLongPolling = false\n  }\n\n  /**\n   * Request a snapshot for subset of data and inject it into the subscribed data stream.\n   *\n   * Only available when mode is `changes_only`.\n   * Returns the insertion point & the data, but more importantly injects the data\n   * into the subscribed data stream. Returned value is unlikely to be useful for the caller,\n   * unless the caller has complicated additional logic.\n   *\n   * Data will be injected in a way that's also tracking further incoming changes, and it'll\n   * skip the ones that are already in the snapshot.\n   *\n   * @param opts - The options for the snapshot request.\n   * @returns The metadata and the data for the snapshot.\n   */\n  async requestSnapshot(opts: SubsetParams): Promise<{\n    metadata: SnapshotMetadata\n    data: Array<ChangeMessage<T>>\n  }> {\n    if (this.#mode === `full`) {\n      throw new Error(\n        `Snapshot requests are not supported in ${this.#mode} mode, as the consumer is guaranteed to observe all data`\n      )\n    }\n    // We shouldn't be getting a snapshot on a shape that's not started\n    if (!this.#started) await this.#start()\n\n    // Wait until we're not mid-stream before pausing\n    // This ensures we don't pause in the middle of a transaction\n    await this.#waitForStreamEnd()\n\n    // Pause the stream if this is the first snapshot request\n    this.#activeSnapshotRequests++\n\n    try {\n      if (this.#activeSnapshotRequests === 1) {\n        // Currently this cannot throw, but in case it can later it's in this try block to not have a stuck counter\n        this.#pause()\n      }\n\n      const { metadata, data } = await this.fetchSnapshot(opts)\n\n      const dataWithEndBoundary = (data as Array<Message<T>>).concat([\n        { headers: { control: `snapshot-end`, ...metadata } },\n        { headers: { control: `subset-end`, ...opts } },\n      ])\n\n      this.#snapshotTracker.addSnapshot(\n        metadata,\n        new Set(data.map((message) => message.key))\n      )\n      this.#onMessages(dataWithEndBoundary, false)\n\n      return {\n        metadata,\n        data,\n      }\n    } finally {\n      // Resume the stream if this was the last snapshot request\n      this.#activeSnapshotRequests--\n      if (this.#activeSnapshotRequests === 0) {\n        this.#resume()\n      }\n    }\n  }\n\n  /**\n   * Fetch a snapshot for subset of data.\n   * Returns the metadata and the data, but does not inject it into the subscribed data stream.\n   *\n   * @param opts - The options for the snapshot request.\n   * @returns The metadata and the data for the snapshot.\n   */\n  async fetchSnapshot(opts: SubsetParams): Promise<{\n    metadata: SnapshotMetadata\n    data: Array<ChangeMessage<T>>\n  }> {\n    const { fetchUrl, requestHeaders } = await this.#constructUrl(\n      this.options.url,\n      true,\n      opts\n    )\n\n    const response = await this.#fetchClient(fetchUrl.toString(), {\n      headers: requestHeaders,\n    })\n\n    if (!response.ok) {\n      throw new FetchError(\n        response.status,\n        undefined,\n        undefined,\n        Object.fromEntries([...response.headers.entries()]),\n        fetchUrl.toString()\n      )\n    }\n\n    // Use schema from stream if available, otherwise extract from response header\n    const schema: Schema =\n      this.#schema ??\n      getSchemaFromHeaders(response.headers, {\n        required: true,\n        url: fetchUrl.toString(),\n      })\n\n    const { metadata, data: rawData } = await response.json()\n    const data = this.#messageParser.parseSnapshotData<ChangeMessage<T>>(\n      rawData,\n      schema\n    )\n\n    return {\n      metadata,\n      data,\n    }\n  }\n}\n\n/**\n * Extracts the schema from response headers.\n * @param headers - The response headers\n * @param options - Options for schema extraction\n * @param options.required - If true, throws MissingHeadersError when header is missing. Defaults to false.\n * @param options.url - The URL to include in the error message if required is true\n * @returns The parsed schema, or an empty object if not required and header is missing\n * @throws {MissingHeadersError} if required is true and the header is missing\n */\nfunction getSchemaFromHeaders(\n  headers: Headers,\n  options?: { required?: boolean; url?: string }\n): Schema {\n  const schemaHeader = headers.get(SHAPE_SCHEMA_HEADER)\n  if (!schemaHeader) {\n    if (options?.required && options?.url) {\n      throw new MissingHeadersError(options.url, [SHAPE_SCHEMA_HEADER])\n    }\n    return {}\n  }\n  return JSON.parse(schemaHeader)\n}\n\n/**\n * Validates that no reserved parameter names are used in the provided params object\n * @throws {ReservedParamError} if any reserved parameter names are found\n */\nfunction validateParams(params: Record<string, unknown> | undefined): void {\n  if (!params) return\n\n  const reservedParams = Object.keys(params).filter((key) =>\n    RESERVED_PARAMS.has(key as ReservedParamKeys)\n  )\n  if (reservedParams.length > 0) {\n    throw new ReservedParamError(reservedParams)\n  }\n}\n\nfunction validateOptions<T>(options: Partial<ShapeStreamOptions<T>>): void {\n  if (!options.url) {\n    throw new MissingShapeUrlError()\n  }\n  if (options.signal && !(options.signal instanceof AbortSignal)) {\n    throw new InvalidSignalError()\n  }\n\n  if (\n    options.offset !== undefined &&\n    options.offset !== `-1` &&\n    options.offset !== `now` &&\n    !options.handle\n  ) {\n    throw new MissingShapeHandleError()\n  }\n\n  validateParams(options.params)\n\n  return\n}\n\n// `unknown` being in the value is a bit of defensive programming if user doesn't use TS\nfunction setQueryParam(\n  url: URL,\n  key: string,\n  value: Record<string, string> | string | unknown\n): void {\n  if (value === undefined || value == null) {\n    return\n  } else if (typeof value === `string`) {\n    url.searchParams.set(key, value)\n  } else if (typeof value === `object`) {\n    for (const [k, v] of Object.entries(value)) {\n      url.searchParams.set(`${key}[${k}]`, v)\n    }\n  } else {\n    url.searchParams.set(key, value.toString())\n  }\n}\n\nfunction convertWhereParamsToObj(\n  allPgParams: ExternalParamsRecord<Row>\n): ExternalParamsRecord<Row> {\n  if (Array.isArray(allPgParams.params)) {\n    return {\n      ...allPgParams,\n      params: Object.fromEntries(allPgParams.params.map((v, i) => [i + 1, v])),\n    }\n  }\n  return allPgParams\n}\n", "interface ExpiredShapeCacheEntry {\n  expiredHandle: string\n  lastUsed: number\n}\n\n/**\n * LRU cache for tracking expired shapes with automatic cleanup\n */\nexport class ExpiredShapesCache {\n  private data: Record<string, ExpiredShapeCacheEntry> = {}\n  private max: number = 250\n  private readonly storageKey = `electric_expired_shapes`\n\n  getExpiredHandle(shapeUrl: string): string | null {\n    const entry = this.data[shapeUrl]\n    if (entry) {\n      // Update last used time when accessed\n      entry.lastUsed = Date.now()\n      this.save()\n      return entry.expiredHandle\n    }\n    return null\n  }\n\n  markExpired(shapeUrl: string, handle: string): void {\n    this.data[shapeUrl] = { expiredHandle: handle, lastUsed: Date.now() }\n\n    const keys = Object.keys(this.data)\n    if (keys.length > this.max) {\n      const oldest = keys.reduce((min, k) =>\n        this.data[k].lastUsed < this.data[min].lastUsed ? k : min\n      )\n      delete this.data[oldest]\n    }\n\n    this.save()\n  }\n\n  private save(): void {\n    if (typeof localStorage === `undefined`) return\n    try {\n      localStorage.setItem(this.storageKey, JSON.stringify(this.data))\n    } catch {\n      // Ignore localStorage errors\n    }\n  }\n\n  private load(): void {\n    if (typeof localStorage === `undefined`) return\n    try {\n      const stored = localStorage.getItem(this.storageKey)\n      if (stored) {\n        this.data = JSON.parse(stored)\n      }\n    } catch {\n      // Ignore localStorage errors, start fresh\n      this.data = {}\n    }\n  }\n\n  constructor() {\n    this.load()\n  }\n\n  clear(): void {\n    this.data = {}\n    this.save()\n  }\n}\n\n// Module-level singleton instance\nexport const expiredShapesCache = new ExpiredShapesCache()\n", "interface UpToDateEntry {\n  timestamp: number\n  cursor: string\n}\n\n/**\n * Tracks up-to-date messages to detect when we're replaying cached responses.\n *\n * When a shape receives an up-to-date, we record the timestamp and cursor in localStorage.\n * On page refresh, if we find a recent timestamp (< 60s), we know we'll be replaying\n * cached responses. We suppress their up-to-date notifications until we see a NEW cursor\n * (different from the last recorded one), which indicates fresh data from the server.\n *\n * localStorage writes are throttled to once per 60 seconds to avoid performance issues\n * with frequent updates. In-memory data is always kept current.\n */\nexport class UpToDateTracker {\n  private data: Record<string, UpToDateEntry> = {}\n  private readonly storageKey = `electric_up_to_date_tracker`\n  private readonly cacheTTL = 60_000 // 60s to match typical CDN s-maxage cache duration\n  private readonly maxEntries = 250\n  private readonly writeThrottleMs = 60_000 // Throttle localStorage writes to once per 60s\n  private lastWriteTime = 0\n  private pendingSaveTimer?: ReturnType<typeof setTimeout>\n\n  constructor() {\n    this.load()\n    this.cleanup()\n  }\n\n  /**\n   * Records that a shape received an up-to-date message with a specific cursor.\n   * This timestamp and cursor are used to detect cache replay scenarios.\n   * Updates in-memory immediately, but throttles localStorage writes.\n   */\n  recordUpToDate(shapeKey: string, cursor: string): void {\n    this.data[shapeKey] = {\n      timestamp: Date.now(),\n      cursor,\n    }\n\n    // Implement LRU eviction if we exceed max entries\n    const keys = Object.keys(this.data)\n    if (keys.length > this.maxEntries) {\n      const oldest = keys.reduce((min, k) =>\n        this.data[k].timestamp < this.data[min].timestamp ? k : min\n      )\n      delete this.data[oldest]\n    }\n\n    this.scheduleSave()\n  }\n\n  /**\n   * Schedules a throttled save to localStorage.\n   * Writes immediately if enough time has passed, otherwise schedules for later.\n   */\n  private scheduleSave(): void {\n    const now = Date.now()\n    const timeSinceLastWrite = now - this.lastWriteTime\n\n    if (timeSinceLastWrite >= this.writeThrottleMs) {\n      // Enough time has passed, write immediately\n      this.lastWriteTime = now\n      this.save()\n    } else if (!this.pendingSaveTimer) {\n      // Schedule a write for when the throttle period expires\n      const delay = this.writeThrottleMs - timeSinceLastWrite\n      this.pendingSaveTimer = setTimeout(() => {\n        this.lastWriteTime = Date.now()\n        this.pendingSaveTimer = undefined\n        this.save()\n      }, delay)\n    }\n    // else: a save is already scheduled, no need to do anything\n  }\n\n  /**\n   * Checks if we should enter replay mode for this shape.\n   * Returns the last seen cursor if there's a recent up-to-date (< 60s),\n   * which means we'll likely be replaying cached responses.\n   * Returns null if no recent up-to-date exists.\n   */\n  shouldEnterReplayMode(shapeKey: string): string | null {\n    const entry = this.data[shapeKey]\n    if (!entry) {\n      return null\n    }\n\n    const age = Date.now() - entry.timestamp\n    if (age >= this.cacheTTL) {\n      return null\n    }\n\n    return entry.cursor\n  }\n\n  /**\n   * Cleans up expired entries from the cache.\n   * Called on initialization and can be called periodically.\n   */\n  private cleanup(): void {\n    const now = Date.now()\n    const keys = Object.keys(this.data)\n    let modified = false\n\n    for (const key of keys) {\n      const age = now - this.data[key].timestamp\n      if (age > this.cacheTTL) {\n        delete this.data[key]\n        modified = true\n      }\n    }\n\n    if (modified) {\n      this.save()\n    }\n  }\n\n  private save(): void {\n    if (typeof localStorage === `undefined`) return\n    try {\n      localStorage.setItem(this.storageKey, JSON.stringify(this.data))\n    } catch {\n      // Ignore localStorage errors (quota exceeded, etc.)\n    }\n  }\n\n  private load(): void {\n    if (typeof localStorage === `undefined`) return\n    try {\n      const stored = localStorage.getItem(this.storageKey)\n      if (stored) {\n        this.data = JSON.parse(stored)\n      }\n    } catch {\n      // Ignore localStorage errors, start fresh\n      this.data = {}\n    }\n  }\n\n  /**\n   * Clears all tracked up-to-date timestamps.\n   * Useful for testing or manual cache invalidation.\n   */\n  clear(): void {\n    this.data = {}\n    if (this.pendingSaveTimer) {\n      clearTimeout(this.pendingSaveTimer)\n      this.pendingSaveTimer = undefined\n    }\n    this.save()\n  }\n}\n\n// Module-level singleton instance\nexport const upToDateTracker = new UpToDateTracker()\n", "import { isVisibleInSnapshot } from './helpers'\nimport { Row, SnapshotMetadata } from './types'\nimport { ChangeMessage } from './types'\n\n/**\n * Tracks active snapshots and filters out duplicate change messages that are already included in snapshots.\n *\n * When requesting a snapshot in changes_only mode, we need to track which transactions were included in the\n * snapshot to avoid processing duplicate changes that arrive via the live stream. This class maintains that\n * tracking state and provides methods to:\n *\n * - Add new snapshots for tracking via addSnapshot()\n * - Remove completed snapshots via removeSnapshot()\n * - Check if incoming changes should be filtered via shouldRejectMessage()\n */\nexport class SnapshotTracker {\n  private activeSnapshots: Map<\n    number,\n    { xmin: bigint; xmax: bigint; xip_list: bigint[]; keys: Set<string> }\n  > = new Map()\n  private xmaxSnapshots: Map<bigint, Set<number>> = new Map()\n  private snapshotsByDatabaseLsn: Map<bigint, Set<number>> = new Map()\n\n  /**\n   * Add a new snapshot for tracking\n   */\n  addSnapshot(metadata: SnapshotMetadata, keys: Set<string>): void {\n    this.activeSnapshots.set(metadata.snapshot_mark, {\n      xmin: BigInt(metadata.xmin),\n      xmax: BigInt(metadata.xmax),\n      xip_list: metadata.xip_list.map(BigInt),\n      keys,\n    })\n    const xmaxSet =\n      this.xmaxSnapshots\n        .get(BigInt(metadata.xmax))\n        ?.add(metadata.snapshot_mark) ?? new Set([metadata.snapshot_mark])\n    this.xmaxSnapshots.set(BigInt(metadata.xmax), xmaxSet)\n    const databaseLsnSet =\n      this.snapshotsByDatabaseLsn\n        .get(BigInt(metadata.database_lsn))\n        ?.add(metadata.snapshot_mark) ?? new Set([metadata.snapshot_mark])\n    this.snapshotsByDatabaseLsn.set(\n      BigInt(metadata.database_lsn),\n      databaseLsnSet\n    )\n  }\n\n  /**\n   * Remove a snapshot from tracking\n   */\n  removeSnapshot(snapshotMark: number): void {\n    this.activeSnapshots.delete(snapshotMark)\n  }\n\n  /**\n   * Check if a change message should be filtered because its already in an active snapshot\n   * Returns true if the message should be filtered out (not processed)\n   */\n  shouldRejectMessage(message: ChangeMessage<Row<unknown>>): boolean {\n    const txids = message.headers.txids || []\n    if (txids.length === 0) return false\n\n    const xid = Math.max(...txids) // Use the maximum transaction ID\n\n    for (const [xmax, snapshots] of this.xmaxSnapshots.entries()) {\n      if (xid >= xmax) {\n        for (const snapshot of snapshots) {\n          this.removeSnapshot(snapshot)\n        }\n      }\n    }\n\n    return [...this.activeSnapshots.values()].some(\n      (x) => x.keys.has(message.key) && isVisibleInSnapshot(xid, x)\n    )\n  }\n\n  lastSeenUpdate(newDatabaseLsn: bigint): void {\n    for (const [dbLsn, snapshots] of this.snapshotsByDatabaseLsn.entries()) {\n      if (dbLsn <= newDatabaseLsn) {\n        for (const snapshot of snapshots) {\n          this.removeSnapshot(snapshot)\n        }\n      }\n    }\n  }\n}\n", "import { Message, Offset, Row } from './types'\nimport { isChangeMessage, isControlMessage } from './helpers'\nimport { FetchError } from './error'\nimport { LogMode, ShapeStreamInterface } from './client'\n\nexport type ShapeData<T extends Row<unknown> = Row> = Map<string, T>\nexport type ShapeChangedCallback<T extends Row<unknown> = Row> = (data: {\n  value: ShapeData<T>\n  rows: T[]\n}) => void\n\ntype ShapeStatus = `syncing` | `up-to-date`\n\n/**\n * A Shape is an object that subscribes to a shape log,\n * keeps a materialised shape `.rows` in memory and\n * notifies subscribers when the value has changed.\n *\n * It can be used without a framework and as a primitive\n * to simplify developing framework hooks.\n *\n * @constructor\n * @param {ShapeStream<T extends Row>} - the underlying shape stream\n * @example\n * ```\n * const shapeStream = new ShapeStream<{ foo: number }>({\n *   url: `http://localhost:3000/v1/shape`,\n *   params: {\n *     table: `foo`\n *   }\n * })\n * const shape = new Shape(shapeStream)\n * ```\n *\n * `rows` returns a promise that resolves the Shape data once the Shape has been\n * fully loaded (and when resuming from being offline):\n *\n *     const rows = await shape.rows\n *\n * `currentRows` returns the current data synchronously:\n *\n *     const rows = shape.currentRows\n *\n *  Subscribe to updates. Called whenever the shape updates in Postgres.\n *\n *     shape.subscribe(({ rows }) => {\n *       console.log(rows)\n *     })\n */\nexport class Shape<T extends Row<unknown> = Row> {\n  readonly stream: ShapeStreamInterface<T>\n\n  readonly #data: ShapeData<T> = new Map()\n  readonly #subscribers = new Map<number, ShapeChangedCallback<T>>()\n  readonly #insertedKeys = new Set<string>()\n  readonly #requestedSubSnapshots = new Set<string>()\n  #reexecuteSnapshotsPending = false\n  #status: ShapeStatus = `syncing`\n  #error: FetchError | false = false\n\n  constructor(stream: ShapeStreamInterface<T>) {\n    this.stream = stream\n    this.stream.subscribe(\n      this.#process.bind(this),\n      this.#handleError.bind(this)\n    )\n  }\n\n  get isUpToDate(): boolean {\n    return this.#status === `up-to-date`\n  }\n\n  get lastOffset(): Offset {\n    return this.stream.lastOffset\n  }\n\n  get handle(): string | undefined {\n    return this.stream.shapeHandle\n  }\n\n  get rows(): Promise<T[]> {\n    return this.value.then((v) => Array.from(v.values()))\n  }\n\n  get currentRows(): T[] {\n    return Array.from(this.currentValue.values())\n  }\n\n  get value(): Promise<ShapeData<T>> {\n    return new Promise((resolve, reject) => {\n      if (this.stream.isUpToDate) {\n        resolve(this.currentValue)\n      } else {\n        const unsubscribe = this.subscribe(({ value }) => {\n          unsubscribe()\n          if (this.#error) reject(this.#error)\n          resolve(value)\n        })\n      }\n    })\n  }\n\n  get currentValue() {\n    return this.#data\n  }\n\n  get error() {\n    return this.#error\n  }\n\n  /** Unix time at which we last synced. Undefined when `isLoading` is true. */\n  lastSyncedAt(): number | undefined {\n    return this.stream.lastSyncedAt()\n  }\n\n  /** Time elapsed since last sync (in ms). Infinity if we did not yet sync. */\n  lastSynced() {\n    return this.stream.lastSynced()\n  }\n\n  /** True during initial fetch. False afterwise.  */\n  isLoading() {\n    return this.stream.isLoading()\n  }\n\n  /** Indicates if we are connected to the Electric sync service. */\n  isConnected(): boolean {\n    return this.stream.isConnected()\n  }\n\n  /** Current log mode of the underlying stream */\n  get mode(): LogMode {\n    return this.stream.mode\n  }\n\n  /**\n   * Request a snapshot for subset of data. Only available when mode is changes_only.\n   * Returns void; data will be emitted via the stream and processed by this Shape.\n   */\n  async requestSnapshot(\n    params: Parameters<ShapeStreamInterface<T>[`requestSnapshot`]>[0]\n  ): Promise<void> {\n    // Track this snapshot request for future re-execution on shape rotation\n    const key = JSON.stringify(params)\n    this.#requestedSubSnapshots.add(key)\n    // Ensure the stream is up-to-date so schema is available for parsing\n    await this.#awaitUpToDate()\n    await this.stream.requestSnapshot(params)\n  }\n\n  subscribe(callback: ShapeChangedCallback<T>): () => void {\n    const subscriptionId = Math.random()\n\n    this.#subscribers.set(subscriptionId, callback)\n\n    return () => {\n      this.#subscribers.delete(subscriptionId)\n    }\n  }\n\n  unsubscribeAll(): void {\n    this.#subscribers.clear()\n  }\n\n  get numSubscribers() {\n    return this.#subscribers.size\n  }\n\n  #process(messages: Message<T>[]): void {\n    let shouldNotify = false\n\n    messages.forEach((message) => {\n      if (isChangeMessage(message)) {\n        shouldNotify = this.#updateShapeStatus(`syncing`)\n        if (this.mode === `full`) {\n          switch (message.headers.operation) {\n            case `insert`:\n              this.#data.set(message.key, message.value)\n              break\n            case `update`:\n              this.#data.set(message.key, {\n                ...this.#data.get(message.key)!,\n                ...message.value,\n              })\n              break\n            case `delete`:\n              this.#data.delete(message.key)\n              break\n          }\n        } else {\n          // changes_only: only apply updates/deletes for keys for which we observed an insert\n          switch (message.headers.operation) {\n            case `insert`:\n              this.#insertedKeys.add(message.key)\n              this.#data.set(message.key, message.value)\n              break\n            case `update`:\n              if (this.#insertedKeys.has(message.key)) {\n                this.#data.set(message.key, {\n                  ...this.#data.get(message.key)!,\n                  ...message.value,\n                })\n              }\n              break\n            case `delete`:\n              if (this.#insertedKeys.has(message.key)) {\n                this.#data.delete(message.key)\n                this.#insertedKeys.delete(message.key)\n              }\n              break\n          }\n        }\n      }\n\n      if (isControlMessage(message)) {\n        switch (message.headers.control) {\n          case `up-to-date`:\n            shouldNotify = this.#updateShapeStatus(`up-to-date`)\n            if (this.#reexecuteSnapshotsPending) {\n              this.#reexecuteSnapshotsPending = false\n              void this.#reexecuteSnapshots()\n            }\n            break\n          case `must-refetch`:\n            this.#data.clear()\n            this.#insertedKeys.clear()\n            this.#error = false\n            shouldNotify = this.#updateShapeStatus(`syncing`)\n            // Flag to re-execute sub-snapshots once the new shape is up-to-date\n            this.#reexecuteSnapshotsPending = true\n            break\n        }\n      }\n    })\n\n    if (shouldNotify) this.#notify()\n  }\n\n  async #reexecuteSnapshots(): Promise<void> {\n    // Wait until stream is up-to-date again (ensures schema is available)\n    await this.#awaitUpToDate()\n\n    // Re-execute all snapshots concurrently\n    await Promise.all(\n      Array.from(this.#requestedSubSnapshots).map(async (jsonParams) => {\n        try {\n          const snapshot = JSON.parse(jsonParams)\n          await this.stream.requestSnapshot(snapshot)\n        } catch (_) {\n          // Ignore and continue; errors will be surfaced via stream onError\n        }\n      })\n    )\n  }\n\n  async #awaitUpToDate(): Promise<void> {\n    if (this.stream.isUpToDate) return\n    await new Promise<void>((resolve) => {\n      const check = () => {\n        if (this.stream.isUpToDate) {\n          clearInterval(interval)\n          unsub()\n          resolve()\n        }\n      }\n      const interval = setInterval(check, 10)\n      const unsub = this.stream.subscribe(\n        () => check(),\n        () => check()\n      )\n      check()\n    })\n  }\n\n  #updateShapeStatus(status: ShapeStatus): boolean {\n    const stateChanged = this.#status !== status\n    this.#status = status\n    return stateChanged && status === `up-to-date`\n  }\n\n  #handleError(e: Error): void {\n    if (e instanceof FetchError) {\n      this.#error = e\n      this.#notify()\n    }\n  }\n\n  #notify(): void {\n    this.#subscribers.forEach((callback) => {\n      callback({ value: this.currentValue, rows: this.currentRows })\n    })\n  }\n}\n", "import { TanStackDBError } from '@tanstack/db'\n\n// Electric DB Collection Errors\nexport class ElectricDBCollectionError extends TanStackDBError {\n  constructor(message: string, collectionId?: string) {\n    super(`${collectionId ? `[${collectionId}] ` : ``}${message}`)\n    this.name = `ElectricDBCollectionError`\n  }\n}\n\nexport class ExpectedNumberInAwaitTxIdError extends ElectricDBCollectionError {\n  constructor(txIdType: string, collectionId?: string) {\n    super(`Expected number in awaitTxId, received ${txIdType}`, collectionId)\n    this.name = `ExpectedNumberInAwaitTxIdError`\n  }\n}\n\nexport class TimeoutWaitingForTxIdError extends ElectricDBCollectionError {\n  constructor(txId: number, collectionId?: string) {\n    super(`Timeout waiting for txId: ${txId}`, collectionId)\n    this.name = `TimeoutWaitingForTxIdError`\n  }\n}\n\nexport class TimeoutWaitingForMatchError extends ElectricDBCollectionError {\n  constructor(collectionId?: string) {\n    super(`Timeout waiting for custom match function`, collectionId)\n    this.name = `TimeoutWaitingForMatchError`\n  }\n}\n\nexport class StreamAbortedError extends ElectricDBCollectionError {\n  constructor(collectionId?: string) {\n    super(`Stream aborted`, collectionId)\n    this.name = `StreamAbortedError`\n  }\n}\n", "/**\n * Serialize values for Electric SQL subset parameters.\n *\n * IMPORTANT: Electric expects RAW values, NOT SQL-formatted literals.\n * Electric handles all type casting and escaping on the server side.\n * The params Record<string, string> contains the actual values as strings,\n * and Electric will parse/cast them based on the column type in the WHERE clause.\n *\n * @param value - The value to serialize\n * @returns The raw value as a string (no SQL formatting/quoting)\n */\nexport function serialize(value: unknown): string {\n  // Handle null/undefined - return empty string\n  // Electric interprets empty string as NULL in typed column context\n  if (value === null || value === undefined) {\n    return ``\n  }\n\n  // Handle strings - return as-is (NO quotes, Electric handles escaping)\n  if (typeof value === `string`) {\n    return value\n  }\n\n  // Handle numbers - convert to string\n  if (typeof value === `number`) {\n    return value.toString()\n  }\n\n  // Handle bigints - convert to string\n  if (typeof value === `bigint`) {\n    return value.toString()\n  }\n\n  // Handle booleans - return as lowercase string\n  if (typeof value === `boolean`) {\n    return value ? `true` : `false`\n  }\n\n  // Handle dates - return ISO format (NO quotes)\n  if (value instanceof Date) {\n    return value.toISOString()\n  }\n\n  // Handle arrays - for = ANY() operator, serialize as Postgres array literal\n  // Format: {val1,val2,val3} with proper escaping\n  if (Array.isArray(value)) {\n    // Postgres array literal format uses curly braces\n    const elements = value.map((item) => {\n      if (item === null || item === undefined) {\n        return `NULL`\n      }\n      if (typeof item === `string`) {\n        // Escape quotes and backslashes for Postgres array literals\n        const escaped = item.replace(/\\\\/g, `\\\\\\\\`).replace(/\"/g, `\\\\\"`)\n        return `\"${escaped}\"`\n      }\n      return serialize(item)\n    })\n    return `{${elements.join(`,`)}}`\n  }\n\n  // Safely stringify the value for the error message\n  // JSON.stringify can't handle BigInt and other types, so we use a try-catch\n  let valueStr: string\n  try {\n    valueStr = JSON.stringify(value)\n  } catch {\n    valueStr = String(value)\n  }\n  throw new Error(`Cannot serialize value: ${valueStr}`)\n}\n", "import { serialize } from './pg-serializer'\nimport type { SubsetParams } from '@electric-sql/client'\nimport type { IR, LoadSubsetOptions } from '@tanstack/db'\n\nexport type CompiledSqlRecord = Omit<SubsetParams, `params`> & {\n  params?: Array<unknown>\n}\n\nexport function compileSQL<T>(options: LoadSubsetOptions): SubsetParams {\n  const { where, orderBy, limit } = options\n\n  const params: Array<T> = []\n  const compiledSQL: CompiledSqlRecord = { params }\n\n  if (where) {\n    // TODO: this only works when the where expression's PropRefs directly reference a column of the collection\n    //       doesn't work if it goes through aliases because then we need to know the entire query to be able to follow the reference until the base collection (cf. followRef function)\n    compiledSQL.where = compileBasicExpression(where, params)\n  }\n\n  if (orderBy) {\n    compiledSQL.orderBy = compileOrderBy(orderBy, params)\n  }\n\n  if (limit) {\n    compiledSQL.limit = limit\n  }\n\n  // WORKAROUND for Electric bug: Empty subset requests don't load data\n  // Add dummy \"true = true\" predicate when there's no where clause\n  // This is always true so doesn't filter data, just tricks Electric into loading\n  if (!where) {\n    compiledSQL.where = `true = true`\n  }\n\n  // Serialize the values in the params array into PG formatted strings\n  // and transform the array into a Record<string, string>\n  const paramsRecord = params.reduce(\n    (acc, param, index) => {\n      const serialized = serialize(param)\n      // Only include non-empty values in params\n      // Empty strings from null/undefined should be omitted\n      if (serialized !== ``) {\n        acc[`${index + 1}`] = serialized\n      }\n      return acc\n    },\n    {} as Record<string, string>,\n  )\n\n  return {\n    ...compiledSQL,\n    params: paramsRecord,\n  }\n}\n\n/**\n * Quote PostgreSQL identifiers to handle mixed case column names correctly.\n * Electric/Postgres requires quotes for case-sensitive identifiers.\n * @param name - The identifier to quote\n * @returns The quoted identifier\n */\nfunction quoteIdentifier(name: string): string {\n  return `\"${name}\"`\n}\n\n/**\n * Compiles the expression to a SQL string and mutates the params array with the values.\n * @param exp - The expression to compile\n * @param params - The params array\n * @returns The compiled SQL string\n */\nfunction compileBasicExpression(\n  exp: IR.BasicExpression<unknown>,\n  params: Array<unknown>,\n): string {\n  switch (exp.type) {\n    case `val`:\n      params.push(exp.value)\n      return `$${params.length}`\n    case `ref`:\n      // TODO: doesn't yet support JSON(B) values which could be accessed with nested props\n      if (exp.path.length !== 1) {\n        throw new Error(\n          `Compiler can't handle nested properties: ${exp.path.join(`.`)}`,\n        )\n      }\n      return quoteIdentifier(exp.path[0]!)\n    case `func`:\n      return compileFunction(exp, params)\n    default:\n      throw new Error(`Unknown expression type`)\n  }\n}\n\nfunction compileOrderBy(orderBy: IR.OrderBy, params: Array<unknown>): string {\n  const compiledOrderByClauses = orderBy.map((clause: IR.OrderByClause) =>\n    compileOrderByClause(clause, params),\n  )\n  return compiledOrderByClauses.join(`,`)\n}\n\nfunction compileOrderByClause(\n  clause: IR.OrderByClause,\n  params: Array<unknown>,\n): string {\n  // FIXME: We should handle stringSort and locale.\n  //        Correctly supporting them is tricky as it depends on Postgres' collation\n  const { expression, compareOptions } = clause\n  let sql = compileBasicExpression(expression, params)\n\n  if (compareOptions.direction === `desc`) {\n    sql = `${sql} DESC`\n  }\n\n  if (compareOptions.nulls === `first`) {\n    sql = `${sql} NULLS FIRST`\n  }\n\n  if (compareOptions.nulls === `last`) {\n    sql = `${sql} NULLS LAST`\n  }\n\n  return sql\n}\n\n/**\n * Check if a BasicExpression represents a null/undefined value\n */\nfunction isNullValue(exp: IR.BasicExpression<unknown>): boolean {\n  return exp.type === `val` && (exp.value === null || exp.value === undefined)\n}\n\nfunction compileFunction(\n  exp: IR.Func<unknown>,\n  params: Array<unknown> = [],\n): string {\n  const { name, args } = exp\n\n  const opName = getOpName(name)\n\n  // Handle comparison operators with null/undefined values\n  // These would create invalid queries with missing params (e.g., \"col = $1\" with empty params)\n  // In SQL, all comparisons with NULL return UNKNOWN, so these are almost always mistakes\n  if (isComparisonOp(name)) {\n    const nullArgIndex = args.findIndex((arg: IR.BasicExpression) =>\n      isNullValue(arg),\n    )\n\n    if (nullArgIndex !== -1) {\n      // All comparison operators (including eq) throw an error for null values\n      // Users should use isNull() or isUndefined() to check for null values\n      throw new Error(\n        `Cannot use null/undefined value with '${name}' operator. ` +\n          `Comparisons with null always evaluate to UNKNOWN in SQL. ` +\n          `Use isNull() or isUndefined() to check for null values, ` +\n          `or filter out null values before building the query.`,\n      )\n    }\n  }\n\n  const compiledArgs = args.map((arg: IR.BasicExpression) =>\n    compileBasicExpression(arg, params),\n  )\n\n  // Special case for IS NULL / IS NOT NULL - these are postfix operators\n  if (name === `isNull` || name === `isUndefined`) {\n    if (compiledArgs.length !== 1) {\n      throw new Error(`${name} expects 1 argument`)\n    }\n    return `${compiledArgs[0]} ${opName}`\n  }\n\n  // Special case for NOT - unary prefix operator\n  if (name === `not`) {\n    if (compiledArgs.length !== 1) {\n      throw new Error(`NOT expects 1 argument`)\n    }\n    // Check if the argument is IS NULL to generate IS NOT NULL\n    const arg = args[0]\n    if (arg && arg.type === `func`) {\n      const funcArg = arg\n      if (funcArg.name === `isNull` || funcArg.name === `isUndefined`) {\n        const innerArg = compileBasicExpression(funcArg.args[0]!, params)\n        return `${innerArg} IS NOT NULL`\n      }\n    }\n    return `${opName} (${compiledArgs[0]})`\n  }\n\n  if (isBinaryOp(name)) {\n    // Special handling for AND/OR which can be variadic\n    if ((name === `and` || name === `or`) && compiledArgs.length > 2) {\n      // Chain multiple arguments: (a AND b AND c) or (a OR b OR c)\n      return compiledArgs.map((arg) => `(${arg})`).join(` ${opName} `)\n    }\n\n    if (compiledArgs.length !== 2) {\n      throw new Error(`Binary operator ${name} expects 2 arguments`)\n    }\n    const [lhs, rhs] = compiledArgs\n\n    // Special case for comparison operators with boolean values\n    // PostgreSQL doesn't support < > <= >= on booleans\n    // Transform to equivalent equality checks or constant expressions\n    if (isBooleanComparisonOp(name)) {\n      const lhsArg = args[0]\n      const rhsArg = args[1]\n\n      // Check if RHS is a boolean literal value\n      if (\n        rhsArg &&\n        rhsArg.type === `val` &&\n        typeof rhsArg.value === `boolean`\n      ) {\n        const boolValue = rhsArg.value\n        // Remove the boolean param we just added since we'll transform the expression\n        params.pop()\n\n        // Transform based on operator and boolean value\n        // Boolean ordering: false < true\n        if (name === `lt`) {\n          if (boolValue === true) {\n            // lt(col, true) → col = false (only false is less than true)\n            params.push(false)\n            return `${lhs} = $${params.length}`\n          } else {\n            // lt(col, false) → nothing is less than false\n            return `false`\n          }\n        } else if (name === `gt`) {\n          if (boolValue === false) {\n            // gt(col, false) → col = true (only true is greater than false)\n            params.push(true)\n            return `${lhs} = $${params.length}`\n          } else {\n            // gt(col, true) → nothing is greater than true\n            return `false`\n          }\n        } else if (name === `lte`) {\n          if (boolValue === true) {\n            // lte(col, true) → everything is ≤ true\n            return `true`\n          } else {\n            // lte(col, false) → col = false\n            params.push(false)\n            return `${lhs} = $${params.length}`\n          }\n        } else if (name === `gte`) {\n          if (boolValue === false) {\n            // gte(col, false) → everything is ≥ false\n            return `true`\n          } else {\n            // gte(col, true) → col = true\n            params.push(true)\n            return `${lhs} = $${params.length}`\n          }\n        }\n      }\n\n      // Check if LHS is a boolean literal value (less common but handle it)\n      if (\n        lhsArg &&\n        lhsArg.type === `val` &&\n        typeof lhsArg.value === `boolean`\n      ) {\n        const boolValue = lhsArg.value\n        // Remove params for this expression and rebuild\n        params.pop() // remove RHS\n        params.pop() // remove LHS (boolean)\n\n        // Recompile RHS to get fresh param\n        const rhsCompiled = compileBasicExpression(rhsArg!, params)\n\n        // Transform: flip the comparison (val op col → col flipped_op val)\n        if (name === `lt`) {\n          // lt(true, col) → gt(col, true) → col > true → nothing is greater than true\n          if (boolValue === true) {\n            return `false`\n          } else {\n            // lt(false, col) → gt(col, false) → col = true\n            params.push(true)\n            return `${rhsCompiled} = $${params.length}`\n          }\n        } else if (name === `gt`) {\n          // gt(true, col) → lt(col, true) → col = false\n          if (boolValue === true) {\n            params.push(false)\n            return `${rhsCompiled} = $${params.length}`\n          } else {\n            // gt(false, col) → lt(col, false) → nothing is less than false\n            return `false`\n          }\n        } else if (name === `lte`) {\n          if (boolValue === false) {\n            // lte(false, col) → gte(col, false) → everything\n            return `true`\n          } else {\n            // lte(true, col) → gte(col, true) → col = true\n            params.push(true)\n            return `${rhsCompiled} = $${params.length}`\n          }\n        } else if (name === `gte`) {\n          if (boolValue === true) {\n            // gte(true, col) → lte(col, true) → everything\n            return `true`\n          } else {\n            // gte(false, col) → lte(col, false) → col = false\n            params.push(false)\n            return `${rhsCompiled} = $${params.length}`\n          }\n        }\n      }\n    }\n\n    // Special case for = ANY operator which needs parentheses around the array parameter\n    if (name === `in`) {\n      return `${lhs} ${opName}(${rhs})`\n    }\n    return `${lhs} ${opName} ${rhs}`\n  }\n\n  return `${opName}(${compiledArgs.join(`,`)})`\n}\n\nfunction isBinaryOp(name: string): boolean {\n  const binaryOps = [\n    `eq`,\n    `gt`,\n    `gte`,\n    `lt`,\n    `lte`,\n    `and`,\n    `or`,\n    `in`,\n    `like`,\n    `ilike`,\n  ]\n  return binaryOps.includes(name)\n}\n\n/**\n * Check if operator is a comparison operator that takes two values\n * These operators cannot accept null/undefined as values\n * (null comparisons in SQL always evaluate to UNKNOWN)\n */\nfunction isComparisonOp(name: string): boolean {\n  const comparisonOps = [`eq`, `gt`, `gte`, `lt`, `lte`, `like`, `ilike`]\n  return comparisonOps.includes(name)\n}\n\n/**\n * Checks if the operator is a comparison operator (excluding eq)\n * These operators don't work on booleans in PostgreSQL without casting\n */\nfunction isBooleanComparisonOp(name: string): boolean {\n  return [`gt`, `gte`, `lt`, `lte`].includes(name)\n}\n\nfunction getOpName(name: string): string {\n  const opNames = {\n    eq: `=`,\n    gt: `>`,\n    gte: `>=`,\n    lt: `<`,\n    lte: `<=`,\n    add: `+`,\n    and: `AND`,\n    or: `OR`,\n    not: `NOT`,\n    isUndefined: `IS NULL`,\n    isNull: `IS NULL`,\n    in: `= ANY`, // Use = ANY syntax for array parameters\n    like: `LIKE`,\n    ilike: `ILIKE`,\n    upper: `UPPER`,\n    lower: `LOWER`,\n    length: `LENGTH`,\n    concat: `CONCAT`,\n    coalesce: `COALESCE`,\n  }\n\n  const opName = opNames[name as keyof typeof opNames]\n\n  if (!opName) {\n    throw new Error(`Unknown operator/function: ${name}`)\n  }\n\n  return opName\n}\n", "// Import Row and Message types for the isEventMessage function\nimport type { Message, Row } from '@electric-sql/client'\n\nexport type RowId = string | number\nexport type MoveTag = string\nexport type ParsedMoveTag = Array<string>\nexport type Position = number\nexport type Value = string\nexport type MoveOutPattern = {\n  pos: Position\n  value: Value\n}\n\nconst TAG_WILDCARD = `_`\n\n/**\n * Event message type for move-out events\n */\nexport interface EventMessage {\n  headers: {\n    event: `move-out`\n    patterns: Array<MoveOutPattern>\n  }\n}\n\n/**\n * Tag index structure: array indexed by position, maps value to set of row IDs.\n * For example:\n * ```example\n * const tag1 = [a, b, c]\n * const tag2 = [a, b, d]\n * const tag3 = [a, d, e]\n *\n * // Index is:\n * [\n *   new Map([a -> <rows with a on index 0>])\n *   new Map([b -> <rows with b on index 1>, d -> <rows with d on index 1>])\n *   new Map([c -> <rows with c on index 2>, d -> <rows with d on index 2>, e -> <rows with e on index 2>])\n * ]\n * ```\n */\nexport type TagIndex = Array<Map<Value, Set<RowId>>>\n\n/**\n * Abstraction to get the value at a specific position in a tag\n */\nexport function getValue(tag: ParsedMoveTag, position: Position): Value {\n  if (position >= tag.length) {\n    throw new Error(`Position out of bounds`)\n  }\n  return tag[position]!\n}\n\n/**\n * Abstraction to extract position and value from a pattern.\n */\nfunction getPositionalValue(pattern: MoveOutPattern): {\n  pos: number\n  value: string\n} {\n  return pattern\n}\n\n/**\n * Abstraction to get the length of a tag\n */\nexport function getTagLength(tag: ParsedMoveTag): number {\n  return tag.length\n}\n\n/**\n * Check if a tag matches a pattern.\n * A tag matches if the value at the pattern's position equals the pattern's value,\n * or if the value at that position is \"_\" (wildcard).\n */\nexport function tagMatchesPattern(\n  tag: ParsedMoveTag,\n  pattern: MoveOutPattern,\n): boolean {\n  const { pos, value } = getPositionalValue(pattern)\n  const tagValue = getValue(tag, pos)\n  return tagValue === value || tagValue === TAG_WILDCARD\n}\n\n/**\n * Add a tag to the index for efficient pattern matching\n */\nexport function addTagToIndex(\n  tag: ParsedMoveTag,\n  rowId: RowId,\n  index: TagIndex,\n  tagLength: number,\n): void {\n  for (let i = 0; i < tagLength; i++) {\n    const value = getValue(tag, i)\n\n    // Only index non-wildcard values\n    if (value !== TAG_WILDCARD) {\n      const positionIndex = index[i]!\n      if (!positionIndex.has(value)) {\n        positionIndex.set(value, new Set())\n      }\n\n      const tags = positionIndex.get(value)!\n      tags.add(rowId)\n    }\n  }\n}\n\n/**\n * Remove a tag from the index\n */\nexport function removeTagFromIndex(\n  tag: ParsedMoveTag,\n  rowId: RowId,\n  index: TagIndex,\n  tagLength: number,\n): void {\n  for (let i = 0; i < tagLength; i++) {\n    const value = getValue(tag, i)\n\n    // Only remove non-wildcard values\n    if (value !== TAG_WILDCARD) {\n      const positionIndex = index[i]\n      if (positionIndex) {\n        const rowSet = positionIndex.get(value)\n        if (rowSet) {\n          rowSet.delete(rowId)\n\n          // Clean up empty sets\n          if (rowSet.size === 0) {\n            positionIndex.delete(value)\n          }\n        }\n      }\n    }\n  }\n}\n\n/**\n * Find all rows that match a given pattern\n */\nexport function findRowsMatchingPattern(\n  pattern: MoveOutPattern,\n  index: TagIndex,\n): Set<RowId> {\n  const { pos, value } = getPositionalValue(pattern)\n  const positionIndex = index[pos]\n  const rowSet = positionIndex?.get(value)\n  return rowSet ?? new Set()\n}\n\n/**\n * Check if a message is an event message with move-out event\n */\nexport function isMoveOutMessage<T extends Row<unknown>>(\n  message: Message<T>,\n): message is Message<T> & EventMessage {\n  return message.headers.event === `move-out`\n}\n", "import {\n  ShapeStream,\n  isChangeMessage,\n  isControlMessage,\n  isVisibleInSnapshot,\n} from '@electric-sql/client'\nimport { Store } from '@tanstack/store'\nimport DebugModule from 'debug'\nimport { DeduplicatedLoadSubset, and } from '@tanstack/db'\nimport {\n  ExpectedNumberInAwaitTxIdError,\n  StreamAbortedError,\n  TimeoutWaitingForMatchError,\n  TimeoutWaitingForTxIdError,\n} from './errors'\nimport { compileSQL } from './sql-compiler'\nimport {\n  addTagToIndex,\n  findRowsMatchingPattern,\n  getTagLength,\n  isMoveOutMessage,\n  removeTagFromIndex,\n  tagMatchesPattern,\n} from './tag-index'\nimport type {\n  MoveOutPattern,\n  MoveTag,\n  ParsedMoveTag,\n  RowId,\n  TagIndex,\n} from './tag-index'\nimport type {\n  BaseCollectionConfig,\n  ChangeMessageOrDeleteKeyMessage,\n  CollectionConfig,\n  DeleteMutationFnParams,\n  InsertMutationFnParams,\n  LoadSubsetOptions,\n  SyncConfig,\n  SyncMode,\n  UpdateMutationFnParams,\n  UtilsRecord,\n} from '@tanstack/db'\nimport type { StandardSchemaV1 } from '@standard-schema/spec'\nimport type {\n  ControlMessage,\n  GetExtensions,\n  Message,\n  PostgresSnapshot,\n  Row,\n  ShapeStreamOptions,\n} from '@electric-sql/client'\n\n// Re-export for user convenience in custom match functions\nexport { isChangeMessage, isControlMessage } from '@electric-sql/client'\n\nconst debug = DebugModule.debug(`ts/db:electric`)\n\n/**\n * Symbol for internal test hooks (hidden from public API)\n */\nexport const ELECTRIC_TEST_HOOKS = Symbol(`electricTestHooks`)\n\n/**\n * Internal test hooks interface (for testing only)\n */\nexport interface ElectricTestHooks {\n  /**\n   * Called before marking collection ready after first up-to-date in progressive mode\n   * Allows tests to pause and validate snapshot phase before atomic swap completes\n   */\n  beforeMarkingReady?: () => Promise<void>\n}\n\n/**\n * Type representing a transaction ID in ElectricSQL\n */\nexport type Txid = number\n\n/**\n * Custom match function type - receives stream messages and returns boolean\n * indicating if the mutation has been synchronized\n */\nexport type MatchFunction<T extends Row<unknown>> = (\n  message: Message<T>,\n) => boolean\n\n/**\n * Matching strategies for Electric synchronization\n * Handlers can return:\n * - Txid strategy: { txid: number | number[], timeout?: number } (recommended)\n * - Void (no return value) - mutation completes without waiting\n *\n * The optional timeout property specifies how long to wait for the txid(s) in milliseconds.\n * If not specified, defaults to 5000ms.\n */\nexport type MatchingStrategy = {\n  txid: Txid | Array<Txid>\n  timeout?: number\n} | void\n\n/**\n * Type representing a snapshot end message\n */\ntype SnapshotEndMessage = ControlMessage & {\n  headers: { control: `snapshot-end` }\n}\n// The `InferSchemaOutput` and `ResolveType` are copied from the `@tanstack/db` package\n// but we modified `InferSchemaOutput` slightly to restrict the schema output to `Row<unknown>`\n// This is needed in order for `GetExtensions` to be able to infer the parser extensions type from the schema\ntype InferSchemaOutput<T> = T extends StandardSchemaV1\n  ? StandardSchemaV1.InferOutput<T> extends Row<unknown>\n    ? StandardSchemaV1.InferOutput<T>\n    : Record<string, unknown>\n  : Record<string, unknown>\n\n/**\n * The mode of sync to use for the collection.\n * @default `eager`\n * @description\n * - `eager`:\n *   - syncs all data immediately on preload\n *   - collection will be marked as ready once the sync is complete\n *   - there is no incremental sync\n * - `on-demand`:\n *   - syncs data in incremental snapshots when the collection is queried\n *   - collection will be marked as ready immediately after the first snapshot is synced\n * - `progressive`:\n *   - syncs all data for the collection in the background\n *   - uses incremental snapshots during the initial sync to provide a fast path to the data required for queries\n *   - collection will be marked as ready once the full sync is complete\n */\nexport type ElectricSyncMode = SyncMode | `progressive`\n\n/**\n * Configuration interface for Electric collection options\n * @template T - The type of items in the collection\n * @template TSchema - The schema type for validation\n */\nexport interface ElectricCollectionConfig<\n  T extends Row<unknown> = Row<unknown>,\n  TSchema extends StandardSchemaV1 = never,\n> extends Omit<\n  BaseCollectionConfig<\n    T,\n    string | number,\n    TSchema,\n    ElectricCollectionUtils<T>,\n    any\n  >,\n  `onInsert` | `onUpdate` | `onDelete` | `syncMode`\n> {\n  /**\n   * Configuration options for the ElectricSQL ShapeStream\n   */\n  shapeOptions: ShapeStreamOptions<GetExtensions<T>>\n  syncMode?: ElectricSyncMode\n\n  /**\n   * Internal test hooks (for testing only)\n   * Hidden via Symbol to prevent accidental usage in production\n   */\n  [ELECTRIC_TEST_HOOKS]?: ElectricTestHooks\n\n  /**\n   * Optional asynchronous handler function called before an insert operation\n   * @param params Object containing transaction and collection information\n   * @returns Promise resolving to { txid, timeout? } or void\n   * @example\n   * // Basic Electric insert handler with txid (recommended)\n   * onInsert: async ({ transaction }) => {\n   *   const newItem = transaction.mutations[0].modified\n   *   const result = await api.todos.create({\n   *     data: newItem\n   *   })\n   *   return { txid: result.txid }\n   * }\n   *\n   * @example\n   * // Insert handler with custom timeout\n   * onInsert: async ({ transaction }) => {\n   *   const newItem = transaction.mutations[0].modified\n   *   const result = await api.todos.create({\n   *     data: newItem\n   *   })\n   *   return { txid: result.txid, timeout: 10000 } // Wait up to 10 seconds\n   * }\n   *\n   * @example\n   * // Insert handler with multiple items - return array of txids\n   * onInsert: async ({ transaction }) => {\n   *   const items = transaction.mutations.map(m => m.modified)\n   *   const results = await Promise.all(\n   *     items.map(item => api.todos.create({ data: item }))\n   *   )\n   *   return { txid: results.map(r => r.txid) }\n   * }\n   *\n   * @example\n   * // Use awaitMatch utility for custom matching\n   * onInsert: async ({ transaction, collection }) => {\n   *   const newItem = transaction.mutations[0].modified\n   *   await api.todos.create({ data: newItem })\n   *   await collection.utils.awaitMatch(\n   *     (message) => isChangeMessage(message) &&\n   *                  message.headers.operation === 'insert' &&\n   *                  message.value.name === newItem.name\n   *   )\n   * }\n   */\n  onInsert?: (\n    params: InsertMutationFnParams<\n      T,\n      string | number,\n      ElectricCollectionUtils<T>\n    >,\n  ) => Promise<MatchingStrategy>\n\n  /**\n   * Optional asynchronous handler function called before an update operation\n   * @param params Object containing transaction and collection information\n   * @returns Promise resolving to { txid, timeout? } or void\n   * @example\n   * // Basic Electric update handler with txid (recommended)\n   * onUpdate: async ({ transaction }) => {\n   *   const { original, changes } = transaction.mutations[0]\n   *   const result = await api.todos.update({\n   *     where: { id: original.id },\n   *     data: changes\n   *   })\n   *   return { txid: result.txid }\n   * }\n   *\n   * @example\n   * // Use awaitMatch utility for custom matching\n   * onUpdate: async ({ transaction, collection }) => {\n   *   const { original, changes } = transaction.mutations[0]\n   *   await api.todos.update({ where: { id: original.id }, data: changes })\n   *   await collection.utils.awaitMatch(\n   *     (message) => isChangeMessage(message) &&\n   *                  message.headers.operation === 'update' &&\n   *                  message.value.id === original.id\n   *   )\n   * }\n   */\n  onUpdate?: (\n    params: UpdateMutationFnParams<\n      T,\n      string | number,\n      ElectricCollectionUtils<T>\n    >,\n  ) => Promise<MatchingStrategy>\n\n  /**\n   * Optional asynchronous handler function called before a delete operation\n   * @param params Object containing transaction and collection information\n   * @returns Promise resolving to { txid, timeout? } or void\n   * @example\n   * // Basic Electric delete handler with txid (recommended)\n   * onDelete: async ({ transaction }) => {\n   *   const mutation = transaction.mutations[0]\n   *   const result = await api.todos.delete({\n   *     id: mutation.original.id\n   *   })\n   *   return { txid: result.txid }\n   * }\n   *\n   * @example\n   * // Use awaitMatch utility for custom matching\n   * onDelete: async ({ transaction, collection }) => {\n   *   const mutation = transaction.mutations[0]\n   *   await api.todos.delete({ id: mutation.original.id })\n   *   await collection.utils.awaitMatch(\n   *     (message) => isChangeMessage(message) &&\n   *                  message.headers.operation === 'delete' &&\n   *                  message.value.id === mutation.original.id\n   *   )\n   * }\n   */\n  onDelete?: (\n    params: DeleteMutationFnParams<\n      T,\n      string | number,\n      ElectricCollectionUtils<T>\n    >,\n  ) => Promise<MatchingStrategy>\n}\n\nfunction isUpToDateMessage<T extends Row<unknown>>(\n  message: Message<T>,\n): message is ControlMessage & { up_to_date: true } {\n  return isControlMessage(message) && message.headers.control === `up-to-date`\n}\n\nfunction isMustRefetchMessage<T extends Row<unknown>>(\n  message: Message<T>,\n): message is ControlMessage & { headers: { control: `must-refetch` } } {\n  return isControlMessage(message) && message.headers.control === `must-refetch`\n}\n\nfunction isSnapshotEndMessage<T extends Row<unknown>>(\n  message: Message<T>,\n): message is SnapshotEndMessage {\n  return isControlMessage(message) && message.headers.control === `snapshot-end`\n}\n\nfunction isSubsetEndMessage<T extends Row<unknown>>(\n  message: Message<T>,\n): message is ControlMessage & { headers: { control: `subset-end` } } {\n  return (\n    isControlMessage(message) &&\n    (message.headers.control as string) === `subset-end`\n  )\n}\n\nfunction parseSnapshotMessage(message: SnapshotEndMessage): PostgresSnapshot {\n  return {\n    xmin: message.headers.xmin,\n    xmax: message.headers.xmax,\n    xip_list: message.headers.xip_list,\n  }\n}\n\n// Check if a message contains txids in its headers\nfunction hasTxids<T extends Row<unknown>>(\n  message: Message<T>,\n): message is Message<T> & { headers: { txids?: Array<Txid> } } {\n  return `txids` in message.headers && Array.isArray(message.headers.txids)\n}\n\n/**\n * Creates a deduplicated loadSubset handler for progressive/on-demand modes\n * Returns null for eager mode, or a DeduplicatedLoadSubset instance for other modes.\n * Handles fetching snapshots in progressive mode during buffering phase,\n * and requesting snapshots in on-demand mode.\n *\n * When cursor expressions are provided (whereFrom/whereCurrent), makes two\n * requestSnapshot calls:\n * - One for whereFrom (rows > cursor) with limit\n * - One for whereCurrent (rows = cursor, for tie-breaking) without limit\n */\nfunction createLoadSubsetDedupe<T extends Row<unknown>>({\n  stream,\n  syncMode,\n  isBufferingInitialSync,\n  begin,\n  write,\n  commit,\n  collectionId,\n}: {\n  stream: ShapeStream<T>\n  syncMode: ElectricSyncMode\n  isBufferingInitialSync: () => boolean\n  begin: () => void\n  write: (mutation: {\n    type: `insert` | `update` | `delete`\n    value: T\n    metadata: Record<string, unknown>\n  }) => void\n  commit: () => void\n  collectionId?: string\n}): DeduplicatedLoadSubset | null {\n  // Eager mode doesn't need subset loading\n  if (syncMode === `eager`) {\n    return null\n  }\n\n  const loadSubset = async (opts: LoadSubsetOptions) => {\n    // In progressive mode, use fetchSnapshot during snapshot phase\n    if (isBufferingInitialSync()) {\n      // Progressive mode snapshot phase: fetch and apply immediately\n      const snapshotParams = compileSQL<T>(opts)\n      try {\n        const { data: rows } = await stream.fetchSnapshot(snapshotParams)\n\n        // Check again if we're still buffering - we might have received up-to-date\n        // and completed the atomic swap while waiting for the snapshot\n        if (!isBufferingInitialSync()) {\n          debug(\n            `${collectionId ? `[${collectionId}] ` : ``}Ignoring snapshot - sync completed while fetching`,\n          )\n          return\n        }\n\n        // Apply snapshot data in a sync transaction (only if we have data)\n        if (rows.length > 0) {\n          begin()\n          for (const row of rows) {\n            write({\n              type: `insert`,\n              value: row.value,\n              metadata: {\n                ...row.headers,\n              },\n            })\n          }\n          commit()\n\n          debug(\n            `${collectionId ? `[${collectionId}] ` : ``}Applied snapshot with ${rows.length} rows`,\n          )\n        }\n      } catch (error) {\n        debug(\n          `${collectionId ? `[${collectionId}] ` : ``}Error fetching snapshot: %o`,\n          error,\n        )\n        throw error\n      }\n    } else if (syncMode === `progressive`) {\n      // Progressive mode after full sync complete: no need to load more\n      return\n    } else {\n      // On-demand mode: use requestSnapshot\n      // When cursor is provided, make two calls:\n      // 1. whereCurrent (all ties, no limit)\n      // 2. whereFrom (rows > cursor, with limit)\n      const { cursor, where, orderBy, limit } = opts\n\n      if (cursor) {\n        // Make parallel requests for cursor-based pagination\n        const promises: Array<Promise<unknown>> = []\n\n        // Request 1: All rows matching whereCurrent (ties at boundary, no limit)\n        // Combine main where with cursor.whereCurrent\n        const whereCurrentOpts: LoadSubsetOptions = {\n          where: where ? and(where, cursor.whereCurrent) : cursor.whereCurrent,\n          orderBy,\n          // No limit - get all ties\n        }\n        const whereCurrentParams = compileSQL<T>(whereCurrentOpts)\n        promises.push(stream.requestSnapshot(whereCurrentParams))\n\n        debug(\n          `${collectionId ? `[${collectionId}] ` : ``}Requesting cursor.whereCurrent snapshot (all ties)`,\n        )\n\n        // Request 2: Rows matching whereFrom (rows > cursor, with limit)\n        // Combine main where with cursor.whereFrom\n        const whereFromOpts: LoadSubsetOptions = {\n          where: where ? and(where, cursor.whereFrom) : cursor.whereFrom,\n          orderBy,\n          limit,\n        }\n        const whereFromParams = compileSQL<T>(whereFromOpts)\n        promises.push(stream.requestSnapshot(whereFromParams))\n\n        debug(\n          `${collectionId ? `[${collectionId}] ` : ``}Requesting cursor.whereFrom snapshot (with limit ${limit})`,\n        )\n\n        // Wait for both requests to complete\n        await Promise.all(promises)\n      } else {\n        // No cursor - standard single request\n        const snapshotParams = compileSQL<T>(opts)\n        await stream.requestSnapshot(snapshotParams)\n      }\n    }\n  }\n\n  return new DeduplicatedLoadSubset({ loadSubset })\n}\n\n/**\n * Type for the awaitTxId utility function\n */\nexport type AwaitTxIdFn = (txId: Txid, timeout?: number) => Promise<boolean>\n\n/**\n * Type for the awaitMatch utility function\n */\nexport type AwaitMatchFn<T extends Row<unknown>> = (\n  matchFn: MatchFunction<T>,\n  timeout?: number,\n) => Promise<boolean>\n\n/**\n * Electric collection utilities type\n */\nexport interface ElectricCollectionUtils<\n  T extends Row<unknown> = Row<unknown>,\n> extends UtilsRecord {\n  awaitTxId: AwaitTxIdFn\n  awaitMatch: AwaitMatchFn<T>\n}\n\n/**\n * Creates Electric collection options for use with a standard Collection\n *\n * @template T - The explicit type of items in the collection (highest priority)\n * @template TSchema - The schema type for validation and type inference (second priority)\n * @template TFallback - The fallback type if no explicit or schema type is provided\n * @param config - Configuration options for the Electric collection\n * @returns Collection options with utilities\n */\n\n// Overload for when schema is provided\nexport function electricCollectionOptions<T extends StandardSchemaV1>(\n  config: ElectricCollectionConfig<InferSchemaOutput<T>, T> & {\n    schema: T\n  },\n): Omit<CollectionConfig<InferSchemaOutput<T>, string | number, T>, `utils`> & {\n  id?: string\n  utils: ElectricCollectionUtils<InferSchemaOutput<T>>\n  schema: T\n}\n\n// Overload for when no schema is provided\nexport function electricCollectionOptions<T extends Row<unknown>>(\n  config: ElectricCollectionConfig<T> & {\n    schema?: never // prohibit schema\n  },\n): Omit<CollectionConfig<T, string | number>, `utils`> & {\n  id?: string\n  utils: ElectricCollectionUtils<T>\n  schema?: never // no schema in the result\n}\n\nexport function electricCollectionOptions<T extends Row<unknown>>(\n  config: ElectricCollectionConfig<T, any>,\n): Omit<\n  CollectionConfig<T, string | number, any, ElectricCollectionUtils<T>>,\n  `utils`\n> & {\n  id?: string\n  utils: ElectricCollectionUtils<T>\n  schema?: any\n} {\n  const seenTxids = new Store<Set<Txid>>(new Set([]))\n  const seenSnapshots = new Store<Array<PostgresSnapshot>>([])\n  const internalSyncMode = config.syncMode ?? `eager`\n  const finalSyncMode =\n    internalSyncMode === `progressive` ? `on-demand` : internalSyncMode\n  const pendingMatches = new Store<\n    Map<\n      string,\n      {\n        matchFn: (message: Message<any>) => boolean\n        resolve: (value: boolean) => void\n        reject: (error: Error) => void\n        timeoutId: ReturnType<typeof setTimeout>\n        matched: boolean\n      }\n    >\n  >(new Map())\n\n  // Buffer messages since last up-to-date to handle race conditions\n  const currentBatchMessages = new Store<Array<Message<any>>>([])\n\n  // Track whether the current batch has been committed (up-to-date received)\n  // This allows awaitMatch to resolve immediately for messages from committed batches\n  const batchCommitted = new Store<boolean>(false)\n\n  /**\n   * Helper function to remove multiple matches from the pendingMatches store\n   */\n  const removePendingMatches = (matchIds: Array<string>) => {\n    if (matchIds.length > 0) {\n      pendingMatches.setState((current) => {\n        const newMatches = new Map(current)\n        matchIds.forEach((id) => newMatches.delete(id))\n        return newMatches\n      })\n    }\n  }\n\n  /**\n   * Helper function to resolve and cleanup matched pending matches\n   */\n  const resolveMatchedPendingMatches = () => {\n    const matchesToResolve: Array<string> = []\n    pendingMatches.state.forEach((match, matchId) => {\n      if (match.matched) {\n        clearTimeout(match.timeoutId)\n        match.resolve(true)\n        matchesToResolve.push(matchId)\n        debug(\n          `${config.id ? `[${config.id}] ` : ``}awaitMatch resolved on up-to-date for match %s`,\n          matchId,\n        )\n      }\n    })\n    removePendingMatches(matchesToResolve)\n  }\n  const sync = createElectricSync<T>(config.shapeOptions, {\n    seenTxids,\n    seenSnapshots,\n    syncMode: internalSyncMode,\n    pendingMatches,\n    currentBatchMessages,\n    batchCommitted,\n    removePendingMatches,\n    resolveMatchedPendingMatches,\n    collectionId: config.id,\n    testHooks: config[ELECTRIC_TEST_HOOKS],\n  })\n\n  /**\n   * Wait for a specific transaction ID to be synced\n   * @param txId The transaction ID to wait for as a number\n   * @param timeout Optional timeout in milliseconds (defaults to 5000ms)\n   * @returns Promise that resolves when the txId is synced\n   */\n  const awaitTxId: AwaitTxIdFn = async (\n    txId: Txid,\n    timeout: number = 5000,\n  ): Promise<boolean> => {\n    debug(\n      `${config.id ? `[${config.id}] ` : ``}awaitTxId called with txid %d`,\n      txId,\n    )\n    if (typeof txId !== `number`) {\n      throw new ExpectedNumberInAwaitTxIdError(typeof txId, config.id)\n    }\n\n    // First check if the txid is in the seenTxids store\n    const hasTxid = seenTxids.state.has(txId)\n    if (hasTxid) return true\n\n    // Then check if the txid is in any of the seen snapshots\n    const hasSnapshot = seenSnapshots.state.some((snapshot) =>\n      isVisibleInSnapshot(txId, snapshot),\n    )\n    if (hasSnapshot) return true\n\n    return new Promise((resolve, reject) => {\n      const timeoutId = setTimeout(() => {\n        unsubscribeSeenTxids()\n        unsubscribeSeenSnapshots()\n        reject(new TimeoutWaitingForTxIdError(txId, config.id))\n      }, timeout)\n\n      const unsubscribeSeenTxids = seenTxids.subscribe(() => {\n        if (seenTxids.state.has(txId)) {\n          debug(\n            `${config.id ? `[${config.id}] ` : ``}awaitTxId found match for txid %o`,\n            txId,\n          )\n          clearTimeout(timeoutId)\n          unsubscribeSeenTxids()\n          unsubscribeSeenSnapshots()\n          resolve(true)\n        }\n      })\n\n      const unsubscribeSeenSnapshots = seenSnapshots.subscribe(() => {\n        const visibleSnapshot = seenSnapshots.state.find((snapshot) =>\n          isVisibleInSnapshot(txId, snapshot),\n        )\n        if (visibleSnapshot) {\n          debug(\n            `${config.id ? `[${config.id}] ` : ``}awaitTxId found match for txid %o in snapshot %o`,\n            txId,\n            visibleSnapshot,\n          )\n          clearTimeout(timeoutId)\n          unsubscribeSeenSnapshots()\n          unsubscribeSeenTxids()\n          resolve(true)\n        }\n      })\n    })\n  }\n\n  /**\n   * Wait for a custom match function to find a matching message\n   * @param matchFn Function that returns true when a message matches\n   * @param timeout Optional timeout in milliseconds (defaults to 5000ms)\n   * @returns Promise that resolves when a matching message is found\n   */\n  const awaitMatch: AwaitMatchFn<any> = async (\n    matchFn: MatchFunction<any>,\n    timeout: number = 3000,\n  ): Promise<boolean> => {\n    debug(\n      `${config.id ? `[${config.id}] ` : ``}awaitMatch called with custom function`,\n    )\n\n    return new Promise((resolve, reject) => {\n      const matchId = Math.random().toString(36)\n\n      const cleanupMatch = () => {\n        pendingMatches.setState((current) => {\n          const newMatches = new Map(current)\n          newMatches.delete(matchId)\n          return newMatches\n        })\n      }\n\n      const onTimeout = () => {\n        cleanupMatch()\n        reject(new TimeoutWaitingForMatchError(config.id))\n      }\n\n      const timeoutId = setTimeout(onTimeout, timeout)\n\n      // We need access to the stream messages to check against the match function\n      // This will be handled by the sync configuration\n      const checkMatch = (message: Message<any>) => {\n        if (matchFn(message)) {\n          debug(\n            `${config.id ? `[${config.id}] ` : ``}awaitMatch found matching message, waiting for up-to-date`,\n          )\n          // Mark as matched but don't resolve yet - wait for up-to-date\n          pendingMatches.setState((current) => {\n            const newMatches = new Map(current)\n            const existing = newMatches.get(matchId)\n            if (existing) {\n              newMatches.set(matchId, { ...existing, matched: true })\n            }\n            return newMatches\n          })\n          return true\n        }\n        return false\n      }\n\n      // Check against current batch messages first to handle race conditions\n      for (const message of currentBatchMessages.state) {\n        if (matchFn(message)) {\n          // If batch is committed (up-to-date already received), resolve immediately\n          // just like awaitTxId does when it finds a txid in seenTxids\n          if (batchCommitted.state) {\n            debug(\n              `${config.id ? `[${config.id}] ` : ``}awaitMatch found immediate match in committed batch, resolving immediately`,\n            )\n            clearTimeout(timeoutId)\n            resolve(true)\n            return\n          }\n\n          // If batch is not yet committed, register match and wait for up-to-date\n          debug(\n            `${config.id ? `[${config.id}] ` : ``}awaitMatch found immediate match in current batch, waiting for up-to-date`,\n          )\n          pendingMatches.setState((current) => {\n            const newMatches = new Map(current)\n            newMatches.set(matchId, {\n              matchFn: checkMatch,\n              resolve,\n              reject,\n              timeoutId,\n              matched: true, // Already matched, will resolve on up-to-date\n            })\n            return newMatches\n          })\n          return\n        }\n      }\n\n      // Store the match function for the sync process to use\n      // We'll add this to a pending matches store\n      pendingMatches.setState((current) => {\n        const newMatches = new Map(current)\n        newMatches.set(matchId, {\n          matchFn: checkMatch,\n          resolve,\n          reject,\n          timeoutId,\n          matched: false,\n        })\n        return newMatches\n      })\n    })\n  }\n\n  /**\n   * Process matching strategy and wait for synchronization\n   */\n  const processMatchingStrategy = async (\n    result: MatchingStrategy,\n  ): Promise<void> => {\n    // Only wait if result contains txid\n    if (result && `txid` in result) {\n      const timeout = result.timeout\n      // Handle both single txid and array of txids\n      if (Array.isArray(result.txid)) {\n        await Promise.all(result.txid.map((txid) => awaitTxId(txid, timeout)))\n      } else {\n        await awaitTxId(result.txid, timeout)\n      }\n    }\n    // If result is void/undefined, don't wait - mutation completes immediately\n  }\n\n  // Create wrapper handlers for direct persistence operations that handle different matching strategies\n  const wrappedOnInsert = config.onInsert\n    ? async (\n        params: InsertMutationFnParams<\n          any,\n          string | number,\n          ElectricCollectionUtils<T>\n        >,\n      ) => {\n        const handlerResult = await config.onInsert!(params)\n        await processMatchingStrategy(handlerResult)\n        return handlerResult\n      }\n    : undefined\n\n  const wrappedOnUpdate = config.onUpdate\n    ? async (\n        params: UpdateMutationFnParams<\n          any,\n          string | number,\n          ElectricCollectionUtils<T>\n        >,\n      ) => {\n        const handlerResult = await config.onUpdate!(params)\n        await processMatchingStrategy(handlerResult)\n        return handlerResult\n      }\n    : undefined\n\n  const wrappedOnDelete = config.onDelete\n    ? async (\n        params: DeleteMutationFnParams<\n          any,\n          string | number,\n          ElectricCollectionUtils<T>\n        >,\n      ) => {\n        const handlerResult = await config.onDelete!(params)\n        await processMatchingStrategy(handlerResult)\n        return handlerResult\n      }\n    : undefined\n\n  // Extract standard Collection config properties\n  const {\n    shapeOptions: _shapeOptions,\n    onInsert: _onInsert,\n    onUpdate: _onUpdate,\n    onDelete: _onDelete,\n    ...restConfig\n  } = config\n\n  return {\n    ...restConfig,\n    syncMode: finalSyncMode,\n    sync,\n    onInsert: wrappedOnInsert,\n    onUpdate: wrappedOnUpdate,\n    onDelete: wrappedOnDelete,\n    utils: {\n      awaitTxId,\n      awaitMatch,\n    },\n  }\n}\n\n/**\n * Internal function to create ElectricSQL sync configuration\n */\nfunction createElectricSync<T extends Row<unknown>>(\n  shapeOptions: ShapeStreamOptions<GetExtensions<T>>,\n  options: {\n    syncMode: ElectricSyncMode\n    seenTxids: Store<Set<Txid>>\n    seenSnapshots: Store<Array<PostgresSnapshot>>\n    pendingMatches: Store<\n      Map<\n        string,\n        {\n          matchFn: (message: Message<T>) => boolean\n          resolve: (value: boolean) => void\n          reject: (error: Error) => void\n          timeoutId: ReturnType<typeof setTimeout>\n          matched: boolean\n        }\n      >\n    >\n    currentBatchMessages: Store<Array<Message<T>>>\n    batchCommitted: Store<boolean>\n    removePendingMatches: (matchIds: Array<string>) => void\n    resolveMatchedPendingMatches: () => void\n    collectionId?: string\n    testHooks?: ElectricTestHooks\n  },\n): SyncConfig<T> {\n  const {\n    seenTxids,\n    seenSnapshots,\n    syncMode,\n    pendingMatches,\n    currentBatchMessages,\n    batchCommitted,\n    removePendingMatches,\n    resolveMatchedPendingMatches,\n    collectionId,\n    testHooks,\n  } = options\n  const MAX_BATCH_MESSAGES = 1000 // Safety limit for message buffer\n\n  // Store for the relation schema information\n  const relationSchema = new Store<string | undefined>(undefined)\n\n  const tagCache = new Map<MoveTag, ParsedMoveTag>()\n\n  // Parses a tag string into a MoveTag.\n  // It memoizes the result parsed tag such that future calls\n  // for the same tag string return the same MoveTag array.\n  const parseTag = (tag: MoveTag): ParsedMoveTag => {\n    const cachedTag = tagCache.get(tag)\n    if (cachedTag) {\n      return cachedTag\n    }\n\n    const parsedTag = tag.split(`|`)\n    tagCache.set(tag, parsedTag)\n    return parsedTag\n  }\n\n  // Tag tracking state\n  const rowTagSets = new Map<RowId, Set<MoveTag>>()\n  const tagIndex: TagIndex = []\n  let tagLength: number | undefined = undefined\n\n  /**\n   * Initialize the tag index with the correct length\n   */\n  const initializeTagIndex = (length: number): void => {\n    if (tagIndex.length < length) {\n      // Extend the index array to the required length\n      for (let i = tagIndex.length; i < length; i++) {\n        tagIndex[i] = new Map()\n      }\n    }\n  }\n\n  /**\n   * Add tags to a row and update the tag index\n   */\n  const addTagsToRow = (\n    tags: Array<MoveTag>,\n    rowId: RowId,\n    rowTagSet: Set<MoveTag>,\n  ): void => {\n    for (const tag of tags) {\n      const parsedTag = parseTag(tag)\n\n      // Infer tag length from first tag\n      if (tagLength === undefined) {\n        tagLength = getTagLength(parsedTag)\n        initializeTagIndex(tagLength)\n      }\n\n      // Validate tag length matches\n      const currentTagLength = getTagLength(parsedTag)\n      if (currentTagLength !== tagLength) {\n        debug(\n          `${collectionId ? `[${collectionId}] ` : ``}Tag length mismatch: expected ${tagLength}, got ${currentTagLength}`,\n        )\n        continue\n      }\n\n      rowTagSet.add(tag)\n      addTagToIndex(parsedTag, rowId, tagIndex, tagLength)\n    }\n  }\n\n  /**\n   * Remove tags from a row and update the tag index\n   */\n  const removeTagsFromRow = (\n    removedTags: Array<MoveTag>,\n    rowId: RowId,\n    rowTagSet: Set<MoveTag>,\n  ): void => {\n    if (tagLength === undefined) {\n      return\n    }\n\n    for (const tag of removedTags) {\n      const parsedTag = parseTag(tag)\n      rowTagSet.delete(tag)\n      removeTagFromIndex(parsedTag, rowId, tagIndex, tagLength)\n      // We aggresively evict the tag from the cache\n      // if this tag is shared with another row\n      // and is not removed from that other row\n      // then next time we encounter the tag it will be parsed again\n      tagCache.delete(tag)\n    }\n  }\n\n  /**\n   * Process tags for a change message (add and remove tags)\n   */\n  const processTagsForChangeMessage = (\n    tags: Array<MoveTag> | undefined,\n    removedTags: Array<MoveTag> | undefined,\n    rowId: RowId,\n  ): Set<MoveTag> => {\n    // Initialize tag set for this row if it doesn't exist (needed for checking deletion)\n    if (!rowTagSets.has(rowId)) {\n      rowTagSets.set(rowId, new Set())\n    }\n    const rowTagSet = rowTagSets.get(rowId)!\n\n    // Add new tags\n    if (tags) {\n      addTagsToRow(tags, rowId, rowTagSet)\n    }\n\n    // Remove tags\n    if (removedTags) {\n      removeTagsFromRow(removedTags, rowId, rowTagSet)\n    }\n\n    return rowTagSet\n  }\n\n  /**\n   * Clear all tag tracking state (used when truncating)\n   */\n  const clearTagTrackingState = (): void => {\n    rowTagSets.clear()\n    tagIndex.length = 0\n    tagLength = undefined\n  }\n\n  /**\n   * Remove all tags for a row from both the tag set and the index\n   * Used when a row is deleted\n   */\n  const clearTagsForRow = (rowId: RowId): void => {\n    if (tagLength === undefined) {\n      return\n    }\n\n    const rowTagSet = rowTagSets.get(rowId)\n    if (!rowTagSet) {\n      return\n    }\n\n    // Remove each tag from the index\n    for (const tag of rowTagSet) {\n      const parsedTag = parseTag(tag)\n      const currentTagLength = getTagLength(parsedTag)\n      if (currentTagLength === tagLength) {\n        removeTagFromIndex(parsedTag, rowId, tagIndex, tagLength)\n      }\n      tagCache.delete(tag)\n    }\n\n    // Remove the row from the tag sets map\n    rowTagSets.delete(rowId)\n  }\n\n  /**\n   * Remove matching tags from a row based on a pattern\n   * Returns true if the row's tag set is now empty\n   */\n  const removeMatchingTagsFromRow = (\n    rowId: RowId,\n    pattern: MoveOutPattern,\n  ): boolean => {\n    const rowTagSet = rowTagSets.get(rowId)\n    if (!rowTagSet) {\n      return false\n    }\n\n    // Find tags that match this pattern and remove them\n    for (const tag of rowTagSet) {\n      const parsedTag = parseTag(tag)\n      if (tagMatchesPattern(parsedTag, pattern)) {\n        rowTagSet.delete(tag)\n        removeTagFromIndex(parsedTag, rowId, tagIndex, tagLength!)\n      }\n    }\n\n    // Check if row's tag set is now empty\n    if (rowTagSet.size === 0) {\n      rowTagSets.delete(rowId)\n      return true\n    }\n\n    return false\n  }\n\n  /**\n   * Process move-out event: remove matching tags from rows and delete rows with empty tag sets\n   */\n  const processMoveOutEvent = (\n    patterns: Array<MoveOutPattern>,\n    begin: () => void,\n    write: (message: ChangeMessageOrDeleteKeyMessage<T>) => void,\n    transactionStarted: boolean,\n  ): boolean => {\n    if (tagLength === undefined) {\n      debug(\n        `${collectionId ? `[${collectionId}] ` : ``}Received move-out message but no tag length set yet, ignoring`,\n      )\n      return transactionStarted\n    }\n\n    let txStarted = transactionStarted\n\n    // Process all patterns and collect rows to delete\n    for (const pattern of patterns) {\n      // Find all rows that match this pattern\n      const affectedRowIds = findRowsMatchingPattern(pattern, tagIndex)\n\n      for (const rowId of affectedRowIds) {\n        if (removeMatchingTagsFromRow(rowId, pattern)) {\n          // Delete rows with empty tag sets\n          if (!txStarted) {\n            begin()\n            txStarted = true\n          }\n\n          write({\n            type: `delete`,\n            key: rowId,\n          })\n        }\n      }\n    }\n\n    return txStarted\n  }\n\n  /**\n   * Get the sync metadata for insert operations\n   * @returns Record containing relation information\n   */\n  const getSyncMetadata = (): Record<string, unknown> => {\n    // Use the stored schema if available, otherwise default to 'public'\n    const schema = relationSchema.state || `public`\n\n    return {\n      relation: shapeOptions.params?.table\n        ? [schema, shapeOptions.params.table]\n        : undefined,\n    }\n  }\n\n  let unsubscribeStream: () => void\n\n  return {\n    sync: (params: Parameters<SyncConfig<T>[`sync`]>[0]) => {\n      const { begin, write, commit, markReady, truncate, collection } = params\n\n      // Wrap markReady to wait for test hook in progressive mode\n      let progressiveReadyGate: Promise<void> | null = null\n      const wrappedMarkReady = (isBuffering: boolean) => {\n        // Only create gate if we're in buffering phase (first up-to-date)\n        if (\n          isBuffering &&\n          syncMode === `progressive` &&\n          testHooks?.beforeMarkingReady\n        ) {\n          // Create a new gate promise for this sync cycle\n          progressiveReadyGate = testHooks.beforeMarkingReady()\n          progressiveReadyGate.then(() => {\n            markReady()\n          })\n        } else {\n          // No hook, not buffering, or already past first up-to-date\n          markReady()\n        }\n      }\n\n      // Abort controller for the stream - wraps the signal if provided\n      const abortController = new AbortController()\n\n      if (shapeOptions.signal) {\n        shapeOptions.signal.addEventListener(\n          `abort`,\n          () => {\n            abortController.abort()\n          },\n          {\n            once: true,\n          },\n        )\n        if (shapeOptions.signal.aborted) {\n          abortController.abort()\n        }\n      }\n\n      // Cleanup pending matches on abort\n      abortController.signal.addEventListener(`abort`, () => {\n        pendingMatches.setState((current) => {\n          current.forEach((match) => {\n            clearTimeout(match.timeoutId)\n            match.reject(new StreamAbortedError())\n          })\n          return new Map() // Clear all pending matches\n        })\n      })\n\n      const stream = new ShapeStream({\n        ...shapeOptions,\n        // In on-demand mode, we only want to sync changes, so we set the log to `changes_only`\n        log: syncMode === `on-demand` ? `changes_only` : undefined,\n        // In on-demand mode, we only need the changes from the point of time the collection was created\n        // so we default to `now` when there is no saved offset.\n        offset:\n          shapeOptions.offset ?? (syncMode === `on-demand` ? `now` : undefined),\n        signal: abortController.signal,\n        onError: (errorParams) => {\n          // Just immediately mark ready if there's an error to avoid blocking\n          // apps waiting for `.preload()` to finish.\n          // Note that Electric sends a 409 error on a `must-refetch` message, but the\n          // ShapeStream handled this and it will not reach this handler, therefor\n          // this markReady will not be triggers by a `must-refetch`.\n          markReady()\n\n          if (shapeOptions.onError) {\n            return shapeOptions.onError(errorParams)\n          } else {\n            console.error(\n              `An error occurred while syncing collection: ${collection.id}, \\n` +\n                `it has been marked as ready to avoid blocking apps waiting for '.preload()' to finish. \\n` +\n                `You can provide an 'onError' handler on the shapeOptions to handle this error, and this message will not be logged.`,\n              errorParams,\n            )\n          }\n\n          return\n        },\n      })\n      let transactionStarted = false\n      const newTxids = new Set<Txid>()\n      const newSnapshots: Array<PostgresSnapshot> = []\n      let hasReceivedUpToDate = false // Track if we've completed initial sync in progressive mode\n\n      // Progressive mode state\n      // Helper to determine if we're buffering the initial sync\n      const isBufferingInitialSync = () =>\n        syncMode === `progressive` && !hasReceivedUpToDate\n      const bufferedMessages: Array<Message<T>> = [] // Buffer change messages during initial sync\n\n      /**\n       * Process a change message: handle tags and write the mutation\n       */\n      const processChangeMessage = (changeMessage: Message<T>) => {\n        if (!isChangeMessage(changeMessage)) {\n          return\n        }\n\n        // Process tags if present\n        const tags = changeMessage.headers.tags\n        const removedTags = changeMessage.headers.removed_tags\n        const hasTags = tags || removedTags\n\n        const rowId = collection.getKeyFromItem(changeMessage.value)\n        const operation = changeMessage.headers.operation\n\n        if (operation === `delete`) {\n          clearTagsForRow(rowId)\n        } else if (hasTags) {\n          processTagsForChangeMessage(tags, removedTags, rowId)\n        }\n\n        write({\n          type: changeMessage.headers.operation,\n          value: changeMessage.value,\n          // Include the primary key and relation info in the metadata\n          metadata: {\n            ...changeMessage.headers,\n          },\n        })\n      }\n\n      // Create deduplicated loadSubset wrapper for non-eager modes\n      // This prevents redundant snapshot requests when multiple concurrent\n      // live queries request overlapping or subset predicates\n      const loadSubsetDedupe = createLoadSubsetDedupe({\n        stream,\n        syncMode,\n        isBufferingInitialSync,\n        begin,\n        write,\n        commit,\n        collectionId,\n      })\n\n      unsubscribeStream = stream.subscribe((messages: Array<Message<T>>) => {\n        // Track commit point type - up-to-date takes precedence as it also triggers progressive mode atomic swap\n        let commitPoint: `up-to-date` | `subset-end` | null = null\n\n        // Don't clear the buffer between batches - this preserves messages for awaitMatch\n        // to find even if multiple batches arrive before awaitMatch is called.\n        // The buffer is naturally limited by MAX_BATCH_MESSAGES (oldest messages are dropped).\n        // Reset batchCommitted since we're starting a new batch\n        batchCommitted.setState(() => false)\n\n        for (const message of messages) {\n          // Add message to current batch buffer (for race condition handling)\n          if (isChangeMessage(message) || isMoveOutMessage(message)) {\n            currentBatchMessages.setState((currentBuffer) => {\n              const newBuffer = [...currentBuffer, message]\n              // Limit buffer size for safety\n              if (newBuffer.length > MAX_BATCH_MESSAGES) {\n                newBuffer.splice(0, newBuffer.length - MAX_BATCH_MESSAGES)\n              }\n              return newBuffer\n            })\n          }\n\n          // Check for txids in the message and add them to our store\n          // Skip during buffered initial sync in progressive mode (txids will be extracted during atomic swap)\n          if (hasTxids(message) && !isBufferingInitialSync()) {\n            message.headers.txids?.forEach((txid) => newTxids.add(txid))\n          }\n\n          // Check pending matches against this message\n          // Note: matchFn will mark matches internally, we don't resolve here\n          const matchesToRemove: Array<string> = []\n          pendingMatches.state.forEach((match, matchId) => {\n            if (!match.matched) {\n              try {\n                match.matchFn(message)\n              } catch (err) {\n                // If matchFn throws, clean up and reject the promise\n                clearTimeout(match.timeoutId)\n                match.reject(\n                  err instanceof Error ? err : new Error(String(err)),\n                )\n                matchesToRemove.push(matchId)\n                debug(`matchFn error: %o`, err)\n              }\n            }\n          })\n\n          // Remove matches that errored\n          removePendingMatches(matchesToRemove)\n\n          if (isChangeMessage(message)) {\n            // Check if the message contains schema information\n            const schema = message.headers.schema\n            if (schema && typeof schema === `string`) {\n              // Store the schema for future use if it's a valid string\n              relationSchema.setState(() => schema)\n            }\n\n            // In buffered initial sync of progressive mode, buffer messages instead of writing\n            if (isBufferingInitialSync()) {\n              bufferedMessages.push(message)\n            } else {\n              // Normal processing: write changes immediately\n              if (!transactionStarted) {\n                begin()\n                transactionStarted = true\n              }\n\n              processChangeMessage(message)\n            }\n          } else if (isSnapshotEndMessage(message)) {\n            // Track postgres snapshot metadata for resolving awaiting mutations\n            // Skip during buffered initial sync (will be extracted during atomic swap)\n            if (!isBufferingInitialSync()) {\n              newSnapshots.push(parseSnapshotMessage(message))\n            }\n          } else if (isUpToDateMessage(message)) {\n            // up-to-date takes precedence - also triggers progressive mode atomic swap\n            commitPoint = `up-to-date`\n          } else if (isSubsetEndMessage(message)) {\n            // subset-end triggers commit but not progressive mode atomic swap\n            if (commitPoint !== `up-to-date`) {\n              commitPoint = `subset-end`\n            }\n          } else if (isMoveOutMessage(message)) {\n            // Handle move-out event: buffer if buffering, otherwise process immediately\n            if (isBufferingInitialSync()) {\n              bufferedMessages.push(message)\n            } else {\n              // Normal processing: process move-out immediately\n              transactionStarted = processMoveOutEvent(\n                message.headers.patterns,\n                begin,\n                write,\n                transactionStarted,\n              )\n            }\n          } else if (isMustRefetchMessage(message)) {\n            debug(\n              `${collectionId ? `[${collectionId}] ` : ``}Received must-refetch message, starting transaction with truncate`,\n            )\n\n            // Start a transaction and truncate the collection\n            if (!transactionStarted) {\n              begin()\n              transactionStarted = true\n            }\n\n            truncate()\n\n            // Clear tag tracking state\n            clearTagTrackingState()\n\n            // Reset the loadSubset deduplication state since we're starting fresh\n            // This ensures that previously loaded predicates don't prevent refetching after truncate\n            loadSubsetDedupe?.reset()\n\n            // Reset flags so we continue accumulating changes until next up-to-date\n            commitPoint = null\n            hasReceivedUpToDate = false // Reset for progressive mode (isBufferingInitialSync will reflect this)\n            bufferedMessages.length = 0 // Clear buffered messages\n          }\n        }\n\n        if (commitPoint !== null) {\n          // PROGRESSIVE MODE: Atomic swap on first up-to-date (not subset-end)\n          if (isBufferingInitialSync() && commitPoint === `up-to-date`) {\n            debug(\n              `${collectionId ? `[${collectionId}] ` : ``}Progressive mode: Performing atomic swap with ${bufferedMessages.length} buffered messages`,\n            )\n\n            // Start atomic swap transaction\n            begin()\n\n            // Truncate to clear all snapshot data\n            truncate()\n\n            // Clear tag tracking state for atomic swap\n            clearTagTrackingState()\n\n            // Apply all buffered change messages and extract txids/snapshots\n            for (const bufferedMsg of bufferedMessages) {\n              if (isChangeMessage(bufferedMsg)) {\n                processChangeMessage(bufferedMsg)\n\n                // Extract txids from buffered messages (will be committed to store after transaction)\n                if (hasTxids(bufferedMsg)) {\n                  bufferedMsg.headers.txids?.forEach((txid) =>\n                    newTxids.add(txid),\n                  )\n                }\n              } else if (isSnapshotEndMessage(bufferedMsg)) {\n                // Extract snapshots from buffered messages (will be committed to store after transaction)\n                newSnapshots.push(parseSnapshotMessage(bufferedMsg))\n              } else if (isMoveOutMessage(bufferedMsg)) {\n                // Process buffered move-out messages during atomic swap\n                processMoveOutEvent(\n                  bufferedMsg.headers.patterns,\n                  begin,\n                  write,\n                  transactionStarted,\n                )\n              }\n            }\n\n            // Commit the atomic swap\n            commit()\n\n            // Exit buffering phase by marking that we've received up-to-date\n            // isBufferingInitialSync() will now return false\n            bufferedMessages.length = 0\n\n            debug(\n              `${collectionId ? `[${collectionId}] ` : ``}Progressive mode: Atomic swap complete, now in normal sync mode`,\n            )\n          } else {\n            // Normal mode or on-demand: commit transaction if one was started\n            // Both up-to-date and subset-end trigger a commit\n            if (transactionStarted) {\n              commit()\n              transactionStarted = false\n            }\n          }\n          wrappedMarkReady(isBufferingInitialSync())\n\n          // Track that we've received the first up-to-date for progressive mode\n          if (commitPoint === `up-to-date`) {\n            hasReceivedUpToDate = true\n          }\n\n          // Always commit txids when we receive up-to-date, regardless of transaction state\n          seenTxids.setState((currentTxids) => {\n            const clonedSeen = new Set<Txid>(currentTxids)\n            if (newTxids.size > 0) {\n              debug(\n                `${collectionId ? `[${collectionId}] ` : ``}new txids synced from pg %O`,\n                Array.from(newTxids),\n              )\n            }\n            newTxids.forEach((txid) => clonedSeen.add(txid))\n            newTxids.clear()\n            return clonedSeen\n          })\n\n          // Always commit snapshots when we receive up-to-date, regardless of transaction state\n          seenSnapshots.setState((currentSnapshots) => {\n            const seen = [...currentSnapshots, ...newSnapshots]\n            newSnapshots.forEach((snapshot) =>\n              debug(\n                `${collectionId ? `[${collectionId}] ` : ``}new snapshot synced from pg %o`,\n                snapshot,\n              ),\n            )\n            newSnapshots.length = 0\n            return seen\n          })\n\n          // Resolve all matched pending matches on up-to-date or subset-end\n          // Set batchCommitted BEFORE resolving to avoid timing window where late awaitMatch\n          // calls could register as \"matched\" after resolver pass already ran\n          batchCommitted.setState(() => true)\n\n          resolveMatchedPendingMatches()\n        }\n      })\n\n      // Return the deduplicated loadSubset if available (on-demand or progressive mode)\n      // The loadSubset method is auto-bound, so it can be safely returned directly\n      return {\n        loadSubset: loadSubsetDedupe?.loadSubset,\n        cleanup: () => {\n          // Unsubscribe from the stream\n          unsubscribeStream()\n          // Abort the abort controller to stop the stream\n          abortController.abort()\n          // Reset deduplication tracking so collection can load fresh data if restarted\n          loadSubsetDedupe?.reset()\n        },\n      }\n    },\n    // Expose the getSyncMetadata function\n    getSyncMetadata,\n  }\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;AAqBA,eAAsB,SAAS,QAAoC,SAAkC;AACjG,QAAM,SAAS,OAAO,UAAS;AAC/B,MAAI;AACJ,SAAO,EAAE,SAAS,MAAM,OAAO,KAAI,GAAI,MAAM;AACzC,YAAQ,OAAO,KAAK;;AAE5B;AAeM,SAAU,SAAS,QAAuD;AAC5E,MAAI;AACJ,MAAI;AACJ,MAAI;AACJ,MAAI,yBAAyB;AAG7B,SAAO,SAAS,QAAQ,KAAe;AACnC,QAAI,WAAW,QAAW;AACtB,eAAS;AACT,iBAAW;AACX,oBAAc;WACX;AAEH,eAAS,OAAO,QAAQ,GAAG;;AAG/B,UAAM,YAAY,OAAO;AACzB,QAAI,YAAY;AAChB,WAAO,WAAW,WAAW;AACzB,UAAI,wBAAwB;AACxB,YAAI,OAAO,QAAQ,MAAC,IAA2B;AAC3C,sBAAY,EAAE;;AAGlB,iCAAyB;;AAI7B,UAAI,UAAU;AACd,aAAO,WAAW,aAAa,YAAY,IAAI,EAAE,UAAU;AACvD,gBAAQ,OAAO,QAAQ,GAAG;UACtB,KAAA;AACI,gBAAI,gBAAgB,IAAI;AACpB,4BAAc,WAAW;;AAE7B;UAEJ,KAAA;AACI,qCAAyB;UAC7B,KAAA;AACI,sBAAU;AACV;;;AAIZ,UAAI,YAAY,IAAI;AAGhB;;AAIJ,aAAO,OAAO,SAAS,WAAW,OAAO,GAAG,WAAW;AACvD,kBAAY;AACZ,oBAAc;;AAGlB,QAAI,cAAc,WAAW;AACzB,eAAS;eACF,cAAc,GAAG;AAGxB,eAAS,OAAO,SAAS,SAAS;AAClC,kBAAY;;EAEpB;AACJ;AASM,SAAU,YACZ,MACA,SACA,WAA6C;AAE7C,MAAI,UAAU,WAAU;AACxB,QAAM,UAAU,IAAI,YAAW;AAG/B,SAAO,SAAS,OAAO,MAAkB,aAAmB;AACxD,QAAI,KAAK,WAAW,GAAG;AAEnB,oBAAS,QAAT,cAAS,SAAA,SAAT,UAAY,OAAO;AACnB,gBAAU,WAAU;eACb,cAAc,GAAG;AAGxB,YAAM,QAAQ,QAAQ,OAAO,KAAK,SAAS,GAAG,WAAW,CAAC;AAC1D,YAAM,cAAc,eAAe,KAAK,cAAc,CAAC,MAAC,KAA0B,IAAI;AACtF,YAAM,QAAQ,QAAQ,OAAO,KAAK,SAAS,WAAW,CAAC;AAEvD,cAAQ,OAAO;QACX,KAAK;AAGD,kBAAQ,OAAO,QAAQ,OACjB,QAAQ,OAAO,OAAO,QACtB;AACN;QACJ,KAAK;AACD,kBAAQ,QAAQ;AAChB;QACJ,KAAK;AACD,eAAK,QAAQ,KAAK,KAAK;AACvB;QACJ,KAAK;AACD,gBAAM,QAAQ,SAAS,OAAO,EAAE;AAChC,cAAI,CAAC,MAAM,KAAK,GAAG;AACf,oBAAQ,QAAQ,QAAQ,KAAK;;AAEjC;;;EAGhB;AACJ;AAEA,SAAS,OAAO,GAAe,GAAa;AACxC,QAAM,MAAM,IAAI,WAAW,EAAE,SAAS,EAAE,MAAM;AAC9C,MAAI,IAAI,CAAC;AACT,MAAI,IAAI,GAAG,EAAE,MAAM;AACnB,SAAO;AACX;AAEA,SAAS,aAAU;AAKf,SAAO;IACH,MAAM;IACN,OAAO;IACP,IAAI;IACJ,OAAO;;AAEf;;;;;;;;;;;;;;ACpLO,IAAM,yBAAyB;AAEtC,IAAM,uBAAuB;AAC7B,IAAM,cAAc;AAkDd,SAAU,iBAAiB,OAAoB,IAU9B;MAV8B,EACjD,QAAQ,aACR,SAAS,cACT,QAAQ,aACR,WACA,SACA,SACA,gBACA,OAAO,WAAU,IAAA,IACd,OAAI,OAAA,IAT0C,CAAA,UAAA,WAAA,UAAA,aAAA,WAAA,WAAA,kBAAA,OAAA,CAUpD;AACG,SAAO,IAAI,QAAc,CAAC,SAAS,WAAU;AAEzC,UAAM,UAAO,OAAA,OAAA,CAAA,GAAQ,YAAY;AACjC,QAAI,CAAC,QAAQ,QAAQ;AACjB,cAAQ,SAAS;;AAGrB,QAAI;AACJ,aAAS,qBAAkB;AACvB,2BAAqB,MAAK;AAC1B,UAAI,CAAC,SAAS,QAAQ;AAClB,eAAM;;IAEd;AAEA,QAAI,CAAC,gBAAgB;AACjB,eAAS,iBAAiB,oBAAoB,kBAAkB;;AAGpE,QAAI,gBAAgB;AACpB,QAAI,aAAa;AACjB,aAAS,UAAO;AACZ,eAAS,oBAAoB,oBAAoB,kBAAkB;AACnE,aAAO,aAAa,UAAU;AAC9B,2BAAqB,MAAK;IAC9B;AAGA,oBAAW,QAAX,gBAAW,SAAA,SAAX,YAAa,iBAAiB,SAAS,MAAK;AACxC,cAAO;AACP,cAAO;IACX,CAAC;AAED,UAAMA,SAAQ,eAAU,QAAV,eAAU,SAAV,aAAc,OAAO;AACnC,UAAM,SAAS,gBAAW,QAAX,gBAAW,SAAX,cAAe;AAC9B,mBAAe,SAAM;;AACjB,6BAAuB,IAAI,gBAAe;AAC1C,UAAI;AACA,cAAM,WAAW,MAAMA,OAAM,OAAK,OAAA,OAAA,OAAA,OAAA,CAAA,GAC3B,IAAI,GAAA,EACP,SACA,QAAQ,qBAAqB,OAAM,CAAA,CAAA;AAGvC,cAAM,OAAO,QAAQ;AAErB,cAAM,SAAS,SAAS,MAAM,SAAS,YAAY,QAAK;AACpD,cAAI,IAAI;AAEJ,oBAAQ,WAAW,IAAI;iBACpB;AAEH,mBAAO,QAAQ,WAAW;;QAElC,GAAG,WAAQ;AACP,0BAAgB;QACpB,GAAG,SAAS,CAAC,CAAC;AAEd,oBAAO,QAAP,YAAO,SAAA,SAAP,QAAO;AACP,gBAAO;AACP,gBAAO;eACF,KAAK;AACV,YAAI,CAAC,qBAAqB,OAAO,SAAS;AAEtC,cAAI;AAEA,kBAAM,YAAgBC,MAAA,YAAO,QAAP,YAAO,SAAA,SAAP,QAAU,GAAG,OAAC,QAAAA,QAAA,SAAAA,MAAI;AACxC,mBAAO,aAAa,UAAU;AAC9B,yBAAa,OAAO,WAAW,QAAQ,QAAQ;mBAC1C,UAAU;AAEf,oBAAO;AACP,mBAAO,QAAQ;;;;IAI/B;AAEA,WAAM;EACV,CAAC;AACL;AAEA,SAAS,cAAc,UAAkB;AACrC,QAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AACvD,MAAI,EAAC,gBAAW,QAAX,gBAAW,SAAA,SAAX,YAAa,WAAW,sBAAsB,IAAG;AAClD,UAAM,IAAI,MAAM,+BAA+B,sBAAsB,aAAa,WAAW,EAAE;;AAEvG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzJO,IAAM,aAAN,MAAM,oBAAmB,MAAM;EAMpC,YACE,QACA,MACA,MACA,SACO,KACP,SACA;AACA;MACE,WACE,cAAc,MAAM,OAAO,GAAG,KAAK,QAAA,OAAA,OAAQ,KAAK,UAAU,IAAI,CAAC;IACnE;AANO,SAAA,MAAA;AAOP,SAAK,OAAO;AACZ,SAAK,SAAS;AACd,SAAK,OAAO;AACZ,SAAK,OAAO;AACZ,SAAK,UAAU;EACjB;EAEA,aAAa,aACX,UACA,KACqB;AACrB,UAAM,SAAS,SAAS;AACxB,UAAM,UAAU,OAAO,YAAY,CAAC,GAAG,SAAS,QAAQ,QAAQ,CAAC,CAAC;AAClE,QAAI,OAA2B;AAC/B,QAAI,OAA2B;AAE/B,UAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AACvD,QAAI,CAAC,SAAS,UAAU;AACtB,UAAI,eAAe,YAAY,SAAS,kBAAkB,GAAG;AAC3D,eAAQ,MAAM,SAAS,KAAK;MAC9B,OAAO;AACL,eAAO,MAAM,SAAS,KAAK;MAC7B;IACF;AAEA,WAAO,IAAI,YAAW,QAAQ,MAAM,MAAM,SAAS,GAAG;EACxD;AACF;AAEO,IAAM,yBAAN,cAAqC,MAAM;EAChD,cAAc;AACZ,UAAM,4BAA4B;AAClC,SAAK,OAAO;EACd;AACF;AASO,IAAM,uBAAN,cAAmC,MAAM;EAC9C,cAAc;AACZ,UAAM,uDAAuD;AAC7D,SAAK,OAAO;EACd;AACF;AAEO,IAAM,qBAAN,cAAiC,MAAM;EAC5C,cAAc;AACZ,UAAM,+DAA+D;AACrE,SAAK,OAAO;EACd;AACF;AAEO,IAAM,0BAAN,cAAsC,MAAM;EACjD,cAAc;AACZ;MACE;IACF;AACA,SAAK,OAAO;EACd;AACF;AAEO,IAAM,qBAAN,cAAiC,MAAM;EAC5C,YAAY,gBAA0B;AACpC;MACE,kEAAkE,eAAe,KAAK,IAAI,CAAC;IAC7F;AACA,SAAK,OAAO;EACd;AACF;AAEO,IAAM,uBAAN,cAAmC,MAAM;EAC9C,YAAY,YAAoB;AAC9B,UAAM,WAAW,cAAA,OAAA,aAAc,SAAS,8BAA8B;AACtE,SAAK,OAAO;EACd;AACF;AASO,IAAM,sBAAN,cAAkC,MAAM;EAC7C,YAAY,KAAa,gBAA+B;AACtD,QAAI,MAAM,yCAAyC,GAAG;;AACtD,mBAAe,QAAQ,CAAC,MAAM;AAC5B,aAAO,KAAK,CAAC;;IACf,CAAC;AACD,WAAO;;AACP,WAAO;;AACP,UAAM,GAAG;EACX;AACF;AC5FA,IAAM,cAAc,CAAC,UAAkB,OAAO,KAAK;AACnD,IAAM,YAAY,CAAC,UAAkB,UAAU,UAAU,UAAU;AACnE,IAAM,cAAc,CAAC,UAAkB,OAAO,KAAK;AACnD,IAAM,YAAY,CAAC,UAAkB,KAAK,MAAM,KAAK;AACrD,IAAM,iBAAgC,CAAC,MAAc;AAE9C,IAAM,gBAAwB;EACnC,MAAM;EACN,MAAM;EACN,MAAM;EACN,MAAM;EACN,QAAQ;EACR,QAAQ;EACR,MAAM;EACN,OAAO;AACT;AAGO,SAAS,cACd,OACA,QACmB;AACnB,MAAI,IAAI;AACR,MAAI,OAAO;AACX,MAAI,MAAM;AACV,MAAI,SAAS;AACb,MAAI,OAAO;AACX,MAAI,IAAwB;AAE5B,WAAS,aAAa,GAAU,OAAe,KAAa;AAC1D,QAAI,MAAoB,EAAE,MAAM,OAAO,GAAG;AAC1C,UAAM,QAAQ,SAAS,OAAO;AAC9B,WAAO,SAAS,OAAO,GAAG,IAAI;EAChC;AAEA,WAAS,KAAK,GAAqC;AACjD,UAAM,KAAK,CAAC;AACZ,WAAO,IAAI,EAAE,QAAQ,KAAK;AACxB,aAAO,EAAE,CAAC;AACV,UAAI,QAAQ;AACV,YAAI,SAAS,MAAM;AACjB,iBAAO,EAAE,EAAE,CAAC;QACd,WAAW,SAAS,KAAK;AACvB,aAAG,KAAK,SAAS,OAAO,GAAG,IAAI,GAAG;AAClC,gBAAM;AACN,mBAAS,EAAE,IAAI,CAAC,MAAM;AACtB,iBAAO,IAAI;QACb,OAAO;AACL,iBAAO;QACT;MACF,WAAW,SAAS,KAAK;AACvB,iBAAS;MACX,WAAW,SAAS,KAAK;AACvB,eAAO,EAAE;AACT,WAAG,KAAK,KAAK,CAAC,CAAC;MACjB,WAAW,SAAS,KAAK;AACvB,iBAAS;AACT,eAAO,KAAK,GAAG,KAAK,aAAa,GAAG,MAAM,CAAC,CAAC;AAC5C,eAAO,IAAI;AACX;MACF,WAAW,SAAS,OAAO,MAAM,OAAO,MAAM,KAAK;AACjD,WAAG,KAAK,aAAa,GAAG,MAAM,CAAC,CAAC;AAChC,eAAO,IAAI;MACb;AACA,UAAI;IACN;AACA,WAAO,KAAK,GAAG,KAAK,GAAG,KAAK,aAAa,GAAG,MAAM,IAAI,CAAC,CAAC,CAAC;AACzD,WAAO;EACT;AAEA,SAAO,KAAK,KAAK,EAAE,CAAC;AACtB;AAEO,IAAM,gBAAN,MAA4C;EAGjD,YACE,QACA,aACA;AAIA,SAAK,SAAS,eAAA,eAAA,CAAA,GAAK,aAAA,GAAkB,MAAA;AACrC,SAAK,cAAc;EACrB;EAEA,MAAc,UAAkB,QAAwB;AACtD,WAAO,KAAK,MAAM,UAAU,CAAC,KAAK,UAAU;AAM1C,WACG,QAAQ,WAAW,QAAQ,gBAC5B,OAAO,UAAU,YACjB,UAAU,MACV;AACA,eAAO,KAAK,sBAAsB,OAAO,MAAM;MACjD;AACA,aAAO;IACT,CAAC;EACH;;;;;EAMA,kBACE,UACA,QACe;AACf,WAAO,SAAS,IAAI,CAAC,YAAY;AAC/B,YAAM,MAAM;AAGZ,UAAI,IAAI,SAAS,OAAO,IAAI,UAAU,YAAY,IAAI,UAAU,MAAM;AACpE,YAAI,QAAQ,KAAK,sBAAsB,IAAI,OAAO,MAAM;MAC1D;AAGA,UACE,IAAI,aACJ,OAAO,IAAI,cAAc,YACzB,IAAI,cAAc,MAClB;AACA,YAAI,YAAY,KAAK,sBAAsB,IAAI,WAAW,MAAM;MAClE;AAEA,aAAO;IACT,CAAC;EACH;;;;EAKQ,sBACN,OACA,QACuB;AACvB,UAAM,MAAM;AACZ,WAAO,KAAK,GAAG,EAAE,QAAQ,CAAC,QAAQ;AAChC,UAAI,GAAG,IAAI,KAAK,SAAS,KAAK,IAAI,GAAG,GAAoB,MAAM;IACjE,CAAC;AAED,WAAO,KAAK,cAAc,KAAK,YAAY,GAAG,IAAI;EACpD;;EAGQ,SACN,KACA,OACA,QACyB;AAnL7B,QAAA;AAoLI,UAAM,aAAa,OAAO,GAAG;AAC7B,QAAI,CAAC,YAAY;AAGf,aAAO;IACT;AAGA,UAA2D,KAAA,YAAnD,EAAA,MAAM,KAAK,MAAM,WA5L7B,IA4L+D,IAAnB,iBAAA,UAAmB,IAAnB,CAAhC,QAAW,MAAA,CAAA;AAKnB,UAAM,cAAa,KAAA,KAAK,OAAO,GAAG,MAAf,OAAA,KAAoB;AACvC,UAAM,SAAS,mBAAmB,YAAY,YAAY,GAAG;AAE7D,QAAI,cAAc,aAAa,GAAG;AAEhC,YAAM,wBAAwB;QAC5B,CAACC,QAAO,MAAM,cAAcA,QAAO,MAAM;QACzC;QACA;MACF;AACA,aAAO,sBAAsB,KAAK;IACpC;AAEA,WAAO,OAAO,OAAO,cAAc;EACrC;AACF;AAEA,SAAS,mBACP,QACA,YACA,YACmC;AAtNrC,MAAA;AAuNE,QAAM,aAAa,GAAE,KAAA,WAAW,aAAX,OAAA,KAAuB;AAI5C,SAAO,CAAC,UAAyB;AAC/B,QAAI,UAAU,MAAM;AAClB,UAAI,CAAC,YAAY;AACf,cAAM,IAAI,qBAAqB,cAAA,OAAA,aAAc,SAAS;MACxD;AACA,aAAO;IACT;AACA,WAAO,OAAO,OAAO,UAAU;EACjC;AACF;AC5MO,SAAS,gBAAgB,YAA4B;AAE1D,QAAM,UAAU,WAAW,QAAQ,MAAM,IAAI;AAC7C,SAAO,IAAI,OAAO;AACpB;AAiKO,SAAS,kBACd,aACA,QACQ;AACR,MAAI,CAAC,eAAe,CAAC,OAAQ,QAAO,eAAA,OAAA,cAAe;AAGnD,QAAM,cAAc,oBAAI,IAAI;IAC1B;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,CAAC;AAGD,QAAM,eAAsD,CAAC;AAG7D,MAAI,MAAM;AACV,SAAO,MAAM,YAAY,QAAQ;AAC/B,UAAM,KAAK,YAAY,GAAG;AAC1B,QAAI,OAAO,OAAO,OAAO,KAAK;AAC5B,YAAM,QAAQ;AACd,YAAM,YAAY;AAClB;AAEA,aAAO,MAAM,YAAY,QAAQ;AAC/B,YAAI,YAAY,GAAG,MAAM,WAAW;AAClC,cAAI,YAAY,MAAM,CAAC,MAAM,WAAW;AACtC,mBAAO;UACT,OAAO;AACL;AACA;UACF;QACF,OAAO;AACL;QACF;MACF;AACA,mBAAa,KAAK,EAAE,OAAO,KAAK,IAAI,CAAC;IACvC,OAAO;AACL;IACF;EACF;AAGA,QAAM,mBAAmB,CAACC,SAAyB;AACjD,WAAO,aAAa,KAAK,CAAC,UAAUA,QAAO,MAAM,SAASA,OAAM,MAAM,GAAG;EAC3E;AAUA,QAAM,oBACJ,IAAA,OAAC,6DAA0D,GAAC;AAE9D,SAAO,YAAY,QAAQ,mBAAmB,CAAC,OAAO,KAAK,WAAW;AAEpE,QAAI,iBAAiB,MAAM,GAAG;AAC5B,aAAO;IACT;AAGA,QAAI,YAAY,IAAI,MAAM,YAAY,CAAC,GAAG;AACxC,aAAO;IACT;AAIA,QAAI,MAAM,WAAW,GAAG,GAAG;AACzB,aAAO;IACT;AAGA,UAAM,UAAU,OAAO,KAAK;AAC5B,WAAO;EACT,CAAC;AACH;AC3RO,SAAS,gBACd,SAC6B;AAC7B,SAAO,SAAS;AAClB;AAmBO,SAAS,iBACd,SAC2B;AAC3B,SAAO,CAAC,gBAAgB,OAAO;AACjC;AAEO,SAAS,kBACd,SACkD;AAClD,SAAO,iBAAiB,OAAO,KAAK,QAAQ,QAAQ,YAAY;AAClE;AAOO,SAAS,UAAU,SAA6C;AACrE,MAAI,QAAQ,QAAQ,WAAW,aAAc;AAC7C,QAAM,MAAM,QAAQ,QAAQ;AAC5B,SAAO,MAAO,GAAG,GAAG,OAAkB;AACxC;AASO,SAAS,oBACd,MACA,UACS;AACT,QAAM,MAAM,OAAO,IAAI;AACvB,QAAM,OAAO,OAAO,SAAS,IAAI;AACjC,QAAM,OAAO,OAAO,SAAS,IAAI;AACjC,QAAM,MAAM,SAAS,SAAS,IAAI,MAAM;AAQxC,SAAO,MAAM,QAAS,MAAM,QAAQ,CAAC,IAAI,SAAS,GAAG;AACvD;AChGO,IAAM,2BAA2B;AACjC,IAAM,sBAAsB;AAC5B,IAAM,2BAA2B;AACjC,IAAM,sBAAsB;AAC5B,IAAM,0BAA0B;AAChC,IAAM,sBAAsB;AAC5B,IAAM,gCAAgC;AACtC,IAAM,6BAA6B;AACnC,IAAM,2BAA2B;AACjC,IAAM,mBAAmB;AACzB,IAAM,qBAAqB;AAC3B,IAAM,oBAAoB;AAC1B,IAAM,oBAAoB;AAC1B,IAAM,gBAAgB;AACtB,IAAM,qBAAqB;AAI3B,IAAM,oCAAoC;AAC1C,IAAM,uBAAuB;AAC7B,IAAM,+BAA+B;AACrC,IAAM,eAAe;AACrB,IAAM,uBAAuB;AAC7B,IAAM,qBAAqB;AAC3B,IAAM,qBAAqB;AAC3B,IAAM,sBAAsB;AAC5B,IAAM,wBAAwB;AAC9B,IAAM,4BAA4B;AAClC,IAAM,0BAA0B;AAChC,IAAM,6BAA6B;AAGnC,IAAM,iCAAgD;EAC3D;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;AACF;ACzBA,IAAM,0BAA0B,CAAC,GAAG;AAuB7B,IAAM,kBAAkB;EAC7B,cAAc;EACd,UAAU;;EACV,YAAY;EACZ,YAAY;;AACd;AAOO,SAAS,sBAAsB,YAAwC;AAC5E,MAAI,CAAC,WAAY,QAAO;AAGxB,QAAM,gBAAgB,OAAO,UAAU;AACvC,MAAI,OAAO,SAAS,aAAa,KAAK,gBAAgB,GAAG;AACvD,WAAO,gBAAgB;EACzB;AAGA,QAAM,YAAY,KAAK,MAAM,UAAU;AACvC,MAAI,CAAC,MAAM,SAAS,GAAG;AAErB,UAAM,UAAU,YAAY,KAAK,IAAI;AACrC,WAAO,KAAK,IAAI,GAAG,KAAK,IAAI,SAAS,IAAQ,CAAC;EAChD;AAEA,SAAO;AACT;AAEO,SAAS,uBACd,aACA,iBAAiC,iBACnB;AACd,QAAM;IACJ;IACA;IACA;IACA,OAAAC,SAAQ;IACR;IACA,aAAa;EACf,IAAI;AACJ,SAAO,UAAU,SAAsD;AAzFzE,QAAA;AA0FI,UAAM,MAAM,KAAK,CAAC;AAClB,UAAM,UAAU,KAAK,CAAC;AAEtB,QAAI,QAAQ;AACZ,QAAI,UAAU;AAEd,WAAO,MAAM;AACX,UAAI;AACF,cAAM,SAAS,MAAM,YAAY,GAAG,IAAI;AACxC,YAAI,OAAO,IAAI;AACb,iBAAO;QACT;AAEA,cAAM,MAAM,MAAM,WAAW,aAAa,QAAQ,IAAI,SAAS,CAAC;AAEhE,cAAM;MACR,SAAS,GAAG;AACV,2BAAA,OAAA,SAAA,gBAAA;AACA,aAAI,KAAA,WAAA,OAAA,SAAA,QAAS,WAAT,OAAA,SAAA,GAAiB,SAAS;AAC5B,gBAAM,IAAI,uBAAuB;QACnC,WACE,aAAa,cACb,CAAC,wBAAwB,SAAS,EAAE,MAAM,KAC1C,EAAE,UAAU,OACZ,EAAE,SAAS,KACX;AAEA,gBAAM;QACR,OAAO;AAEL;AACA,cAAI,UAAU,YAAY;AACxB,gBAAIA,QAAO;AACT,sBAAQ;gBACN,wBAAwB,OAAO,IAAI,UAAU;cAC/C;YACF;AACA,kBAAM;UACR;AAMA,gBAAM,kBACJ,aAAa,cAAc,EAAE,UACzB,sBAAsB,EAAE,QAAQ,aAAa,CAAC,IAC9C;AAKN,gBAAM,SAAS,KAAK,OAAO,IAAI;AAC/B,gBAAM,kBAAkB,KAAK,IAAI,QAAQ,QAAQ;AAGjD,gBAAM,SAAS,KAAK,IAAI,iBAAiB,eAAe;AAExD,cAAIA,QAAO;AACT,kBAAM,SAAS,kBAAkB,IAAI,kBAAkB;AACvD,oBAAQ;cACN,kBAAkB,OAAO,UAAU,MAAM,OAAO,MAAM,eAAe,eAAe,qBAAqB,eAAe;YAC1H;UACF;AAGA,gBAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,MAAM,CAAC;AAG1D,kBAAQ,KAAK,IAAI,QAAQ,YAAY,QAAQ;QAC/C;MACF;IACF;EACF;AACF;AAEA,IAAM,uBAAuB,CAAC,KAAK,KAAK,GAAG;AAGpC,SAAS,gCAAgC,aAA2B;AACzE,SAAO,UAAU,SAAsD;AA1KzE,QAAA,IAAA;AA2KI,UAAM,MAAM,KAAK,CAAC;AAClB,UAAM,MAAM,MAAM,YAAY,GAAG,IAAI;AACrC,QAAI;AACF,UAAI,IAAI,SAAS,OAAO,qBAAqB,SAAS,IAAI,MAAM,GAAG;AACjE,eAAO;MACT;AAEA,YAAM,OAAO,MAAM,IAAI,KAAK;AAC5B,aAAO,IAAI,SAAS,MAAM,GAAG;IAC/B,SAAS,KAAK;AACZ,WAAI,MAAA,KAAA,KAAK,CAAC,MAAN,OAAA,SAAA,GAAS,WAAT,OAAA,SAAA,GAAiB,SAAS;AAC5B,cAAM,IAAI,uBAAuB;MACnC;AAEA,YAAM,IAAI;QACR,IAAI;QACJ;QACA;QACA,OAAO,YAAY,CAAC,GAAG,IAAI,QAAQ,QAAQ,CAAC,CAAC;QAC7C,IAAI,SAAS;QACb,eAAe,QACX,IAAI,UACJ,OAAO,QAAQ,WACb,MACA;MACR;IACF;EACF;AACF;AAMA,IAAM,wBAAwB;EAC5B,qBAAqB;AACvB;AAWO,SAAS,2BACd,aACA,kBAAwC,uBAC1B;AACd,QAAM,EAAE,oBAAoB,IAAI;AAEhC,MAAI;AAEJ,QAAM,iBAAiB,UAAU,SAAyC;AACxE,UAAM,MAAM,KAAK,CAAC,EAAE,SAAS;AAI7B,UAAM,oBAAoB,iBAAA,OAAA,SAAA,cAAe,QAAQ,GAAG,IAAA;AACpD,QAAI,mBAAmB;AACrB,aAAO;IACT;AAIA,qBAAA,OAAA,SAAA,cAAe,MAAA;AACf,oBAAgB;AAGhB,UAAM,WAAW,MAAM,YAAY,GAAG,IAAI;AAC1C,UAAM,UAAU,gBAAgB,KAAK,QAAQ;AAC7C,QAAI,SAAS;AACX,sBAAgB,IAAI,cAAc;QAChC;QACA,uBAAuB;QACvB,KAAK;QACL,aAAa,KAAK,CAAC;MACrB,CAAC;IACH;AAEA,WAAO;EACT;AAEA,SAAO;AACT;AAEO,IAAM,kCAAkC;EAC7C;EACA;AACF;AAEO,IAAM,8BAA8B,CAAC,iBAAiB;AAEtD,IAAM,iCAAiC,CAAC,iBAAiB;AAEzD,SAAS,oCACd,aACc;AACd,SAAO,UAAU,SAAyC;AACxD,UAAM,WAAW,MAAM,YAAY,GAAG,IAAI;AAE1C,QAAI,SAAS,IAAI;AAEf,YAAM,UAAU,SAAS;AACzB,YAAM,iBAAgC,CAAC;AAEvC,YAAM,oBAAoB,CAAC,oBACzB,eAAe,KAAK,GAAG,gBAAgB,OAAO,CAAC,MAAM,CAAC,QAAQ,IAAI,CAAC,CAAC,CAAC;AAEvE,YAAM,QAAQ,KAAK,CAAC;AACpB,YAAM,YAAY,MAAM,SAAS;AACjC,YAAM,MAAM,IAAI,IAAI,SAAS;AAG7B,YAAM,oBAAoB;QACxB;QACA;QACA;QACA;QACA;MACF,EAAE,KAAK,CAAC,MAAM,IAAI,aAAa,IAAI,CAAC,CAAC;AACrC,UAAI,mBAAmB;AACrB,eAAO;MACT;AAEA,wBAAkB,+BAA+B;AACjD,UAAI,IAAI,aAAa,IAAI,gBAAgB,MAAM,QAAQ;AACrD,0BAAkB,2BAA2B;MAC/C;AAEA,UACE,CAAC,IAAI,aAAa,IAAI,gBAAgB,KACtC,IAAI,aAAa,IAAI,gBAAgB,MAAM,SAC3C;AACA,0BAAkB,8BAA8B;MAClD;AAEA,UAAI,eAAe,SAAS,GAAG;AAC7B,cAAM,IAAI,oBAAoB,WAAW,cAAc;MACzD;IACF;AAEA,WAAO;EACT;AACF;AA7TA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AA+TA,IAAM,gBAAN,MAAoB;EAUlB,YAAY,SAKT;AAfL,iBAAA,MAAA,wBAAA;AACE,iBAAA,MAAS,YAAA;AACT,iBAAA,MAAS,sBAAA;AACT,iBAAA,MAAS,gBAAiB,oBAAI,IAG5B,CAAA;AACF,iBAAA,MAAA,aAAA;AACA,iBAAA,MAAA,aAAA;AAvUF,QAAA;AA+UI,iBAAA,MAAK,eACH,KAAA,QAAQ,gBAAR,OAAA,KACC,IAAI,SAAmC,MAAM,GAAG,IAAI,CAAA;AACvD,iBAAA,MAAK,wBAAyB,QAAQ,qBAAA;AACtC,iBAAA,MAAK,eAAgB,QAAQ,IAAI,SAAS,CAAA;AAC1C,iBAAA,MAAK,eAAgB,aAAA,MAAK,aAAA,CAAA;AAC1B,oBAAA,MAAK,0BAAA,WAAA,EAAL,KAAA,MAAe,QAAQ,KAAK,QAAQ,WAAA;EACtC;EAEA,QAAc;AACZ,iBAAA,MAAK,cAAA,EAAe,QAAQ,CAAC,CAAC,GAAG,OAAO,MAAM,QAAQ,MAAM,CAAC;AAC7D,iBAAA,MAAK,cAAA,EAAe,MAAM;EAC5B;EAEA,WAAW,MAA0D;AACnE,UAAM,MAAM,KAAK,CAAC,EAAE,SAAS;AAE7B,UAAM,QAAQ,aAAA,MAAK,cAAA,EAAe,IAAI,GAAG;AAIzC,QAAI,CAAC,SAAS,QAAQ,aAAA,MAAK,aAAA,EAAe;AAE1C,UAAM,CAAC,SAAS,OAAO,IAAI;AAE3B,QAAI,QAAQ,OAAO,SAAS;AAC1B,mBAAA,MAAK,cAAA,EAAe,OAAO,GAAG;AAC9B;IACF;AACA,iBAAA,MAAK,cAAA,EAAe,OAAO,GAAG;AAG9B,YACG,KAAK,CAAC,aAAa;AAClB,YAAM,UAAU,gBAAgB,KAAK,QAAQ;AAC7C,mBAAA,MAAK,eAAgB,OAAA;AACrB,UACE,aAAA,MAAK,aAAA,KACL,CAAC,aAAA,MAAK,cAAA,EAAe,IAAI,aAAA,MAAK,aAAA,CAAa,GAC3C;AACA,wBAAA,MAAK,0BAAA,WAAA,EAAL,KAAA,MAAe,aAAA,MAAK,aAAA,GAAe,KAAK,CAAC,CAAA;MAC3C;IACF,CAAC,EACA,MAAM,MAAM;IAAC,CAAC;AAEjB,WAAO;EACT;AAsCF;AAnGW,eAAA,oBAAA,QAAA;AACA,yBAAA,oBAAA,QAAA;AACA,iBAAA,oBAAA,QAAA;AAIT,gBAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AARF,2BAAA,oBAAA,QAAA;AAgEE,cAAS,YAAI,MAAsC;AA/XrD,MAAA,IAAA;AAgYI,QAAM,MAAM,KAAK,CAAC,EAAE,SAAS;AAG7B,MAAI,aAAA,MAAK,cAAA,EAAe,QAAQ,aAAA,MAAK,sBAAA,EAAwB;AAI7D,QAAM,UAAU,IAAI,gBAAgB;AAEpC,MAAI;AACF,UAAM,EAAE,QAAQ,QAAQ,IAAI,aAAa,UAAS,KAAA,KAAK,CAAC,MAAN,OAAA,SAAA,GAAS,MAAM;AACjE,UAAM,UAAU,aAAA,MAAK,YAAA,EAAL,KAAA,MAAkB,KAAK,cAAA,eAAA,CAAA,IAAM,KAAA,KAAK,CAAC,MAAN,OAAA,KAAW,CAAC,CAAA,GAAlB,EAAsB,OAAO,CAAA,CAAA;AACpE,iBAAA,MAAK,cAAA,EAAe,IAAI,KAAK,CAAC,SAAS,OAAO,CAAC;AAC/C,YACG,KAAK,CAAC,aAAa;AAElB,UAAI,CAAC,SAAS,MAAM,QAAQ,OAAO,QAAS;AAE5C,YAAM,UAAU,gBAAgB,KAAK,QAAQ;AAG7C,UAAI,CAAC,WAAW,YAAY,KAAK;AAC/B,qBAAA,MAAK,eAAgB,MAAA;AACrB;MACF;AAEA,mBAAA,MAAK,eAAgB,OAAA;AACrB,aAAO,gBAAA,MAAK,0BAAA,WAAA,EAAL,KAAA,MAAe,SAAS,KAAK,CAAC,CAAA;IACvC,CAAC,EACA,MAAM,MAAM;IAAC,CAAC,EACd,QAAQ,OAAO;EACpB,SAAS,GAAG;EAEZ;AACF;AAMF,SAAS,gBAAgB,KAAa,KAA8B;AAClE,QAAM,cAAc,IAAI,QAAQ,IAAI,mBAAmB;AACvD,QAAM,aAAa,IAAI,QAAQ,IAAI,wBAAwB;AAC3D,QAAM,aAAa,IAAI,QAAQ,IAAI,uBAAuB;AAI1D,MAAI,CAAC,eAAe,CAAC,cAAc,WAAY;AAE/C,QAAM,UAAU,IAAI,IAAI,GAAG;AAI3B,MAAI,QAAQ,aAAa,IAAI,gBAAgB,EAAG;AAKhD,QAAM,gBAAgB,QAAQ,aAAa,IAAI,0BAA0B;AACzE,MAAI,iBAAiB,gBAAgB,eAAe;AAClD,YAAQ;MACN,kLAEoC,WAAW;IAGjD;AACA;EACF;AAEA,UAAQ,aAAa,IAAI,0BAA0B,WAAW;AAC9D,UAAQ,aAAa,IAAI,oBAAoB,UAAU;AACvD,UAAQ,aAAa,KAAK;AAC1B,SAAO,QAAQ,SAAS;AAC1B;AAOA,SAAS,aACP,SACA,cAIA;AACA,MAAI,UAAU;AACd,MAAI,CAAC,cAAc;EAEnB,WAAW,aAAa,SAAS;AAE/B,YAAQ,MAAM;EAChB,OAAO;AAGL,UAAM,cAAc,MAAM,QAAQ,MAAM;AACxC,iBAAa,iBAAiB,SAAS,aAAa;MAClD,MAAM;MACN,QAAQ,QAAQ;IAClB,CAAC;AACD,cAAU,MAAM,aAAa,oBAAoB,SAAS,WAAW;EACvE;AAEA,SAAO;IACL,QAAQ,QAAQ;IAChB;EACF;AACF;AAEA,SAAS,OAAO;AAAC;AC9dV,SAAS,kBACd,MACA,cACQ;AACR,UAAQ,KAAK,MAAM;IACjB,KAAK,OAAO;AAEV,YAAM,eAAe,eACjB,aAAa,KAAK,MAAM,IACxB,KAAK;AACT,aAAO,gBAAgB,YAAY;IACrC;IACA,KAAK;AACH,aAAO,IAAI,KAAK,UAAU;IAC5B,KAAK;AACH,aAAO,gBAAgB,MAAM,YAAY;IAC3C,SAAS;AAEP,YAAM,cAAqB;AAC3B,YAAM,IAAI,MAAM,4BAA4B,KAAK,UAAU,WAAW,CAAC,EAAE;IAC3E;EACF;AACF;AAKA,SAAS,gBACP,MACA,cACQ;AACR,QAAM,OAAO,KAAK,KAAK,IAAI,CAAC,QAAQ,kBAAkB,KAAK,YAAY,CAAC;AAExE,UAAQ,KAAK,MAAM;IAEjB,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC,MAAM,KAAK,CAAC,CAAC;IAChC,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC,MAAM,KAAK,CAAC,CAAC;IAChC,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC,OAAO,KAAK,CAAC,CAAC;IACjC,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC,MAAM,KAAK,CAAC,CAAC;IAChC,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC,OAAO,KAAK,CAAC,CAAC;IAGjC,KAAK;AACH,aAAO,KAAK,IAAI,CAAC,MAAM,IAAI,CAAC,GAAG,EAAE,KAAK,OAAO;IAC/C,KAAK;AACH,aAAO,KAAK,IAAI,CAAC,MAAM,IAAI,CAAC,GAAG,EAAE,KAAK,MAAM;IAC9C,KAAK;AACH,aAAO,QAAQ,KAAK,CAAC,CAAC;IAGxB,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC,UAAU,KAAK,CAAC,CAAC;IACpC,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC,SAAS,KAAK,CAAC,CAAC;IACnC,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC,UAAU,KAAK,CAAC,CAAC;IACpC,KAAK;IACL,KAAK;AACH,aAAO,GAAG,KAAK,CAAC,CAAC;IAGnB,KAAK;AACH,aAAO,SAAS,KAAK,CAAC,CAAC;IACzB,KAAK;AACH,aAAO,SAAS,KAAK,CAAC,CAAC;IACzB,KAAK;AACH,aAAO,UAAU,KAAK,CAAC,CAAC;IAC1B,KAAK;AACH,aAAO,UAAU,KAAK,KAAK,IAAI,CAAC;IAGlC,KAAK;AACH,aAAO,YAAY,KAAK,KAAK,IAAI,CAAC;IAEpC;AACE,YAAM,IAAI,MAAM,qBAAqB,KAAK,IAAI,EAAE;EACpD;AACF;AAgBO,SAAS,eACd,SACA,cACQ;AACR,SAAO,QACJ,IAAI,CAAC,WAAW;AACf,UAAM,eAAe,eACjB,aAAa,OAAO,MAAM,IAC1B,OAAO;AACX,QAAI,MAAM,gBAAgB,YAAY;AACtC,QAAI,OAAO,cAAc,OAAQ,QAAO;AACxC,QAAI,OAAO,UAAU,QAAS,QAAO;AACrC,QAAI,OAAO,UAAU,OAAQ,QAAO;AACpC,WAAO;EACT,CAAC,EACA,KAAK,IAAI;AACd;AE3HO,IAAM,qBAAN,MAAyB;EAoD9B,cAAc;AAnDd,SAAQ,OAA+C,CAAC;AACxD,SAAQ,MAAc;AACtB,SAAiB,aAAa;AAkD5B,SAAK,KAAK;EACZ;EAjDA,iBAAiB,UAAiC;AAChD,UAAM,QAAQ,KAAK,KAAK,QAAQ;AAChC,QAAI,OAAO;AAET,YAAM,WAAW,KAAK,IAAI;AAC1B,WAAK,KAAK;AACV,aAAO,MAAM;IACf;AACA,WAAO;EACT;EAEA,YAAY,UAAkB,QAAsB;AAClD,SAAK,KAAK,QAAQ,IAAI,EAAE,eAAe,QAAQ,UAAU,KAAK,IAAI,EAAE;AAEpE,UAAM,OAAO,OAAO,KAAK,KAAK,IAAI;AAClC,QAAI,KAAK,SAAS,KAAK,KAAK;AAC1B,YAAM,SAAS,KAAK;QAAO,CAAC,KAAK,MAC/B,KAAK,KAAK,CAAC,EAAE,WAAW,KAAK,KAAK,GAAG,EAAE,WAAW,IAAI;MACxD;AACA,aAAO,KAAK,KAAK,MAAM;IACzB;AAEA,SAAK,KAAK;EACZ;EAEQ,OAAa;AACnB,QAAI,OAAO,iBAAiB,YAAa;AACzC,QAAI;AACF,mBAAa,QAAQ,KAAK,YAAY,KAAK,UAAU,KAAK,IAAI,CAAC;IACjE,SAAQ,GAAA;IAER;EACF;EAEQ,OAAa;AACnB,QAAI,OAAO,iBAAiB,YAAa;AACzC,QAAI;AACF,YAAM,SAAS,aAAa,QAAQ,KAAK,UAAU;AACnD,UAAI,QAAQ;AACV,aAAK,OAAO,KAAK,MAAM,MAAM;MAC/B;IACF,SAAQ,GAAA;AAEN,WAAK,OAAO,CAAC;IACf;EACF;EAMA,QAAc;AACZ,SAAK,OAAO,CAAC;AACb,SAAK,KAAK;EACZ;AACF;AAGO,IAAM,qBAAqB,IAAI,mBAAmB;ACvDlD,IAAM,kBAAN,MAAsB;EAS3B,cAAc;AARd,SAAQ,OAAsC,CAAC;AAC/C,SAAiB,aAAa;AAC9B,SAAiB,WAAW;AAC5B,SAAiB,aAAa;AAC9B,SAAiB,kBAAkB;AACnC,SAAQ,gBAAgB;AAItB,SAAK,KAAK;AACV,SAAK,QAAQ;EACf;;;;;;EAOA,eAAe,UAAkB,QAAsB;AACrD,SAAK,KAAK,QAAQ,IAAI;MACpB,WAAW,KAAK,IAAI;MACpB;IACF;AAGA,UAAM,OAAO,OAAO,KAAK,KAAK,IAAI;AAClC,QAAI,KAAK,SAAS,KAAK,YAAY;AACjC,YAAM,SAAS,KAAK;QAAO,CAAC,KAAK,MAC/B,KAAK,KAAK,CAAC,EAAE,YAAY,KAAK,KAAK,GAAG,EAAE,YAAY,IAAI;MAC1D;AACA,aAAO,KAAK,KAAK,MAAM;IACzB;AAEA,SAAK,aAAa;EACpB;;;;;EAMQ,eAAqB;AAC3B,UAAM,MAAM,KAAK,IAAI;AACrB,UAAM,qBAAqB,MAAM,KAAK;AAEtC,QAAI,sBAAsB,KAAK,iBAAiB;AAE9C,WAAK,gBAAgB;AACrB,WAAK,KAAK;IACZ,WAAW,CAAC,KAAK,kBAAkB;AAEjC,YAAM,QAAQ,KAAK,kBAAkB;AACrC,WAAK,mBAAmB,WAAW,MAAM;AACvC,aAAK,gBAAgB,KAAK,IAAI;AAC9B,aAAK,mBAAmB;AACxB,aAAK,KAAK;MACZ,GAAG,KAAK;IACV;EAEF;;;;;;;EAQA,sBAAsB,UAAiC;AACrD,UAAM,QAAQ,KAAK,KAAK,QAAQ;AAChC,QAAI,CAAC,OAAO;AACV,aAAO;IACT;AAEA,UAAM,MAAM,KAAK,IAAI,IAAI,MAAM;AAC/B,QAAI,OAAO,KAAK,UAAU;AACxB,aAAO;IACT;AAEA,WAAO,MAAM;EACf;;;;;EAMQ,UAAgB;AACtB,UAAM,MAAM,KAAK,IAAI;AACrB,UAAM,OAAO,OAAO,KAAK,KAAK,IAAI;AAClC,QAAI,WAAW;AAEf,eAAW,OAAO,MAAM;AACtB,YAAM,MAAM,MAAM,KAAK,KAAK,GAAG,EAAE;AACjC,UAAI,MAAM,KAAK,UAAU;AACvB,eAAO,KAAK,KAAK,GAAG;AACpB,mBAAW;MACb;IACF;AAEA,QAAI,UAAU;AACZ,WAAK,KAAK;IACZ;EACF;EAEQ,OAAa;AACnB,QAAI,OAAO,iBAAiB,YAAa;AACzC,QAAI;AACF,mBAAa,QAAQ,KAAK,YAAY,KAAK,UAAU,KAAK,IAAI,CAAC;IACjE,SAAQ,GAAA;IAER;EACF;EAEQ,OAAa;AACnB,QAAI,OAAO,iBAAiB,YAAa;AACzC,QAAI;AACF,YAAM,SAAS,aAAa,QAAQ,KAAK,UAAU;AACnD,UAAI,QAAQ;AACV,aAAK,OAAO,KAAK,MAAM,MAAM;MAC/B;IACF,SAAQ,GAAA;AAEN,WAAK,OAAO,CAAC;IACf;EACF;;;;;EAMA,QAAc;AACZ,SAAK,OAAO,CAAC;AACb,QAAI,KAAK,kBAAkB;AACzB,mBAAa,KAAK,gBAAgB;AAClC,WAAK,mBAAmB;IAC1B;AACA,SAAK,KAAK;EACZ;AACF;AAGO,IAAM,kBAAkB,IAAI,gBAAgB;AC7I5C,IAAM,kBAAN,MAAsB;EAAtB,cAAA;AACL,SAAQ,kBAGJ,oBAAI,IAAI;AACZ,SAAQ,gBAA0C,oBAAI,IAAI;AAC1D,SAAQ,yBAAmD,oBAAI,IAAI;EAAA;;;;EAKnE,YAAY,UAA4B,MAAyB;AA1BnE,QAAA,IAAA,IAAA,IAAA;AA2BI,SAAK,gBAAgB,IAAI,SAAS,eAAe;MAC/C,MAAM,OAAO,SAAS,IAAI;MAC1B,MAAM,OAAO,SAAS,IAAI;MAC1B,UAAU,SAAS,SAAS,IAAI,MAAM;MACtC;IACF,CAAC;AACD,UAAM,WACJ,MAAA,KAAA,KAAK,cACF,IAAI,OAAO,SAAS,IAAI,CAAC,MAD5B,OAAA,SAAA,GAEI,IAAI,SAAS,aAAA,MAFjB,OAAA,KAEmC,oBAAI,IAAI,CAAC,SAAS,aAAa,CAAC;AACrE,SAAK,cAAc,IAAI,OAAO,SAAS,IAAI,GAAG,OAAO;AACrD,UAAM,kBACJ,MAAA,KAAA,KAAK,uBACF,IAAI,OAAO,SAAS,YAAY,CAAC,MADpC,OAAA,SAAA,GAEI,IAAI,SAAS,aAAA,MAFjB,OAAA,KAEmC,oBAAI,IAAI,CAAC,SAAS,aAAa,CAAC;AACrE,SAAK,uBAAuB;MAC1B,OAAO,SAAS,YAAY;MAC5B;IACF;EACF;;;;EAKA,eAAe,cAA4B;AACzC,SAAK,gBAAgB,OAAO,YAAY;EAC1C;;;;;EAMA,oBAAoB,SAA+C;AACjE,UAAM,QAAQ,QAAQ,QAAQ,SAAS,CAAC;AACxC,QAAI,MAAM,WAAW,EAAG,QAAO;AAE/B,UAAM,MAAM,KAAK,IAAI,GAAG,KAAK;AAE7B,eAAW,CAAC,MAAM,SAAS,KAAK,KAAK,cAAc,QAAQ,GAAG;AAC5D,UAAI,OAAO,MAAM;AACf,mBAAW,YAAY,WAAW;AAChC,eAAK,eAAe,QAAQ;QAC9B;MACF;IACF;AAEA,WAAO,CAAC,GAAG,KAAK,gBAAgB,OAAO,CAAC,EAAE;MACxC,CAAC,MAAM,EAAE,KAAK,IAAI,QAAQ,GAAG,KAAK,oBAAoB,KAAK,CAAC;IAC9D;EACF;EAEA,eAAe,gBAA8B;AAC3C,eAAW,CAAC,OAAO,SAAS,KAAK,KAAK,uBAAuB,QAAQ,GAAG;AACtE,UAAI,SAAS,gBAAgB;AAC3B,mBAAW,YAAY,WAAW;AAChC,eAAK,eAAe,QAAQ;QAC9B;MACF;IACF;EACF;AACF;AHdA,IAAM,kBAA0C,oBAAI,IAAI;EACtD;EACA;EACA;EACA;AACF,CAAC;AAwFD,eAAsB,aACpB,OACY;AACZ,MAAI,OAAO,UAAU,YAAY;AAC/B,WAAQ,MAA+B;EACzC;AACA,SAAO;AACT;AAKA,eAAe,iBACb,QAC+B;AAC/B,QAAM,UAAU,OAAO,QAAQ,MAAM;AACrC,QAAM,kBAAkB,MAAM,QAAQ;IACpC,QAAQ,IAAI,OAAO,CAAC,KAAK,KAAK,MAAM;AAClC,UAAI,UAAU,OAAW,QAAO,CAAC,KAAK,MAAS;AAC/C,YAAM,gBAAgB,MAAM,aAAa,KAAK;AAC9C,aAAO;QACL;QACA,MAAM,QAAQ,aAAa,IAAI,cAAc,KAAK,GAAG,IAAI;MAC3D;IACF,CAAC;EACH;AAEA,SAAO,OAAO;IACZ,gBAAgB,OAAO,CAAC,CAAC,GAAG,KAAK,MAAM,UAAU,MAAS;EAC5D;AACF;AAKA,eAAe,eACb,SACiC;AACjC,MAAI,CAAC,QAAS,QAAO,CAAC;AAEtB,QAAM,UAAU,OAAO,QAAQ,OAAO;AACtC,QAAM,kBAAkB,MAAM,QAAQ;IACpC,QAAQ,IAAI,OAAO,CAAC,KAAK,KAAK,MAAM,CAAC,KAAK,MAAM,aAAa,KAAK,CAAC,CAAC;EACtE;AAEA,SAAO,OAAO,YAAY,eAAe;AAC3C;AA8PA,SAAS,kBAAkB,KAAkB;AAC3C,QAAM,WAAW,IAAI,IAAI,IAAI,SAAS,IAAI,QAAQ;AAGlD,aAAW,CAAC,KAAK,KAAK,KAAK,IAAI,cAAc;AAC3C,QAAI,CAAC,+BAA+B,SAAS,GAAG,GAAG;AACjD,eAAS,aAAa,IAAI,KAAK,KAAK;IACtC;EACF;AAEA,WAAS,aAAa,KAAK;AAC3B,SAAO,SAAS,SAAS;AAC3B;AA9dA,IAAA;AAAA,IAAAC;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAwgBO,IAAM,cAAN,MAEP;EA2DE,YAAY,SAA+C;AA7DtD,iBAAA,MAAA,sBAAA;AASL,iBAAA,MAAA,QAAkB,IAAA;AAElB,iBAAA,MAASA,aAAAA;AACT,iBAAA,MAAS,eAAA;AACT,iBAAA,MAAS,cAAA;AAET,iBAAA,MAAS,cAAe,oBAAI,IAM1B,CAAA;AAEF,iBAAA,MAAA,UAAW,KAAA;AACX,iBAAA,MAAA,QAAS,QAAA;AACT,iBAAA,MAAA,WAAA;AACA,iBAAA,MAAA,gBAAA;AACA,iBAAA,MAAA,aAAA;AACA,iBAAA,MAAA,aAAuB,KAAA;AACvB,iBAAA,MAAA,cAAwB,IAAA;AACxB,iBAAA,MAAA,YAAsB,KAAA;AACtB,iBAAA,MAAA,YAAA;AACA,iBAAA,MAAA,KAAA;AACA,iBAAA,MAAA,OAAA;AACA,iBAAA,MAAA,QAAA;AACA,iBAAA,MAAA,uBAAA;AACA,iBAAA,MAAA,eAAgB,KAAA;AAChB,iBAAA,MAAA,YAAA;AACA,iBAAA,MAAA,oBAAA;AACA,iBAAA,MAAA,oBAAA;AACA,iBAAA,MAAA,eAAgB,QAAQ,QAAgB,CAAC,CAAC,CAAA;AAC1C,iBAAA,MAAA,kBAAmB,IAAI,gBAAgB,CAAA;AACvC,iBAAA,MAAA,yBAA0B,CAAA;AAC1B,iBAAA,MAAA,iBAAA;AACA,iBAAA,MAAA,yBAAA;AACA,iBAAA,MAAA,eAAA;AACA,iBAAA,MAAA,gBAAA;AACA,iBAAA,MAAA,2BAAA;AACA,iBAAA,MAAA,2BAA4B,GAAA;AAC5B,iBAAA,MAAA,iCAAkC,CAAA;AAClC,iBAAA,MAAA,yBAA0B,CAAA;AAC1B,iBAAA,MAAA,2BAA4B,KAAA;AAC5B,iBAAA,MAAA,sBAAuB,GAAA;AACvB,iBAAA,MAAA,qBAAsB,GAAA;AACtB,iBAAA,MAAA,iCAAA;AA9jBF,QAAA,IAAA,IAAA,IAAA;AAskBI,SAAK,UAAU,eAAA,EAAE,WAAW,KAAA,GAAS,OAAA;AACrC,oBAAgB,KAAK,OAAO;AAC5B,iBAAA,MAAK,cAAc,KAAA,KAAK,QAAQ,WAAb,OAAA,KAAuB,IAAA;AAC1C,iBAAA,MAAK,kBAAmB,EAAA;AACxB,iBAAA,MAAK,cAAe,KAAK,QAAQ,MAAA;AAIjC,QAAI;AAEJ,QAAI,QAAQ,cAAc;AACxB,YAAM,oBAAoB,CACxB,QAC0B;AAC1B,cAAM,SAAkC,CAAC;AACzC,mBAAW,CAAC,OAAO,KAAK,KAAK,OAAO,QAAQ,GAAG,GAAG;AAChD,gBAAM,SAAS,QAAQ,aAAc,OAAO,KAAK;AACjD,iBAAO,MAAM,IAAI;QACnB;AACA,eAAO;MACT;AAEA,oBAAc,QAAQ,cAClB,CAAC,QACC,QAAQ,YAAa,kBAAkB,GAAG,CAAC,IAC7C;IACN,OAAO;AACL,oBAAc,QAAQ;IACxB;AAEA,iBAAA,MAAK,gBAAiB,IAAI,cAAiB,QAAQ,QAAQ,WAAW,CAAA;AAEtE,iBAAA,MAAK,UAAW,KAAK,QAAQ,OAAA;AAC7B,iBAAA,MAAK,QAAQ,KAAA,KAAK,QAAQ,QAAb,OAAA,KAAoB,MAAA;AAEjC,UAAM,mBACJ,KAAA,QAAQ,gBAAR,OAAA,KACC,IAAI,SAAmC,MAAM,GAAG,IAAI;AAEvD,UAAM,cAAc,cAAA,eAAA,CAAA,IACd,KAAA,QAAQ,mBAAR,OAAA,KAA0B,eAAA,GADZ;MAElB,iBAAiB,MAAM;AA/mB7B,YAAAC,KAAAC;AAgnBQ,qBAAA,MAAK,YAAa,KAAA;AAClB,SAAAA,OAAAD,MAAA,QAAQ,mBAAR,OAAA,SAAAA,IAAwB,oBAAxB,OAAA,SAAAC,IAAA,KAAAD,GAAAA;MACF;IACF,CAAA;AACA,UAAM,yBAAyB;MAC7B;MACA;IACF;AAEA,iBAAA,MAAK,iBAAkB;MACrB,2BAA2B,sBAAsB;IACnD,CAAA;AAEA,iBAAA,MAAKD,eAAe,gCAAgC,aAAA,MAAK,eAAA,CAAe,CAAA;AAExE,oBAAA,MAAK,wBAAA,+BAAA,EAAL,KAAA,IAAA;EACF;EAEA,IAAI,cAAc;AAChB,WAAO,aAAA,MAAK,YAAA;EACd;EAEA,IAAI,QAAQ;AACV,WAAO,aAAA,MAAK,MAAA;EACd;EAEA,IAAI,aAAa;AACf,WAAO,aAAA,MAAK,WAAA;EACd;EAEA,IAAI,aAAa;AACf,WAAO,aAAA,MAAK,WAAA;EACd;EAEA,IAAI,OAAO;AACT,WAAO,aAAA,MAAK,KAAA;EACd;EAypBA,UACE,UACA,UAAkC,MAAM;EAAC,GACzC;AACA,UAAM,iBAAiB,KAAK,OAAO;AAEnC,iBAAA,MAAK,YAAA,EAAa,IAAI,gBAAgB,CAAC,UAAU,OAAO,CAAC;AACzD,QAAI,CAAC,aAAA,MAAK,QAAA,EAAU,iBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;AAEpB,WAAO,MAAM;AACX,mBAAA,MAAK,YAAA,EAAa,OAAO,cAAc;IACzC;EACF;EAEA,iBAAuB;AA3zCzB,QAAA;AA4zCI,iBAAA,MAAK,YAAA,EAAa,MAAM;AACxB,KAAA,KAAA,aAAA,MAAK,iCAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;EACF;;EAGA,eAAmC;AACjC,WAAO,aAAA,MAAK,aAAA;EACd;;EAGA,aAAqB;AACnB,QAAI,aAAA,MAAK,aAAA,MAAkB,OAAW,QAAO;AAC7C,WAAO,KAAK,IAAI,IAAI,aAAA,MAAK,aAAA;EAC3B;;EAGA,cAAuB;AACrB,WAAO,aAAA,MAAK,UAAA;EACd;;EAGA,YAAqB;AACnB,WAAO,CAAC,aAAA,MAAK,WAAA;EACf;EAEA,aAAsB;AACpB,WAAO,aAAA,MAAK,QAAA;EACd;EAEA,WAAoB;AAClB,WAAO,aAAA,MAAK,MAAA,MAAW;EACzB;;;;;;;EA2CA,MAAM,4BAA2C;AAt4CnD,QAAA,IAAA;AAu4CI,iBAAA,MAAK,eAAgB,IAAA;AACrB,QAAI,aAAA,MAAK,WAAA,KAAe,GAAC,KAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAA,GAA8B,OAAO,UAAS;AAGrE,OAAA,KAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAA,GAA8B,MAAM,4BAAA;IACtC;AACA,UAAM,gBAAA,MAAK,wBAAA,WAAA,EAAL,KAAA,IAAA;AACN,iBAAA,MAAK,eAAgB,KAAA;EACvB;;;;;;;;;;;;;;;EAqFA,MAAM,gBAAgB,MAGnB;AACD,QAAI,aAAA,MAAK,KAAA,MAAU,QAAQ;AACzB,YAAM,IAAI;QACR,0CAA0C,aAAA,MAAK,KAAA,CAAK;MACtD;IACF;AAEA,QAAI,CAAC,aAAA,MAAK,QAAA,EAAU,OAAM,gBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;AAI1B,UAAM,gBAAA,MAAK,wBAAA,mBAAA,EAAL,KAAA,IAAA;AAGN,qBAAA,MAAK,uBAAA,EAAL;AAEA,QAAI;AACF,UAAI,aAAA,MAAK,uBAAA,MAA4B,GAAG;AAEtC,wBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;MACF;AAEA,YAAM,EAAE,UAAU,KAAK,IAAI,MAAM,KAAK,cAAc,IAAI;AAExD,YAAM,sBAAuB,KAA2B,OAAO;QAC7D,EAAE,SAAS,eAAA,EAAE,SAAS,eAAA,GAAmB,QAAA,EAAW;QACpD,EAAE,SAAS,eAAA,EAAE,SAAS,aAAA,GAAiB,IAAA,EAAO;MAChD,CAAC;AAED,mBAAA,MAAK,gBAAA,EAAiB;QACpB;QACA,IAAI,IAAI,KAAK,IAAI,CAAC,YAAY,QAAQ,GAAG,CAAC;MAC5C;AACA,sBAAA,MAAK,wBAAA,aAAA,EAAL,KAAA,MAAiB,qBAAqB,KAAA;AAEtC,aAAO;QACL;QACA;MACF;IACF,UAAA;AAEE,uBAAA,MAAK,uBAAA,EAAL;AACA,UAAI,aAAA,MAAK,uBAAA,MAA4B,GAAG;AACtC,wBAAA,MAAK,wBAAA,SAAA,EAAL,KAAA,IAAA;MACF;IACF;EACF;;;;;;;;EASA,MAAM,cAAc,MAGjB;AAjiDL,QAAA;AAkiDI,UAAM,EAAE,UAAU,eAAe,IAAI,MAAM,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,MACzC,KAAK,QAAQ,KACb,MACA,IAAA;AAGF,UAAM,WAAW,MAAM,aAAA,MAAKA,aAAAA,EAAL,KAAA,MAAkB,SAAS,SAAS,GAAG;MAC5D,SAAS;IACX,CAAA;AAEA,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI;QACR,SAAS;QACT;QACA;QACA,OAAO,YAAY,CAAC,GAAG,SAAS,QAAQ,QAAQ,CAAC,CAAC;QAClD,SAAS,SAAS;MACpB;IACF;AAGA,UAAM,UACJ,KAAA,aAAA,MAAK,OAAA,MAAL,OAAA,KACA,qBAAqB,SAAS,SAAS;MACrC,UAAU;MACV,KAAK,SAAS,SAAS;IACzB,CAAC;AAEH,UAAM,EAAE,UAAU,MAAM,QAAQ,IAAI,MAAM,SAAS,KAAK;AACxD,UAAM,OAAO,aAAA,MAAK,cAAA,EAAe;MAC/B;MACA;IACF;AAEA,WAAO;MACL;MACA;IACF;EACF;AACF;AAxjCE,SAAA,oBAAA,QAAA;AAESA,gBAAA,oBAAA,QAAA;AACA,kBAAA,oBAAA,QAAA;AACA,iBAAA,oBAAA,QAAA;AAEA,eAAA,oBAAA,QAAA;AAQT,WAAA,oBAAA,QAAA;AACA,SAAA,oBAAA,QAAA;AACA,cAAA,oBAAA,QAAA;AACA,mBAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AACA,cAAA,oBAAA,QAAA;AACA,eAAA,oBAAA,QAAA;AACA,aAAA,oBAAA,QAAA;AACA,eAAA,oBAAA,QAAA;AACA,QAAA,oBAAA,QAAA;AACA,UAAA,oBAAA,QAAA;AACA,WAAA,oBAAA,QAAA;AACA,0BAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AACA,eAAA,oBAAA,QAAA;AACA,uBAAA,oBAAA,QAAA;AACA,uBAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AACA,mBAAA,oBAAA,QAAA;AACA,0BAAA,oBAAA,QAAA;AACA,oBAAA,oBAAA,QAAA;AACA,4BAAA,oBAAA,QAAA;AACA,kBAAA,oBAAA,QAAA;AACA,mBAAA,oBAAA,QAAA;AACA,8BAAA,oBAAA,QAAA;AACA,4BAAA,oBAAA,QAAA;AACA,kCAAA,oBAAA,QAAA;AACA,0BAAA,oBAAA,QAAA;AACA,4BAAA,oBAAA,QAAA;AACA,uBAAA,oBAAA,QAAA;AACA,sBAAA,oBAAA,QAAA;AACA,oCAAA,oBAAA,QAAA;AAtDK,yBAAA,oBAAA,QAAA;AAyDD,iBAAW,WAAY;AACzB,SAAO,aAAA,MAAK,eAAA,MAAoB;AAClC;AAmFM,WAAM,iBAAkB;AAtpBhC,MAAA,IAAA,IAAA,IAAA,IAAA;AAupBI,eAAA,MAAK,UAAW,IAAA;AAEhB,MAAI;AACF,UAAM,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,IAAA;EACR,SAAS,KAAK;AACZ,iBAAA,MAAK,QAAS,GAAA;AAGd,QAAI,aAAA,MAAK,QAAA,GAAU;AACjB,YAAM,YAAY,MAAM,aAAA,MAAK,QAAA,EAAL,KAAA,MAAc,GAAA;AAEtC,UAAI,aAAa,OAAO,cAAc,UAAU;AAG9C,YAAI,UAAU,QAAQ;AAEpB,eAAK,QAAQ,SAAS,eAAA,eAAA,CAAA,IAChB,KAAA,KAAK,QAAQ,WAAb,OAAA,KAAuB,CAAC,CAAA,GACzB,UAAU,MAAA;QAEjB;AAEA,YAAI,UAAU,SAAS;AAErB,eAAK,QAAQ,UAAU,eAAA,eAAA,CAAA,IACjB,KAAA,KAAK,QAAQ,YAAb,OAAA,KAAwB,CAAC,CAAA,GAC1B,UAAU,OAAA;QAEjB;AAGA,qBAAA,MAAK,QAAS,IAAA;AAGd,qBAAA,MAAK,UAAW,KAAA;AAChB,cAAM,gBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;AACN;MACF;AAGA,UAAI,eAAe,OAAO;AACxB,wBAAA,MAAK,wBAAA,yBAAA,EAAL,KAAA,MAA6B,GAAA;MAC/B;AACA,mBAAA,MAAK,YAAa,KAAA;AAClB,OAAA,KAAA,aAAA,MAAK,oBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AACA;IACF;AAIA,QAAI,eAAe,OAAO;AACxB,sBAAA,MAAK,wBAAA,yBAAA,EAAL,KAAA,MAA6B,GAAA;IAC/B;AACA,iBAAA,MAAK,YAAa,KAAA;AAClB,KAAA,KAAA,aAAA,MAAK,oBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AACA,UAAM;EACR;AAGA,eAAA,MAAK,YAAa,KAAA;AAClB,GAAA,KAAA,aAAA,MAAK,oBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AACF;AAEM,kBAAa,iBAAkB;AAttBvC,MAAA,IAAA;AAutBI,MAAI,aAAA,MAAK,MAAA,MAAW,mBAAmB;AACrC,iBAAA,MAAK,QAAS,QAAA;AACd;EACF;AAEA,MACE,CAAC,KAAK,QAAQ,gBACb,KAAA,KAAK,QAAQ,WAAb,OAAA,SAAA,GAAqB,YAAW,aAAA,MAAK,WAAA,IACtC;AACA;EACF;AAEA,QAAM,oBAAoB,aAAA,MAAK,MAAA,MAAW;AAC1C,eAAA,MAAK,QAAS,QAAA;AAEd,QAAM,EAAE,KAAK,OAAO,IAAI,KAAK;AAC7B,QAAM,EAAE,UAAU,eAAe,IAAI,MAAM,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,MACzC,KACA,iBAAA;AAEF,QAAM,gBAAgB,MAAM,gBAAA,MAAK,wBAAA,sBAAA,EAAL,KAAA,MAA0B,MAAA;AACtD,QAAM,yBAAyB,aAAA,MAAK,uBAAA;AAEpC,MAAI;AACF,UAAM,gBAAA,MAAK,wBAAA,aAAA,EAAL,KAAA,MAAiB;MACrB;MACA;MACA,SAAS;MACT;IACF,CAAA;EACF,SAAS,GAAG;AAEV,SACG,aAAa,cAAc,aAAa,2BACzC,uBAAuB,OAAO,WAC9B,uBAAuB,OAAO,WAAW,8BACzC;AAEA,aAAO,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,IAAA;IACT;AAEA,QAAI,aAAa,wBAAwB;AAIvC,YAAM,eAAe,aAAA,MAAK,MAAA;AAI1B,UACE,uBAAuB,OAAO,WAC9B,uBAAuB,OAAO,WAAW,gBACzC,iBAAiB,mBACjB;AACA,qBAAA,MAAK,QAAS,QAAA;MAChB;AACA;IACF;AACA,QAAI,EAAE,aAAa,YAAa,OAAM;AAEtC,QAAI,EAAE,UAAU,KAAK;AAOnB,UAAI,aAAA,MAAK,YAAA,GAAc;AACrB,cAAM,WAAW,kBAAkB,QAAQ;AAC3C,2BAAmB,YAAY,UAAU,aAAA,MAAK,YAAA,CAAY;MAC5D;AAEA,YAAM,iBACJ,EAAE,QAAQ,mBAAmB,KAAK,GAAG,aAAA,MAAK,YAAA,CAAa;AACzD,sBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,MAAY,cAAA;AAKZ,YAAM,gBAAA,MAAK,wBAAA,UAAA,EAAL,KAAA,MACH,MAAM,QAAQ,EAAE,IAAI,IAAI,EAAE,OAAO,CAAC,EAAE,IAAI,CAAA;AAE3C,aAAO,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,IAAA;IACT,OAAO;AAKL,YAAM;IACR;EACF,UAAA;AACE,QAAI,iBAAiB,QAAQ;AAC3B,aAAO,oBAAoB,SAAS,aAAa;IACnD;AACA,iBAAA,MAAK,yBAA0B,MAAA;EACjC;AAEA,GAAA,KAAA,aAAA,MAAK,oBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AACA,SAAO,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,IAAA;AACT;AAEM,kBAAa,eACjB,KACA,mBACA,cACA;AAh0BJ,MAAA,IAAA,IAAA,IAAA,IAAA,IAAA;AAk0BI,QAAM,CAAC,gBAAgB,MAAM,IAAI,MAAM,QAAQ,IAAI;IACjD,eAAe,KAAK,QAAQ,OAAO;IACnC,KAAK,QAAQ,SACT,iBAAiB,wBAAwB,KAAK,QAAQ,MAAM,CAAC,IAC7D;EACN,CAAC;AAGD,MAAI,OAAQ,gBAAe,MAAM;AAEjC,QAAM,WAAW,IAAI,IAAI,GAAG;AAG5B,MAAI,QAAQ;AACV,QAAI,OAAO,MAAO,eAAc,UAAU,mBAAmB,OAAO,KAAK;AACzE,QAAI,OAAO,SAAS,OAAO,OAAO,UAAU,UAAU;AACpD,YAAM,eAAe;QACnB,OAAO;SACP,KAAA,KAAK,QAAQ,iBAAb,OAAA,SAAA,GAA2B;MAC7B;AACA,oBAAc,UAAU,mBAAmB,YAAY;IACzD;AACA,QAAI,OAAO,SAAS;AAElB,YAAM,kBAAkB,MAAM,cAAa,KAAA,KAAK,QAAQ,WAAb,OAAA,SAAA,GAAqB,OAAO;AACvE,UAAI,MAAM,QAAQ,eAAe,GAAG;AAElC,YAAI,iBAAiB,gBAAgB,IAAI,MAAM;AAC/C,YAAI,KAAK,QAAQ,cAAc;AAC7B,2BAAiB,eAAe;YAC9B,KAAK,QAAQ,aAAa;UAC5B;QACF;AAEA,cAAM,oBAAoB,eACvB,IAAI,eAAe,EACnB,KAAK,GAAG;AACX,sBAAc,UAAU,qBAAqB,iBAAiB;MAChE,OAAO;AAEL,sBAAc,UAAU,qBAAqB,OAAO,OAAO;MAC7D;IACF;AACA,QAAI,OAAO,QAAS,eAAc,UAAU,eAAe,OAAO,OAAO;AACzE,QAAI,OAAO;AACT,oBAAc,UAAU,oBAAoB,OAAO,MAAM;AAG3D,UAAM,eAAe,eAAA,CAAA,GAAK,MAAA;AAC1B,WAAO,aAAa;AACpB,WAAO,aAAa;AACpB,WAAO,aAAa;AACpB,WAAO,aAAa;AACpB,WAAO,aAAa;AAEpB,eAAW,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,YAAY,GAAG;AACvD,oBAAc,UAAU,KAAK,KAAK;IACpC;EACF;AAEA,MAAI,cAAc;AAGhB,QAAI,aAAa,WAAW;AAE1B,YAAM,gBAAgB;QACpB,aAAa;SACb,KAAA,KAAK,QAAQ,iBAAb,OAAA,SAAA,GAA2B;MAC7B;AACA,oBAAc,UAAU,oBAAoB,aAAa;AAEzD,eAAS,aAAa;QACpB;QACA,KAAK,UAAU,aAAa,SAAS;MACvC;IACF,WAAW,aAAa,SAAS,OAAO,aAAa,UAAU,UAAU;AAEvE,YAAM,eAAe;QACnB,aAAa;SACb,KAAA,KAAK,QAAQ,iBAAb,OAAA,SAAA,GAA2B;MAC7B;AACA,oBAAc,UAAU,oBAAoB,YAAY;IAC1D;AAEA,QAAI,aAAa;AAEf,eAAS,aAAa;QACpB;QACA,KAAK,UAAU,aAAa,MAAM;MACpC;AACF,QAAI,aAAa;AACf,oBAAc,UAAU,oBAAoB,aAAa,KAAK;AAChE,QAAI,aAAa;AACf,oBAAc,UAAU,qBAAqB,aAAa,MAAM;AAGlE,QAAI,aAAa,aAAa;AAE5B,YAAM,kBAAkB;QACtB,aAAa;SACb,KAAA,KAAK,QAAQ,iBAAb,OAAA,SAAA,GAA2B;MAC7B;AACA,oBAAc,UAAU,uBAAuB,eAAe;AAE9D,eAAS,aAAa;QACpB;QACA,KAAK,UAAU,aAAa,WAAW;MACzC;IACF,WACE,aAAa,WACb,OAAO,aAAa,YAAY,UAChC;AAEA,YAAM,iBAAiB;QACrB,aAAa;SACb,KAAA,KAAK,QAAQ,iBAAb,OAAA,SAAA,GAA2B;MAC7B;AACA,oBAAc,UAAU,uBAAuB,cAAc;IAC/D;EACF;AAGA,WAAS,aAAa,IAAI,oBAAoB,aAAA,MAAK,WAAA,CAAW;AAC9D,WAAS,aAAa,IAAI,sBAAsB,aAAA,MAAK,KAAA,CAAK;AAG1D,QAAM,oBAAoB,iBAAiB;AAE3C,MAAI,aAAA,MAAK,WAAA,KAAe,CAAC,mBAAmB;AAI1C,QAAI,CAAC,aAAA,MAAK,aAAA,KAAiB,CAAC,mBAAmB;AAC7C,eAAS,aAAa,IAAI,kBAAkB,MAAM;IACpD;AACA,aAAS,aAAa;MACpB;MACA,aAAA,MAAK,gBAAA;IACP;EACF;AAEA,MAAI,aAAA,MAAK,YAAA,GAAc;AAErB,aAAS,aAAa,IAAI,0BAA0B,aAAA,MAAK,YAAA,CAAa;EACxE;AAGA,QAAM,WAAW,kBAAkB,QAAQ;AAC3C,QAAM,gBAAgB,mBAAmB,iBAAiB,QAAQ;AAClE,MAAI,eAAe;AACjB,aAAS,aAAa,IAAI,4BAA4B,aAAa;EACrE;AAGA,WAAS,aAAa,KAAK;AAE3B,SAAO;IACL;IACA;EACF;AACF;AAEM,yBAAoB,eAAC,QAAsB;AAp+BnD,MAAA;AAs+BI,eAAA,MAAK,yBAA0B,IAAI,gBAAgB,CAAA;AAGnD,MAAI,QAAQ;AACV,UAAM,gBAAgB,MAAM;AA1+BlC,UAAAC;AA2+BQ,OAAAA,MAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAAA,IAA8B,MAAM,OAAO,MAAA;IAC7C;AAEA,WAAO,iBAAiB,SAAS,eAAe,EAAE,MAAM,KAAK,CAAC;AAE9D,QAAI,OAAO,SAAS;AAElB,OAAA,KAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAA,GAA8B,MAAM,OAAO,MAAA;IAC7C;AAEA,WAAO;EACT;AACF;AAEM,uBAAkB,eAAC,UAAoB;AAz/B/C,MAAA;AA0/BI,QAAM,EAAE,SAAS,OAAO,IAAI;AAC5B,QAAM,cAAc,QAAQ,IAAI,mBAAmB;AACnD,MAAI,aAAa;AAIf,UAAM,WAAW,aAAA,MAAK,gBAAA,IAClB,kBAAkB,aAAA,MAAK,gBAAA,CAAgB,IACvC;AACJ,UAAM,gBAAgB,WAClB,mBAAmB,iBAAiB,QAAQ,IAC5C;AACJ,QAAI,gBAAgB,eAAe;AACjC,mBAAA,MAAK,cAAe,WAAA;IACtB,OAAO;AACL,cAAQ;QACN,kLAEoC,WAAW,4MAEY,aAAA,MAAK,YAAA,CAAY;MAC9E;IACF;EACF;AAEA,QAAM,aAAa,QAAQ,IAAI,wBAAwB;AACvD,MAAI,YAAY;AACd,iBAAA,MAAK,aAAc,UAAA;EACrB;AAEA,QAAM,kBAAkB,QAAQ,IAAI,wBAAwB;AAC5D,MAAI,iBAAiB;AACnB,iBAAA,MAAK,kBAAmB,eAAA;EAC1B;AAEA,eAAA,MAAK,UAAU,KAAA,aAAA,MAAK,OAAA,MAAL,OAAA,KAAgB,qBAAqB,OAAO,CAAA;AAK3D,MAAI,WAAW,KAAK;AAElB,iBAAA,MAAK,eAAgB,KAAK,IAAI,CAAA;EAChC;AACF;AAEM,gBAAW,eAAC,OAA0B,eAAe,OAAO;AAxiCpE,MAAA;AA0iCI,MAAI,MAAM,SAAS,GAAG;AAEpB,iBAAA,MAAK,cAAe,IAAA;AAEpB,UAAM,cAAc,MAAM,MAAM,SAAS,CAAC;AAC1C,QAAI,kBAAkB,WAAW,GAAG;AAClC,UAAI,cAAc;AAIhB,cAAM,SAAS,UAAU,WAAW;AACpC,YAAI,QAAQ;AACV,uBAAA,MAAK,aAAc,MAAA;QACrB;MACF;AACA,mBAAA,MAAK,eAAgB,KAAK,IAAI,CAAA;AAC9B,mBAAA,MAAK,aAAc,IAAA;AAEnB,mBAAA,MAAK,cAAe,KAAA;AAEpB,OAAA,KAAA,aAAA,MAAK,yBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AAIA,UAAI,aAAA,MAAK,wBAAA,cAAA,KAAe,CAAC,cAAc;AAIrC,cAAM,gBAAgB,aAAA,MAAK,gBAAA;AAE3B,YAAI,kBAAkB,aAAA,MAAK,eAAA,GAAiB;AAG1C;QACF;MACF;AAOA,mBAAA,MAAK,iBAAkB,MAAA;AAEvB,UAAI,aAAA,MAAK,gBAAA,GAAkB;AACzB,cAAM,WAAW,kBAAkB,aAAA,MAAK,gBAAA,CAAgB;AACxD,wBAAgB,eAAe,UAAU,aAAA,MAAK,gBAAA,CAAgB;MAChE;IACF;AAGA,UAAM,oBAAoB,MAAM,OAAO,CAAC,YAAY;AAClD,UAAI,gBAAgB,OAAO,GAAG;AAC5B,eAAO,CAAC,aAAA,MAAK,gBAAA,EAAiB,oBAAoB,OAAO;MAC3D;AACA,aAAO;IACT,CAAC;AAED,UAAM,gBAAA,MAAK,wBAAA,UAAA,EAAL,KAAA,MAAc,iBAAA;EACtB;AACF;AASM,gBAAW,eAAC,MAKA;AApnCpB,MAAA;AAsnCI,eAAA,MAAK,kBAAmB,KAAK,QAAA;AAK7B,MAAI,CAAC,aAAA,MAAK,WAAA,KAAe,CAAC,aAAA,MAAK,wBAAA,cAAA,GAAa;AAC1C,UAAM,WAAW,kBAAkB,KAAK,QAAQ;AAChD,UAAM,iBAAiB,gBAAgB,sBAAsB,QAAQ;AACrE,QAAI,gBAAgB;AAElB,mBAAA,MAAK,iBAAkB,cAAA;IACzB;EACF;AAEA,QAAM,UAAS,KAAA,KAAK,QAAQ,YAAb,OAAA,KAAwB,KAAK,QAAQ;AACpD,MACE,aAAA,MAAK,WAAA,KACL,UACA,CAAC,aAAA,MAAK,aAAA,KACN,CAAC,KAAK,qBACN,CAAC,aAAA,MAAK,yBAAA,GACN;AACA,SAAK,SAAS,aAAa,IAAI,mCAAmC,MAAM;AACxE,SAAK,SAAS,aAAa,IAAI,sBAAsB,MAAM;AAC3D,WAAO,gBAAA,MAAK,wBAAA,kBAAA,EAAL,KAAA,MAAsB,IAAA;EAC/B;AAEA,SAAO,gBAAA,MAAK,wBAAA,uBAAA,EAAL,KAAA,MAA2B,IAAA;AACpC;AAEM,0BAAqB,eAAC,MAIV;AAChB,QAAM,EAAE,UAAU,wBAAwB,QAAQ,IAAI;AACtD,QAAM,WAAW,MAAM,aAAA,MAAKD,aAAAA,EAAL,KAAA,MAAkB,SAAS,SAAS,GAAG;IAC5D,QAAQ,uBAAuB;IAC/B;EACF,CAAA;AAEA,eAAA,MAAK,YAAa,IAAA;AAClB,QAAM,gBAAA,MAAK,wBAAA,oBAAA,EAAL,KAAA,MAAwB,QAAA;AAE9B,QAAM,SAAS,aAAA,MAAK,OAAA;AACpB,QAAM,MAAM,MAAM,SAAS,KAAK;AAChC,QAAM,WAAW,OAAO;AACxB,QAAM,QAAQ,aAAA,MAAK,cAAA,EAAe,MAAyB,UAAU,MAAM;AAE3E,QAAM,gBAAA,MAAK,wBAAA,aAAA,EAAL,KAAA,MAAiB,KAAA;AACzB;AAEM,qBAAgB,eAAC,MAIL;AAChB,QAAM,EAAE,UAAU,wBAAwB,QAAQ,IAAI;AACtD,QAAMG,SAAQ,aAAA,MAAK,eAAA;AAGnB,eAAA,MAAK,6BAA8B,KAAK,IAAI,CAAA;AAG5C,QAAM,aAAa,cAAA,eAAA,CAAA,GACd,OAAA,GADc;IAEjB,QAAQ;EACV,CAAA;AAEA,MAAI;AACF,QAAI,SAA4B,CAAC;AACjC,UAAM,iBAAiB,SAAS,SAAS,GAAG;MAC1C,SAAS;MACT,OAAAA;MACA,QAAQ,OAAO,aAAuB;AACpC,qBAAA,MAAK,YAAa,IAAA;AAClB,cAAM,gBAAA,MAAK,wBAAA,oBAAA,EAAL,KAAA,MAAwB,QAAA;MAChC;MACA,WAAW,CAAC,UAA8B;AACxC,YAAI,MAAM,MAAM;AAEd,gBAAM,SAAS,aAAA,MAAK,OAAA;AACpB,gBAAM,UAAU,aAAA,MAAK,cAAA,EAAe;YAClC,MAAM;YACN;UACF;AACA,iBAAO,KAAK,OAAO;AAEnB,cAAI,kBAAkB,OAAO,GAAG;AAG9B,4BAAA,MAAK,wBAAA,aAAA,EAAL,KAAA,MAAiB,QAAQ,IAAA;AACzB,qBAAS,CAAC;UACZ;QACF;MACF;MACA,SAAS,CAAC,UAAiB;AAEzB,cAAM;MACR;MACA,QAAQ,uBAAuB;IACjC,CAAC;EACH,SAAS,OAAO;AACd,QAAI,uBAAuB,OAAO,SAAS;AAQzC,YAAM,IAAI,uBAAuB;IACnC;AACA,UAAM;EACR,UAAA;AAIE,UAAM,qBAAqB,KAAK,IAAI,IAAI,aAAA,MAAK,2BAAA;AAC7C,UAAM,aAAa,uBAAuB,OAAO;AAEjD,QAAI,qBAAqB,aAAA,MAAK,yBAAA,KAA6B,CAAC,YAAY;AAEtE,uBAAA,MAAK,+BAAA,EAAL;AAEA,UACE,aAAA,MAAK,+BAAA,KAAmC,aAAA,MAAK,uBAAA,GAC7C;AAEA,qBAAA,MAAK,2BAA4B,IAAA;AACjC,gBAAQ;UACN;QAKF;MACF,OAAO;AAGL,cAAM,WAAW,KAAK;UACpB,aAAA,MAAK,mBAAA;UACL,aAAA,MAAK,oBAAA,IACH,KAAK,IAAI,GAAG,aAAA,MAAK,+BAAA,CAA+B;QACpD;AACA,cAAM,UAAU,KAAK,MAAM,KAAK,OAAO,IAAI,QAAQ;AACnD,cAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,OAAO,CAAC;MAC7D;IACF,WAAW,sBAAsB,aAAA,MAAK,yBAAA,GAA2B;AAE/D,mBAAA,MAAK,iCAAkC,CAAA;IACzC;EACF;AACF;AAEA,WAAM,WAAG;AAjxCX,MAAA;AAkxCI,MAAI,aAAA,MAAK,QAAA,KAAY,aAAA,MAAK,MAAA,MAAW,UAAU;AAC7C,iBAAA,MAAK,QAAS,iBAAA;AACd,KAAA,KAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAA,GAA8B,MAAM,YAAA;EACtC;AACF;AAEA,YAAO,WAAG;AAxxCZ,MAAA;AAyxCI,MACE,aAAA,MAAK,QAAA,MACJ,aAAA,MAAK,MAAA,MAAW,YAAY,aAAA,MAAK,MAAA,MAAW,oBAC7C;AAIA,SAAI,KAAA,KAAK,QAAQ,WAAb,OAAA,SAAA,GAAqB,SAAS;AAChC;IACF;AAIA,QAAI,aAAA,MAAK,MAAA,MAAW,mBAAmB;AACrC,mBAAA,MAAK,QAAS,QAAA;IAChB;AACA,oBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;EACF;AACF;AAmDM,cAAS,iBAAG;AAChB,MAAI,aAAA,MAAK,YAAA,GAAc;AACrB,WAAO,aAAA,MAAK,YAAA;EACd;AACA,eAAA,MAAK,cAAe,IAAI,QAAQ,CAAC,SAAS,WAAW;AACnD,iBAAA,MAAK,sBAAuB,OAAA;AAC5B,iBAAA,MAAK,sBAAuB,MAAA;EAC9B,CAAC,CAAA;AACD,eAAA,MAAK,YAAA,EAAa,QAAQ,MAAM;AAC9B,iBAAA,MAAK,cAAe,MAAA;AACpB,iBAAA,MAAK,sBAAuB,MAAA;AAC5B,iBAAA,MAAK,sBAAuB,MAAA;EAC9B,CAAC;AACD,SAAO,aAAA,MAAK,YAAA;AACd;AAGM,sBAAiB,iBAAG;AACxB,MAAI,CAAC,aAAA,MAAK,YAAA,GAAc;AACtB;EACF;AACA,MAAI,aAAA,MAAK,iBAAA,GAAmB;AAC1B,WAAO,aAAA,MAAK,iBAAA;EACd;AACA,eAAA,MAAK,mBAAoB,IAAI,QAAQ,CAAC,YAAY;AAChD,iBAAA,MAAK,2BAA4B,OAAA;EACnC,CAAC,CAAA;AACD,eAAA,MAAK,iBAAA,EAAkB,QAAQ,MAAM;AACnC,iBAAA,MAAK,mBAAoB,MAAA;AACzB,iBAAA,MAAK,2BAA4B,MAAA;EACnC,CAAC;AACD,SAAO,aAAA,MAAK,iBAAA;AACd;AAmBM,aAAQ,eAAC,UAAyC;AAKtD,eAAA,MAAK,eAAgB,aAAA,MAAK,aAAA,EAAc;IAAK,MAC3C,QAAQ;MACN,MAAM,KAAK,aAAA,MAAK,YAAA,EAAa,OAAO,CAAC,EAAE,IAAI,OAAO,CAAC,UAAU,EAAE,MAAM;AACnE,YAAI;AACF,gBAAM,SAAS,QAAQ;QACzB,SAAS,KAAK;AACZ,yBAAe,MAAM;AACnB,kBAAM;UACR,CAAC;QACH;MACF,CAAC;IACH;EACF,CAAA;AAEA,SAAO,aAAA,MAAK,aAAA;AACd;AAEA,4BAAuB,SAAC,OAAc;AACpC,eAAA,MAAK,YAAA,EAAa,QAAQ,CAAC,CAAC,GAAG,OAAO,MAAM;AAC1C,eAAA,OAAA,SAAA,QAAU,KAAA;EACZ,CAAC;AACH;AAEA,kCAA6B,WAAG;AAC9B,MACE,OAAO,aAAa,YACpB,OAAO,SAAS,WAAW,aAC3B,OAAO,SAAS,qBAAqB,YACrC;AACA,UAAM,oBAAoB,MAAM;AAC9B,UAAI,SAAS,QAAQ;AACnB,wBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;MACF,OAAO;AACL,wBAAA,MAAK,wBAAA,SAAA,EAAL,KAAA,IAAA;MACF;IACF;AAEA,aAAS,iBAAiB,oBAAoB,iBAAiB;AAG/D,iBAAA,MAAK,mCAAoC,MAAM;AAC7C,eAAS,oBAAoB,oBAAoB,iBAAiB;IACpE,CAAA;EACF;AACF;AAMA,WAAM,SAAC,QAAiB;AACtB,eAAA,MAAK,aAAc,IAAA;AACnB,eAAA,MAAK,kBAAmB,EAAA;AACxB,eAAA,MAAK,cAAe,MAAA;AACpB,eAAA,MAAK,aAAc,KAAA;AACnB,eAAA,MAAK,cAAe,IAAA;AACpB,eAAA,MAAK,YAAa,KAAA;AAClB,eAAA,MAAK,SAAU,MAAA;AACf,eAAA,MAAK,yBAA0B,CAAA;AAE/B,eAAA,MAAK,iCAAkC,CAAA;AACvC,eAAA,MAAK,2BAA4B,KAAA;AACnC;AA58BW,YAGK,UAAU;EACxB,MAAM;EACN,SAAS;AACX;AAskCF,SAAS,qBACP,SACA,SACQ;AACR,QAAM,eAAe,QAAQ,IAAI,mBAAmB;AACpD,MAAI,CAAC,cAAc;AACjB,SAAI,WAAA,OAAA,SAAA,QAAS,cAAY,WAAA,OAAA,SAAA,QAAS,MAAK;AACrC,YAAM,IAAI,oBAAoB,QAAQ,KAAK,CAAC,mBAAmB,CAAC;IAClE;AACA,WAAO,CAAC;EACV;AACA,SAAO,KAAK,MAAM,YAAY;AAChC;AAMA,SAAS,eAAe,QAAmD;AACzE,MAAI,CAAC,OAAQ;AAEb,QAAM,iBAAiB,OAAO,KAAK,MAAM,EAAE;IAAO,CAAC,QACjD,gBAAgB,IAAI,GAAwB;EAC9C;AACA,MAAI,eAAe,SAAS,GAAG;AAC7B,UAAM,IAAI,mBAAmB,cAAc;EAC7C;AACF;AAEA,SAAS,gBAAmB,SAA+C;AACzE,MAAI,CAAC,QAAQ,KAAK;AAChB,UAAM,IAAI,qBAAqB;EACjC;AACA,MAAI,QAAQ,UAAU,EAAE,QAAQ,kBAAkB,cAAc;AAC9D,UAAM,IAAI,mBAAmB;EAC/B;AAEA,MACE,QAAQ,WAAW,UACnB,QAAQ,WAAW,QACnB,QAAQ,WAAW,SACnB,CAAC,QAAQ,QACT;AACA,UAAM,IAAI,wBAAwB;EACpC;AAEA,iBAAe,QAAQ,MAAM;AAE7B;AACF;AAGA,SAAS,cACP,KACA,KACA,OACM;AACN,MAAI,UAAU,UAAa,SAAS,MAAM;AACxC;EACF,WAAW,OAAO,UAAU,UAAU;AACpC,QAAI,aAAa,IAAI,KAAK,KAAK;EACjC,WAAW,OAAO,UAAU,UAAU;AACpC,eAAW,CAAC,GAAG,CAAC,KAAK,OAAO,QAAQ,KAAK,GAAG;AAC1C,UAAI,aAAa,IAAI,GAAG,GAAG,IAAI,CAAC,KAAK,CAAC;IACxC;EACF,OAAO;AACL,QAAI,aAAa,IAAI,KAAK,MAAM,SAAS,CAAC;EAC5C;AACF;AAEA,SAAS,wBACP,aAC2B;AAC3B,MAAI,MAAM,QAAQ,YAAY,MAAM,GAAG;AACrC,WAAO,cAAA,eAAA,CAAA,GACF,WAAA,GADE;MAEL,QAAQ,OAAO,YAAY,YAAY,OAAO,IAAI,CAAC,GAAG,MAAM,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC;IACzE,CAAA;EACF;AACA,SAAO;AACT;AIpqDA,IAAA;AAAA,IAAAC;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAAC;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAoDW,QAAA,oBAAA,QAAA;AACAC,gBAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AACA,yBAAA,oBAAA,QAAA;AACT,6BAAA,oBAAA,QAAA;AACA,UAAA,oBAAA,QAAA;AACAC,UAAA,oBAAA,QAAA;AATK,mBAAA,oBAAA,QAAA;AAuHL,aAAQ,SAAC,UAA8B;AACrC,MAAI,eAAe;AAEnB,WAAS,QAAQ,CAAC,YAAY;AAC5B,QAAI,gBAAgB,OAAO,GAAG;AAC5B,qBAAe,gBAAA,MAAK,kBAAA,oBAAA,EAAL,KAAA,MAAwB,SAAA;AACvC,UAAI,KAAK,SAAS,QAAQ;AACxB,gBAAQ,QAAQ,QAAQ,WAAW;UACjC,KAAK;AACH,yBAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,KAAK,QAAQ,KAAK;AACzC;UACF,KAAK;AACH,yBAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,KAAK,eAAA,eAAA,CAAA,GACvB,aAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,GAAG,CAAA,GAC1B,QAAQ,KAAA,CACZ;AACD;UACF,KAAK;AACH,yBAAA,MAAK,KAAA,EAAM,OAAO,QAAQ,GAAG;AAC7B;QACJ;MACF,OAAO;AAEL,gBAAQ,QAAQ,QAAQ,WAAW;UACjC,KAAK;AACH,yBAAA,MAAK,aAAA,EAAc,IAAI,QAAQ,GAAG;AAClC,yBAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,KAAK,QAAQ,KAAK;AACzC;UACF,KAAK;AACH,gBAAI,aAAA,MAAK,aAAA,EAAc,IAAI,QAAQ,GAAG,GAAG;AACvC,2BAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,KAAK,eAAA,eAAA,CAAA,GACvB,aAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,GAAG,CAAA,GAC1B,QAAQ,KAAA,CACZ;YACH;AACA;UACF,KAAK;AACH,gBAAI,aAAA,MAAK,aAAA,EAAc,IAAI,QAAQ,GAAG,GAAG;AACvC,2BAAA,MAAK,KAAA,EAAM,OAAO,QAAQ,GAAG;AAC7B,2BAAA,MAAK,aAAA,EAAc,OAAO,QAAQ,GAAG;YACvC;AACA;QACJ;MACF;IACF;AAEA,QAAI,iBAAiB,OAAO,GAAG;AAC7B,cAAQ,QAAQ,QAAQ,SAAS;QAC/B,KAAK;AACH,yBAAe,gBAAA,MAAK,kBAAA,oBAAA,EAAL,KAAA,MAAwB,YAAA;AACvC,cAAI,aAAA,MAAK,0BAAA,GAA4B;AACnC,yBAAA,MAAK,4BAA6B,KAAA;AAClC,iBAAK,gBAAA,MAAK,kBAAA,qBAAA,EAAL,KAAA,IAAA;UACP;AACA;QACF,KAAK;AACH,uBAAA,MAAK,KAAA,EAAM,MAAM;AACjB,uBAAA,MAAK,aAAA,EAAc,MAAM;AACzB,uBAAA,MAAKA,SAAS,KAAA;AACd,yBAAe,gBAAA,MAAK,kBAAA,oBAAA,EAAL,KAAA,MAAwB,SAAA;AAEvC,uBAAA,MAAK,4BAA6B,IAAA;AAClC;MACJ;IACF;EACF,CAAC;AAED,MAAI,aAAc,iBAAA,MAAK,kBAAA,SAAA,EAAL,KAAA,IAAA;AACpB;AAEM,wBAAmB,iBAAkB;AAEzC,QAAM,gBAAA,MAAK,kBAAA,gBAAA,EAAL,KAAA,IAAA;AAGN,QAAM,QAAQ;IACZ,MAAM,KAAK,aAAA,MAAK,sBAAA,CAAsB,EAAE,IAAI,OAAO,eAAe;AAChE,UAAI;AACF,cAAM,WAAW,KAAK,MAAM,UAAU;AACtC,cAAM,KAAK,OAAO,gBAAgB,QAAQ;MAC5C,SAAS,GAAG;MAEZ;IACF,CAAC;EACH;AACF;AAEM,mBAAc,iBAAkB;AACpC,MAAI,KAAK,OAAO,WAAY;AAC5B,QAAM,IAAI,QAAc,CAAC,YAAY;AACnC,UAAM,QAAQ,MAAM;AAClB,UAAI,KAAK,OAAO,YAAY;AAC1B,sBAAc,QAAQ;AACtB,cAAM;AACN,gBAAQ;MACV;IACF;AACA,UAAM,WAAW,YAAY,OAAO,EAAE;AACtC,UAAM,QAAQ,KAAK,OAAO;MACxB,MAAM,MAAM;MACZ,MAAM,MAAM;IACd;AACA,UAAM;EACR,CAAC;AACH;AAEA,uBAAkB,SAAC,QAA8B;AAC/C,QAAM,eAAe,aAAA,MAAK,OAAA,MAAY;AACtC,eAAA,MAAK,SAAU,MAAA;AACf,SAAO,gBAAgB,WAAW;AACpC;AAEA,iBAAY,SAAC,GAAgB;AAC3B,MAAI,aAAa,YAAY;AAC3B,iBAAA,MAAKA,SAAS,CAAA;AACd,oBAAA,MAAK,kBAAA,SAAA,EAAL,KAAA,IAAA;EACF;AACF;AAEA,YAAO,WAAS;AACd,eAAA,MAAKD,aAAAA,EAAa,QAAQ,CAAC,aAAa;AACtC,aAAS,EAAE,OAAO,KAAK,cAAc,MAAM,KAAK,YAAY,CAAC;EAC/D,CAAC;AACH;;;;;;AChSK,IAAM,4BAAN,cAAwC,gBAAgB;EAC7D,YAAY,SAAiB,cAAuB;AAClD,UAAM,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE,GAAG,OAAO,EAAE;AAC7D,SAAK,OAAO;EACd;AACF;AAEO,IAAM,iCAAN,cAA6C,0BAA0B;EAC5E,YAAY,UAAkB,cAAuB;AACnD,UAAM,0CAA0C,QAAQ,IAAI,YAAY;AACxE,SAAK,OAAO;EACd;AACF;AAEO,IAAM,6BAAN,cAAyC,0BAA0B;EACxE,YAAY,MAAc,cAAuB;AAC/C,UAAM,6BAA6B,IAAI,IAAI,YAAY;AACvD,SAAK,OAAO;EACd;AACF;AAEO,IAAM,8BAAN,cAA0C,0BAA0B;EACzE,YAAY,cAAuB;AACjC,UAAM,6CAA6C,YAAY;AAC/D,SAAK,OAAO;EACd;AACF;AAEO,IAAM,qBAAN,cAAiC,0BAA0B;EAChE,YAAY,cAAuB;AACjC,UAAM,kBAAkB,YAAY;AACpC,SAAK,OAAO;EACd;AACF;;;ACzBO,SAAS,UAAU,OAAwB;AAGhD,MAAI,UAAU,QAAQ,UAAU,QAAW;AACzC,WAAO;EACT;AAGA,MAAI,OAAO,UAAU,UAAU;AAC7B,WAAO;EACT;AAGA,MAAI,OAAO,UAAU,UAAU;AAC7B,WAAO,MAAM,SAAA;EACf;AAGA,MAAI,OAAO,UAAU,UAAU;AAC7B,WAAO,MAAM,SAAA;EACf;AAGA,MAAI,OAAO,UAAU,WAAW;AAC9B,WAAO,QAAQ,SAAS;EAC1B;AAGA,MAAI,iBAAiB,MAAM;AACzB,WAAO,MAAM,YAAA;EACf;AAIA,MAAI,MAAM,QAAQ,KAAK,GAAG;AAExB,UAAM,WAAW,MAAM,IAAI,CAAC,SAAS;AACnC,UAAI,SAAS,QAAQ,SAAS,QAAW;AACvC,eAAO;MACT;AACA,UAAI,OAAO,SAAS,UAAU;AAE5B,cAAM,UAAU,KAAK,QAAQ,OAAO,MAAM,EAAE,QAAQ,MAAM,KAAK;AAC/D,eAAO,IAAI,OAAO;MACpB;AACA,aAAO,UAAU,IAAI;IACvB,CAAC;AACD,WAAO,IAAI,SAAS,KAAK,GAAG,CAAC;EAC/B;AAIA,MAAI;AACJ,MAAI;AACF,eAAW,KAAK,UAAU,KAAK;EACjC,QAAQ;AACN,eAAW,OAAO,KAAK;EACzB;AACA,QAAM,IAAI,MAAM,2BAA2B,QAAQ,EAAE;AACvD;;;AC9DO,SAAS,WAAc,SAA0C;AACtE,QAAM,EAAE,OAAO,SAAS,MAAA,IAAU;AAElC,QAAM,SAAmB,CAAA;AACzB,QAAM,cAAiC,EAAE,OAAA;AAEzC,MAAI,OAAO;AAGT,gBAAY,QAAQ,uBAAuB,OAAO,MAAM;EAC1D;AAEA,MAAI,SAAS;AACX,gBAAY,UAAUE,gBAAe,SAAS,MAAM;EACtD;AAEA,MAAI,OAAO;AACT,gBAAY,QAAQ;EACtB;AAKA,MAAI,CAAC,OAAO;AACV,gBAAY,QAAQ;EACtB;AAIA,QAAM,eAAe,OAAO;IAC1B,CAAC,KAAK,OAAO,UAAU;AACrB,YAAM,aAAa,UAAU,KAAK;AAGlC,UAAI,eAAe,IAAI;AACrB,YAAI,GAAG,QAAQ,CAAC,EAAE,IAAI;MACxB;AACA,aAAO;IACT;IACA,CAAA;EAAC;AAGH,SAAO;IACL,GAAG;IACH,QAAQ;EAAA;AAEZ;AAQA,SAASC,iBAAgB,MAAsB;AAC7C,SAAO,IAAI,IAAI;AACjB;AAQA,SAAS,uBACP,KACA,QACQ;AACR,UAAQ,IAAI,MAAA;IACV,KAAK;AACH,aAAO,KAAK,IAAI,KAAK;AACrB,aAAO,IAAI,OAAO,MAAM;IAC1B,KAAK;AAEH,UAAI,IAAI,KAAK,WAAW,GAAG;AACzB,cAAM,IAAI;UACR,4CAA4C,IAAI,KAAK,KAAK,GAAG,CAAC;QAAA;MAElE;AACA,aAAOA,iBAAgB,IAAI,KAAK,CAAC,CAAE;IACrC,KAAK;AACH,aAAOC,iBAAgB,KAAK,MAAM;IACpC;AACE,YAAM,IAAI,MAAM,yBAAyB;EAAA;AAE/C;AAEA,SAASF,gBAAe,SAAqB,QAAgC;AAC3E,QAAM,yBAAyB,QAAQ;IAAI,CAAC,WAC1C,qBAAqB,QAAQ,MAAM;EAAA;AAErC,SAAO,uBAAuB,KAAK,GAAG;AACxC;AAEA,SAAS,qBACP,QACA,QACQ;AAGR,QAAM,EAAE,YAAY,eAAA,IAAmB;AACvC,MAAI,MAAM,uBAAuB,YAAY,MAAM;AAEnD,MAAI,eAAe,cAAc,QAAQ;AACvC,UAAM,GAAG,GAAG;EACd;AAEA,MAAI,eAAe,UAAU,SAAS;AACpC,UAAM,GAAG,GAAG;EACd;AAEA,MAAI,eAAe,UAAU,QAAQ;AACnC,UAAM,GAAG,GAAG;EACd;AAEA,SAAO;AACT;AAKA,SAAS,YAAY,KAA2C;AAC9D,SAAO,IAAI,SAAS,UAAU,IAAI,UAAU,QAAQ,IAAI,UAAU;AACpE;AAEA,SAASE,iBACP,KACA,SAAyB,CAAA,GACjB;AACR,QAAM,EAAE,MAAM,KAAA,IAAS;AAEvB,QAAM,SAAS,UAAU,IAAI;AAK7B,MAAI,eAAe,IAAI,GAAG;AACxB,UAAM,eAAe,KAAK;MAAU,CAAC,QACnC,YAAY,GAAG;IAAA;AAGjB,QAAI,iBAAiB,IAAI;AAGvB,YAAM,IAAI;QACR,yCAAyC,IAAI;MAAA;IAKjD;EACF;AAEA,QAAM,eAAe,KAAK;IAAI,CAAC,QAC7B,uBAAuB,KAAK,MAAM;EAAA;AAIpC,MAAI,SAAS,YAAY,SAAS,eAAe;AAC/C,QAAI,aAAa,WAAW,GAAG;AAC7B,YAAM,IAAI,MAAM,GAAG,IAAI,qBAAqB;IAC9C;AACA,WAAO,GAAG,aAAa,CAAC,CAAC,IAAI,MAAM;EACrC;AAGA,MAAI,SAAS,OAAO;AAClB,QAAI,aAAa,WAAW,GAAG;AAC7B,YAAM,IAAI,MAAM,wBAAwB;IAC1C;AAEA,UAAM,MAAM,KAAK,CAAC;AAClB,QAAI,OAAO,IAAI,SAAS,QAAQ;AAC9B,YAAM,UAAU;AAChB,UAAI,QAAQ,SAAS,YAAY,QAAQ,SAAS,eAAe;AAC/D,cAAM,WAAW,uBAAuB,QAAQ,KAAK,CAAC,GAAI,MAAM;AAChE,eAAO,GAAG,QAAQ;MACpB;IACF;AACA,WAAO,GAAG,MAAM,KAAK,aAAa,CAAC,CAAC;EACtC;AAEA,MAAI,WAAW,IAAI,GAAG;AAEpB,SAAK,SAAS,SAAS,SAAS,SAAS,aAAa,SAAS,GAAG;AAEhE,aAAO,aAAa,IAAI,CAAC,QAAQ,IAAI,GAAG,GAAG,EAAE,KAAK,IAAI,MAAM,GAAG;IACjE;AAEA,QAAI,aAAa,WAAW,GAAG;AAC7B,YAAM,IAAI,MAAM,mBAAmB,IAAI,sBAAsB;IAC/D;AACA,UAAM,CAAC,KAAK,GAAG,IAAI;AAKnB,QAAI,sBAAsB,IAAI,GAAG;AAC/B,YAAM,SAAS,KAAK,CAAC;AACrB,YAAM,SAAS,KAAK,CAAC;AAGrB,UACE,UACA,OAAO,SAAS,SAChB,OAAO,OAAO,UAAU,WACxB;AACA,cAAM,YAAY,OAAO;AAEzB,eAAO,IAAA;AAIP,YAAI,SAAS,MAAM;AACjB,cAAI,cAAc,MAAM;AAEtB,mBAAO,KAAK,KAAK;AACjB,mBAAO,GAAG,GAAG,OAAO,OAAO,MAAM;UACnC,OAAO;AAEL,mBAAO;UACT;QACF,WAAW,SAAS,MAAM;AACxB,cAAI,cAAc,OAAO;AAEvB,mBAAO,KAAK,IAAI;AAChB,mBAAO,GAAG,GAAG,OAAO,OAAO,MAAM;UACnC,OAAO;AAEL,mBAAO;UACT;QACF,WAAW,SAAS,OAAO;AACzB,cAAI,cAAc,MAAM;AAEtB,mBAAO;UACT,OAAO;AAEL,mBAAO,KAAK,KAAK;AACjB,mBAAO,GAAG,GAAG,OAAO,OAAO,MAAM;UACnC;QACF,WAAW,SAAS,OAAO;AACzB,cAAI,cAAc,OAAO;AAEvB,mBAAO;UACT,OAAO;AAEL,mBAAO,KAAK,IAAI;AAChB,mBAAO,GAAG,GAAG,OAAO,OAAO,MAAM;UACnC;QACF;MACF;AAGA,UACE,UACA,OAAO,SAAS,SAChB,OAAO,OAAO,UAAU,WACxB;AACA,cAAM,YAAY,OAAO;AAEzB,eAAO,IAAA;AACP,eAAO,IAAA;AAGP,cAAM,cAAc,uBAAuB,QAAS,MAAM;AAG1D,YAAI,SAAS,MAAM;AAEjB,cAAI,cAAc,MAAM;AACtB,mBAAO;UACT,OAAO;AAEL,mBAAO,KAAK,IAAI;AAChB,mBAAO,GAAG,WAAW,OAAO,OAAO,MAAM;UAC3C;QACF,WAAW,SAAS,MAAM;AAExB,cAAI,cAAc,MAAM;AACtB,mBAAO,KAAK,KAAK;AACjB,mBAAO,GAAG,WAAW,OAAO,OAAO,MAAM;UAC3C,OAAO;AAEL,mBAAO;UACT;QACF,WAAW,SAAS,OAAO;AACzB,cAAI,cAAc,OAAO;AAEvB,mBAAO;UACT,OAAO;AAEL,mBAAO,KAAK,IAAI;AAChB,mBAAO,GAAG,WAAW,OAAO,OAAO,MAAM;UAC3C;QACF,WAAW,SAAS,OAAO;AACzB,cAAI,cAAc,MAAM;AAEtB,mBAAO;UACT,OAAO;AAEL,mBAAO,KAAK,KAAK;AACjB,mBAAO,GAAG,WAAW,OAAO,OAAO,MAAM;UAC3C;QACF;MACF;IACF;AAGA,QAAI,SAAS,MAAM;AACjB,aAAO,GAAG,GAAG,IAAI,MAAM,IAAI,GAAG;IAChC;AACA,WAAO,GAAG,GAAG,IAAI,MAAM,IAAI,GAAG;EAChC;AAEA,SAAO,GAAG,MAAM,IAAI,aAAa,KAAK,GAAG,CAAC;AAC5C;AAEA,SAAS,WAAW,MAAuB;AACzC,QAAM,YAAY;IAChB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EAAA;AAEF,SAAO,UAAU,SAAS,IAAI;AAChC;AAOA,SAAS,eAAe,MAAuB;AAC7C,QAAM,gBAAgB,CAAC,MAAM,MAAM,OAAO,MAAM,OAAO,QAAQ,OAAO;AACtE,SAAO,cAAc,SAAS,IAAI;AACpC;AAMA,SAAS,sBAAsB,MAAuB;AACpD,SAAO,CAAC,MAAM,OAAO,MAAM,KAAK,EAAE,SAAS,IAAI;AACjD;AAEA,SAAS,UAAU,MAAsB;AACvC,QAAM,UAAU;IACd,IAAI;IACJ,IAAI;IACJ,KAAK;IACL,IAAI;IACJ,KAAK;IACL,KAAK;IACL,KAAK;IACL,IAAI;IACJ,KAAK;IACL,aAAa;IACb,QAAQ;IACR,IAAI;;IACJ,MAAM;IACN,OAAO;IACP,OAAO;IACP,OAAO;IACP,QAAQ;IACR,QAAQ;IACR,UAAU;EAAA;AAGZ,QAAM,SAAS,QAAQ,IAA4B;AAEnD,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,8BAA8B,IAAI,EAAE;EACtD;AAEA,SAAO;AACT;;;ACxXA,IAAM,eAAe;AAiCd,SAAS,SAAS,KAAoB,UAA2B;AACtE,MAAI,YAAY,IAAI,QAAQ;AAC1B,UAAM,IAAI,MAAM,wBAAwB;EAC1C;AACA,SAAO,IAAI,QAAQ;AACrB;AAKA,SAAS,mBAAmB,SAG1B;AACA,SAAO;AACT;AAKO,SAAS,aAAa,KAA4B;AACvD,SAAO,IAAI;AACb;AAOO,SAAS,kBACd,KACA,SACS;AACT,QAAM,EAAE,KAAK,MAAA,IAAU,mBAAmB,OAAO;AACjD,QAAM,WAAW,SAAS,KAAK,GAAG;AAClC,SAAO,aAAa,SAAS,aAAa;AAC5C;AAKO,SAAS,cACd,KACA,OACA,OACA,WACM;AACN,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,UAAM,QAAQ,SAAS,KAAK,CAAC;AAG7B,QAAI,UAAU,cAAc;AAC1B,YAAM,gBAAgB,MAAM,CAAC;AAC7B,UAAI,CAAC,cAAc,IAAI,KAAK,GAAG;AAC7B,sBAAc,IAAI,OAAO,oBAAI,IAAA,CAAK;MACpC;AAEA,YAAM,OAAO,cAAc,IAAI,KAAK;AACpC,WAAK,IAAI,KAAK;IAChB;EACF;AACF;AAKO,SAAS,mBACd,KACA,OACA,OACA,WACM;AACN,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,UAAM,QAAQ,SAAS,KAAK,CAAC;AAG7B,QAAI,UAAU,cAAc;AAC1B,YAAM,gBAAgB,MAAM,CAAC;AAC7B,UAAI,eAAe;AACjB,cAAM,SAAS,cAAc,IAAI,KAAK;AACtC,YAAI,QAAQ;AACV,iBAAO,OAAO,KAAK;AAGnB,cAAI,OAAO,SAAS,GAAG;AACrB,0BAAc,OAAO,KAAK;UAC5B;QACF;MACF;IACF;EACF;AACF;AAKO,SAAS,wBACd,SACA,OACY;AACZ,QAAM,EAAE,KAAK,MAAA,IAAU,mBAAmB,OAAO;AACjD,QAAM,gBAAgB,MAAM,GAAG;AAC/B,QAAM,SAAS,+CAAe,IAAI;AAClC,SAAO,UAAA,oBAAc,IAAA;AACvB;AAKO,SAAS,iBACd,SACsC;AACtC,SAAO,QAAQ,QAAQ,UAAU;AACnC;;;ACvGA,IAAM,QAAQ,aAAAC,QAAY,MAAM,gBAAgB;AAKzC,IAAM,sBAAsB,OAAO,mBAAmB;AAmO7D,SAASC,mBACP,SACkD;AAClD,SAAO,iBAAiB,OAAO,KAAK,QAAQ,QAAQ,YAAY;AAClE;AAEA,SAAS,qBACP,SACsE;AACtE,SAAO,iBAAiB,OAAO,KAAK,QAAQ,QAAQ,YAAY;AAClE;AAEA,SAAS,qBACP,SAC+B;AAC/B,SAAO,iBAAiB,OAAO,KAAK,QAAQ,QAAQ,YAAY;AAClE;AAEA,SAAS,mBACP,SACoE;AACpE,SACE,iBAAiB,OAAO,KACvB,QAAQ,QAAQ,YAAuB;AAE5C;AAEA,SAAS,qBAAqB,SAA+C;AAC3E,SAAO;IACL,MAAM,QAAQ,QAAQ;IACtB,MAAM,QAAQ,QAAQ;IACtB,UAAU,QAAQ,QAAQ;EAAA;AAE9B;AAGA,SAAS,SACP,SAC8D;AAC9D,SAAO,WAAW,QAAQ,WAAW,MAAM,QAAQ,QAAQ,QAAQ,KAAK;AAC1E;AAaA,SAAS,uBAA+C;EACtD;EACA;EACA;EACA;EACA;EACA;EACA;AACF,GAYkC;AAEhC,MAAI,aAAa,SAAS;AACxB,WAAO;EACT;AAEA,QAAM,aAAa,OAAO,SAA4B;AAEpD,QAAI,uBAAA,GAA0B;AAE5B,YAAM,iBAAiB,WAAc,IAAI;AACzC,UAAI;AACF,cAAM,EAAE,MAAM,KAAA,IAAS,MAAM,OAAO,cAAc,cAAc;AAIhE,YAAI,CAAC,uBAAA,GAA0B;AAC7B;YACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;UAAA;AAE7C;QACF;AAGA,YAAI,KAAK,SAAS,GAAG;AACnB,gBAAA;AACA,qBAAW,OAAO,MAAM;AACtB,kBAAM;cACJ,MAAM;cACN,OAAO,IAAI;cACX,UAAU;gBACR,GAAG,IAAI;cAAA;YACT,CACD;UACH;AACA,iBAAA;AAEA;YACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE,yBAAyB,KAAK,MAAM;UAAA;QAEnF;MACF,SAAS,OAAO;AACd;UACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;UAC3C;QAAA;AAEF,cAAM;MACR;IACF,WAAW,aAAa,eAAe;AAErC;IACF,OAAO;AAKL,YAAM,EAAE,QAAQ,OAAO,SAAS,MAAA,IAAU;AAE1C,UAAI,QAAQ;AAEV,cAAM,WAAoC,CAAA;AAI1C,cAAM,mBAAsC;UAC1C,OAAO,QAAQ,IAAI,OAAO,OAAO,YAAY,IAAI,OAAO;UACxD;;QAAA;AAGF,cAAM,qBAAqB,WAAc,gBAAgB;AACzD,iBAAS,KAAK,OAAO,gBAAgB,kBAAkB,CAAC;AAExD;UACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;QAAA;AAK7C,cAAM,gBAAmC;UACvC,OAAO,QAAQ,IAAI,OAAO,OAAO,SAAS,IAAI,OAAO;UACrD;UACA;QAAA;AAEF,cAAM,kBAAkB,WAAc,aAAa;AACnD,iBAAS,KAAK,OAAO,gBAAgB,eAAe,CAAC;AAErD;UACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE,oDAAoD,KAAK;QAAA;AAItG,cAAM,QAAQ,IAAI,QAAQ;MAC5B,OAAO;AAEL,cAAM,iBAAiB,WAAc,IAAI;AACzC,cAAM,OAAO,gBAAgB,cAAc;MAC7C;IACF;EACF;AAEA,SAAO,IAAI,uBAAuB,EAAE,WAAA,CAAY;AAClD;AAyDO,SAAS,0BACd,QAQA;AACA,QAAM,YAAY,IAAI,MAAA,oBAAqB,IAAI,CAAA,CAAE,CAAC;AAClD,QAAM,gBAAgB,IAAI,MAA+B,CAAA,CAAE;AAC3D,QAAM,mBAAmB,OAAO,YAAY;AAC5C,QAAM,gBACJ,qBAAqB,gBAAgB,cAAc;AACrD,QAAM,iBAAiB,IAAI,MAWzB,oBAAI,IAAA,CAAK;AAGX,QAAM,uBAAuB,IAAI,MAA2B,CAAA,CAAE;AAI9D,QAAM,iBAAiB,IAAI,MAAe,KAAK;AAK/C,QAAM,uBAAuB,CAAC,aAA4B;AACxD,QAAI,SAAS,SAAS,GAAG;AACvB,qBAAe,SAAS,CAAC,YAAY;AACnC,cAAM,aAAa,IAAI,IAAI,OAAO;AAClC,iBAAS,QAAQ,CAAC,OAAO,WAAW,OAAO,EAAE,CAAC;AAC9C,eAAO;MACT,CAAC;IACH;EACF;AAKA,QAAM,+BAA+B,MAAM;AACzC,UAAM,mBAAkC,CAAA;AACxC,mBAAe,MAAM,QAAQ,CAAC,OAAO,YAAY;AAC/C,UAAI,MAAM,SAAS;AACjB,qBAAa,MAAM,SAAS;AAC5B,cAAM,QAAQ,IAAI;AAClB,yBAAiB,KAAK,OAAO;AAC7B;UACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;UACrC;QAAA;MAEJ;IACF,CAAC;AACD,yBAAqB,gBAAgB;EACvC;AACA,QAAM,OAAO,mBAAsB,OAAO,cAAc;IACtD;IACA;IACA,UAAU;IACV;IACA;IACA;IACA;IACA;IACA,cAAc,OAAO;IACrB,WAAW,OAAO,mBAAmB;EAAA,CACtC;AAQD,QAAM,YAAyB,OAC7B,MACA,UAAkB,QACG;AACrB;MACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;MACrC;IAAA;AAEF,QAAI,OAAO,SAAS,UAAU;AAC5B,YAAM,IAAI,+BAA+B,OAAO,MAAM,OAAO,EAAE;IACjE;AAGA,UAAM,UAAU,UAAU,MAAM,IAAI,IAAI;AACxC,QAAI,QAAS,QAAO;AAGpB,UAAM,cAAc,cAAc,MAAM;MAAK,CAAC,aAC5C,oBAAoB,MAAM,QAAQ;IAAA;AAEpC,QAAI,YAAa,QAAO;AAExB,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,YAAM,YAAY,WAAW,MAAM;AACjC,6BAAA;AACA,iCAAA;AACA,eAAO,IAAI,2BAA2B,MAAM,OAAO,EAAE,CAAC;MACxD,GAAG,OAAO;AAEV,YAAM,uBAAuB,UAAU,UAAU,MAAM;AACrD,YAAI,UAAU,MAAM,IAAI,IAAI,GAAG;AAC7B;YACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;YACrC;UAAA;AAEF,uBAAa,SAAS;AACtB,+BAAA;AACA,mCAAA;AACA,kBAAQ,IAAI;QACd;MACF,CAAC;AAED,YAAM,2BAA2B,cAAc,UAAU,MAAM;AAC7D,cAAM,kBAAkB,cAAc,MAAM;UAAK,CAAC,aAChD,oBAAoB,MAAM,QAAQ;QAAA;AAEpC,YAAI,iBAAiB;AACnB;YACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;YACrC;YACA;UAAA;AAEF,uBAAa,SAAS;AACtB,mCAAA;AACA,+BAAA;AACA,kBAAQ,IAAI;QACd;MACF,CAAC;IACH,CAAC;EACH;AAQA,QAAM,aAAgC,OACpC,SACA,UAAkB,QACG;AACrB;MACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;IAAA;AAGvC,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,YAAM,UAAU,KAAK,OAAA,EAAS,SAAS,EAAE;AAEzC,YAAM,eAAe,MAAM;AACzB,uBAAe,SAAS,CAAC,YAAY;AACnC,gBAAM,aAAa,IAAI,IAAI,OAAO;AAClC,qBAAW,OAAO,OAAO;AACzB,iBAAO;QACT,CAAC;MACH;AAEA,YAAM,YAAY,MAAM;AACtB,qBAAA;AACA,eAAO,IAAI,4BAA4B,OAAO,EAAE,CAAC;MACnD;AAEA,YAAM,YAAY,WAAW,WAAW,OAAO;AAI/C,YAAM,aAAa,CAAC,YAA0B;AAC5C,YAAI,QAAQ,OAAO,GAAG;AACpB;YACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;UAAA;AAGvC,yBAAe,SAAS,CAAC,YAAY;AACnC,kBAAM,aAAa,IAAI,IAAI,OAAO;AAClC,kBAAM,WAAW,WAAW,IAAI,OAAO;AACvC,gBAAI,UAAU;AACZ,yBAAW,IAAI,SAAS,EAAE,GAAG,UAAU,SAAS,KAAA,CAAM;YACxD;AACA,mBAAO;UACT,CAAC;AACD,iBAAO;QACT;AACA,eAAO;MACT;AAGA,iBAAW,WAAW,qBAAqB,OAAO;AAChD,YAAI,QAAQ,OAAO,GAAG;AAGpB,cAAI,eAAe,OAAO;AACxB;cACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;YAAA;AAEvC,yBAAa,SAAS;AACtB,oBAAQ,IAAI;AACZ;UACF;AAGA;YACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;UAAA;AAEvC,yBAAe,SAAS,CAAC,YAAY;AACnC,kBAAM,aAAa,IAAI,IAAI,OAAO;AAClC,uBAAW,IAAI,SAAS;cACtB,SAAS;cACT;cACA;cACA;cACA,SAAS;;YAAA,CACV;AACD,mBAAO;UACT,CAAC;AACD;QACF;MACF;AAIA,qBAAe,SAAS,CAAC,YAAY;AACnC,cAAM,aAAa,IAAI,IAAI,OAAO;AAClC,mBAAW,IAAI,SAAS;UACtB,SAAS;UACT;UACA;UACA;UACA,SAAS;QAAA,CACV;AACD,eAAO;MACT,CAAC;IACH,CAAC;EACH;AAKA,QAAM,0BAA0B,OAC9B,WACkB;AAElB,QAAI,UAAU,UAAU,QAAQ;AAC9B,YAAM,UAAU,OAAO;AAEvB,UAAI,MAAM,QAAQ,OAAO,IAAI,GAAG;AAC9B,cAAM,QAAQ,IAAI,OAAO,KAAK,IAAI,CAAC,SAAS,UAAU,MAAM,OAAO,CAAC,CAAC;MACvE,OAAO;AACL,cAAM,UAAU,OAAO,MAAM,OAAO;MACtC;IACF;EAEF;AAGA,QAAM,kBAAkB,OAAO,WAC3B,OACE,WAKG;AACH,UAAM,gBAAgB,MAAM,OAAO,SAAU,MAAM;AACnD,UAAM,wBAAwB,aAAa;AAC3C,WAAO;EACT,IACA;AAEJ,QAAM,kBAAkB,OAAO,WAC3B,OACE,WAKG;AACH,UAAM,gBAAgB,MAAM,OAAO,SAAU,MAAM;AACnD,UAAM,wBAAwB,aAAa;AAC3C,WAAO;EACT,IACA;AAEJ,QAAM,kBAAkB,OAAO,WAC3B,OACE,WAKG;AACH,UAAM,gBAAgB,MAAM,OAAO,SAAU,MAAM;AACnD,UAAM,wBAAwB,aAAa;AAC3C,WAAO;EACT,IACA;AAGJ,QAAM;IACJ,cAAc;IACd,UAAU;IACV,UAAU;IACV,UAAU;IACV,GAAG;EAAA,IACD;AAEJ,SAAO;IACL,GAAG;IACH,UAAU;IACV;IACA,UAAU;IACV,UAAU;IACV,UAAU;IACV,OAAO;MACL;MACA;IAAA;EACF;AAEJ;AAKA,SAAS,mBACP,cACA,SAuBe;AACf,QAAM;IACJ;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EAAA,IACE;AACJ,QAAM,qBAAqB;AAG3B,QAAM,iBAAiB,IAAI,MAA0B,MAAS;AAE9D,QAAM,WAAA,oBAAe,IAAA;AAKrB,QAAM,WAAW,CAAC,QAAgC;AAChD,UAAM,YAAY,SAAS,IAAI,GAAG;AAClC,QAAI,WAAW;AACb,aAAO;IACT;AAEA,UAAM,YAAY,IAAI,MAAM,GAAG;AAC/B,aAAS,IAAI,KAAK,SAAS;AAC3B,WAAO;EACT;AAGA,QAAM,aAAA,oBAAiB,IAAA;AACvB,QAAM,WAAqB,CAAA;AAC3B,MAAI,YAAgC;AAKpC,QAAM,qBAAqB,CAAC,WAAyB;AACnD,QAAI,SAAS,SAAS,QAAQ;AAE5B,eAAS,IAAI,SAAS,QAAQ,IAAI,QAAQ,KAAK;AAC7C,iBAAS,CAAC,IAAI,oBAAI,IAAA;MACpB;IACF;EACF;AAKA,QAAM,eAAe,CACnB,MACA,OACA,cACS;AACT,eAAW,OAAO,MAAM;AACtB,YAAM,YAAY,SAAS,GAAG;AAG9B,UAAI,cAAc,QAAW;AAC3B,oBAAY,aAAa,SAAS;AAClC,2BAAmB,SAAS;MAC9B;AAGA,YAAM,mBAAmB,aAAa,SAAS;AAC/C,UAAI,qBAAqB,WAAW;AAClC;UACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE,iCAAiC,SAAS,SAAS,gBAAgB;QAAA;AAEhH;MACF;AAEA,gBAAU,IAAI,GAAG;AACjB,oBAAc,WAAW,OAAO,UAAU,SAAS;IACrD;EACF;AAKA,QAAM,oBAAoB,CACxB,aACA,OACA,cACS;AACT,QAAI,cAAc,QAAW;AAC3B;IACF;AAEA,eAAW,OAAO,aAAa;AAC7B,YAAM,YAAY,SAAS,GAAG;AAC9B,gBAAU,OAAO,GAAG;AACpB,yBAAmB,WAAW,OAAO,UAAU,SAAS;AAKxD,eAAS,OAAO,GAAG;IACrB;EACF;AAKA,QAAM,8BAA8B,CAClC,MACA,aACA,UACiB;AAEjB,QAAI,CAAC,WAAW,IAAI,KAAK,GAAG;AAC1B,iBAAW,IAAI,OAAO,oBAAI,IAAA,CAAK;IACjC;AACA,UAAM,YAAY,WAAW,IAAI,KAAK;AAGtC,QAAI,MAAM;AACR,mBAAa,MAAM,OAAO,SAAS;IACrC;AAGA,QAAI,aAAa;AACf,wBAAkB,aAAa,OAAO,SAAS;IACjD;AAEA,WAAO;EACT;AAKA,QAAM,wBAAwB,MAAY;AACxC,eAAW,MAAA;AACX,aAAS,SAAS;AAClB,gBAAY;EACd;AAMA,QAAM,kBAAkB,CAAC,UAAuB;AAC9C,QAAI,cAAc,QAAW;AAC3B;IACF;AAEA,UAAM,YAAY,WAAW,IAAI,KAAK;AACtC,QAAI,CAAC,WAAW;AACd;IACF;AAGA,eAAW,OAAO,WAAW;AAC3B,YAAM,YAAY,SAAS,GAAG;AAC9B,YAAM,mBAAmB,aAAa,SAAS;AAC/C,UAAI,qBAAqB,WAAW;AAClC,2BAAmB,WAAW,OAAO,UAAU,SAAS;MAC1D;AACA,eAAS,OAAO,GAAG;IACrB;AAGA,eAAW,OAAO,KAAK;EACzB;AAMA,QAAM,4BAA4B,CAChC,OACA,YACY;AACZ,UAAM,YAAY,WAAW,IAAI,KAAK;AACtC,QAAI,CAAC,WAAW;AACd,aAAO;IACT;AAGA,eAAW,OAAO,WAAW;AAC3B,YAAM,YAAY,SAAS,GAAG;AAC9B,UAAI,kBAAkB,WAAW,OAAO,GAAG;AACzC,kBAAU,OAAO,GAAG;AACpB,2BAAmB,WAAW,OAAO,UAAU,SAAU;MAC3D;IACF;AAGA,QAAI,UAAU,SAAS,GAAG;AACxB,iBAAW,OAAO,KAAK;AACvB,aAAO;IACT;AAEA,WAAO;EACT;AAKA,QAAM,sBAAsB,CAC1B,UACA,OACA,OACA,uBACY;AACZ,QAAI,cAAc,QAAW;AAC3B;QACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;MAAA;AAE7C,aAAO;IACT;AAEA,QAAI,YAAY;AAGhB,eAAW,WAAW,UAAU;AAE9B,YAAM,iBAAiB,wBAAwB,SAAS,QAAQ;AAEhE,iBAAW,SAAS,gBAAgB;AAClC,YAAI,0BAA0B,OAAO,OAAO,GAAG;AAE7C,cAAI,CAAC,WAAW;AACd,kBAAA;AACA,wBAAY;UACd;AAEA,gBAAM;YACJ,MAAM;YACN,KAAK;UAAA,CACN;QACH;MACF;IACF;AAEA,WAAO;EACT;AAMA,QAAM,kBAAkB,MAA+B;;AAErD,UAAM,SAAS,eAAe,SAAS;AAEvC,WAAO;MACL,YAAU,kBAAa,WAAb,mBAAqB,SAC3B,CAAC,QAAQ,aAAa,OAAO,KAAK,IAClC;IAAA;EAER;AAEA,MAAI;AAEJ,SAAO;IACL,MAAM,CAAC,WAAiD;AACtD,YAAM,EAAE,OAAO,OAAO,QAAQ,WAAW,UAAU,WAAA,IAAe;AAGlE,UAAI,uBAA6C;AACjD,YAAM,mBAAmB,CAAC,gBAAyB;AAEjD,YACE,eACA,aAAa,kBACb,uCAAW,qBACX;AAEA,iCAAuB,UAAU,mBAAA;AACjC,+BAAqB,KAAK,MAAM;AAC9B,sBAAA;UACF,CAAC;QACH,OAAO;AAEL,oBAAA;QACF;MACF;AAGA,YAAM,kBAAkB,IAAI,gBAAA;AAE5B,UAAI,aAAa,QAAQ;AACvB,qBAAa,OAAO;UAClB;UACA,MAAM;AACJ,4BAAgB,MAAA;UAClB;UACA;YACE,MAAM;UAAA;QACR;AAEF,YAAI,aAAa,OAAO,SAAS;AAC/B,0BAAgB,MAAA;QAClB;MACF;AAGA,sBAAgB,OAAO,iBAAiB,SAAS,MAAM;AACrD,uBAAe,SAAS,CAAC,YAAY;AACnC,kBAAQ,QAAQ,CAAC,UAAU;AACzB,yBAAa,MAAM,SAAS;AAC5B,kBAAM,OAAO,IAAI,mBAAA,CAAoB;UACvC,CAAC;AACD,iBAAA,oBAAW,IAAA;QACb,CAAC;MACH,CAAC;AAED,YAAM,SAAS,IAAI,YAAY;QAC7B,GAAG;;QAEH,KAAK,aAAa,cAAc,iBAAiB;;;QAGjD,QACE,aAAa,WAAW,aAAa,cAAc,QAAQ;QAC7D,QAAQ,gBAAgB;QACxB,SAAS,CAAC,gBAAgB;AAMxB,oBAAA;AAEA,cAAI,aAAa,SAAS;AACxB,mBAAO,aAAa,QAAQ,WAAW;UACzC,OAAO;AACL,oBAAQ;cACN,+CAA+C,WAAW,EAAE;;;cAG5D;YAAA;UAEJ;AAEA;QACF;MAAA,CACD;AACD,UAAI,qBAAqB;AACzB,YAAM,WAAA,oBAAe,IAAA;AACrB,YAAM,eAAwC,CAAA;AAC9C,UAAI,sBAAsB;AAI1B,YAAM,yBAAyB,MAC7B,aAAa,iBAAiB,CAAC;AACjC,YAAM,mBAAsC,CAAA;AAK5C,YAAM,uBAAuB,CAAC,kBAA8B;AAC1D,YAAI,CAAC,gBAAgB,aAAa,GAAG;AACnC;QACF;AAGA,cAAM,OAAO,cAAc,QAAQ;AACnC,cAAM,cAAc,cAAc,QAAQ;AAC1C,cAAM,UAAU,QAAQ;AAExB,cAAM,QAAQ,WAAW,eAAe,cAAc,KAAK;AAC3D,cAAM,YAAY,cAAc,QAAQ;AAExC,YAAI,cAAc,UAAU;AAC1B,0BAAgB,KAAK;QACvB,WAAW,SAAS;AAClB,sCAA4B,MAAM,aAAa,KAAK;QACtD;AAEA,cAAM;UACJ,MAAM,cAAc,QAAQ;UAC5B,OAAO,cAAc;;UAErB,UAAU;YACR,GAAG,cAAc;UAAA;QACnB,CACD;MACH;AAKA,YAAM,mBAAmB,uBAAuB;QAC9C;QACA;QACA;QACA;QACA;QACA;QACA;MAAA,CACD;AAED,0BAAoB,OAAO,UAAU,CAAC,aAAgC;;AAEpE,YAAI,cAAkD;AAMtD,uBAAe,SAAS,MAAM,KAAK;AAEnC,mBAAW,WAAW,UAAU;AAE9B,cAAI,gBAAgB,OAAO,KAAK,iBAAiB,OAAO,GAAG;AACzD,iCAAqB,SAAS,CAAC,kBAAkB;AAC/C,oBAAM,YAAY,CAAC,GAAG,eAAe,OAAO;AAE5C,kBAAI,UAAU,SAAS,oBAAoB;AACzC,0BAAU,OAAO,GAAG,UAAU,SAAS,kBAAkB;cAC3D;AACA,qBAAO;YACT,CAAC;UACH;AAIA,cAAI,SAAS,OAAO,KAAK,CAAC,uBAAA,GAA0B;AAClD,0BAAQ,QAAQ,UAAhB,mBAAuB,QAAQ,CAAC,SAAS,SAAS,IAAI,IAAI;UAC5D;AAIA,gBAAM,kBAAiC,CAAA;AACvC,yBAAe,MAAM,QAAQ,CAAC,OAAO,YAAY;AAC/C,gBAAI,CAAC,MAAM,SAAS;AAClB,kBAAI;AACF,sBAAM,QAAQ,OAAO;cACvB,SAAS,KAAK;AAEZ,6BAAa,MAAM,SAAS;AAC5B,sBAAM;kBACJ,eAAe,QAAQ,MAAM,IAAI,MAAM,OAAO,GAAG,CAAC;gBAAA;AAEpD,gCAAgB,KAAK,OAAO;AAC5B,sBAAM,qBAAqB,GAAG;cAChC;YACF;UACF,CAAC;AAGD,+BAAqB,eAAe;AAEpC,cAAI,gBAAgB,OAAO,GAAG;AAE5B,kBAAM,SAAS,QAAQ,QAAQ;AAC/B,gBAAI,UAAU,OAAO,WAAW,UAAU;AAExC,6BAAe,SAAS,MAAM,MAAM;YACtC;AAGA,gBAAI,uBAAA,GAA0B;AAC5B,+BAAiB,KAAK,OAAO;YAC/B,OAAO;AAEL,kBAAI,CAAC,oBAAoB;AACvB,sBAAA;AACA,qCAAqB;cACvB;AAEA,mCAAqB,OAAO;YAC9B;UACF,WAAW,qBAAqB,OAAO,GAAG;AAGxC,gBAAI,CAAC,uBAAA,GAA0B;AAC7B,2BAAa,KAAK,qBAAqB,OAAO,CAAC;YACjD;UACF,WAAWA,mBAAkB,OAAO,GAAG;AAErC,0BAAc;UAChB,WAAW,mBAAmB,OAAO,GAAG;AAEtC,gBAAI,gBAAgB,cAAc;AAChC,4BAAc;YAChB;UACF,WAAW,iBAAiB,OAAO,GAAG;AAEpC,gBAAI,uBAAA,GAA0B;AAC5B,+BAAiB,KAAK,OAAO;YAC/B,OAAO;AAEL,mCAAqB;gBACnB,QAAQ,QAAQ;gBAChB;gBACA;gBACA;cAAA;YAEJ;UACF,WAAW,qBAAqB,OAAO,GAAG;AACxC;cACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;YAAA;AAI7C,gBAAI,CAAC,oBAAoB;AACvB,oBAAA;AACA,mCAAqB;YACvB;AAEA,qBAAA;AAGA,kCAAA;AAIA,iEAAkB;AAGlB,0BAAc;AACd,kCAAsB;AACtB,6BAAiB,SAAS;UAC5B;QACF;AAEA,YAAI,gBAAgB,MAAM;AAExB,cAAI,uBAAA,KAA4B,gBAAgB,cAAc;AAC5D;cACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE,iDAAiD,iBAAiB,MAAM;YAAA;AAIrH,kBAAA;AAGA,qBAAA;AAGA,kCAAA;AAGA,uBAAW,eAAe,kBAAkB;AAC1C,kBAAI,gBAAgB,WAAW,GAAG;AAChC,qCAAqB,WAAW;AAGhC,oBAAI,SAAS,WAAW,GAAG;AACzB,oCAAY,QAAQ,UAApB,mBAA2B;oBAAQ,CAAC,SAClC,SAAS,IAAI,IAAI;;gBAErB;cACF,WAAW,qBAAqB,WAAW,GAAG;AAE5C,6BAAa,KAAK,qBAAqB,WAAW,CAAC;cACrD,WAAW,iBAAiB,WAAW,GAAG;AAExC;kBACE,YAAY,QAAQ;kBACpB;kBACA;kBACA;gBAAA;cAEJ;YACF;AAGA,mBAAA;AAIA,6BAAiB,SAAS;AAE1B;cACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;YAAA;UAE/C,OAAO;AAGL,gBAAI,oBAAoB;AACtB,qBAAA;AACA,mCAAqB;YACvB;UACF;AACA,2BAAiB,uBAAA,CAAwB;AAGzC,cAAI,gBAAgB,cAAc;AAChC,kCAAsB;UACxB;AAGA,oBAAU,SAAS,CAAC,iBAAiB;AACnC,kBAAM,aAAa,IAAI,IAAU,YAAY;AAC7C,gBAAI,SAAS,OAAO,GAAG;AACrB;gBACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;gBAC3C,MAAM,KAAK,QAAQ;cAAA;YAEvB;AACA,qBAAS,QAAQ,CAAC,SAAS,WAAW,IAAI,IAAI,CAAC;AAC/C,qBAAS,MAAA;AACT,mBAAO;UACT,CAAC;AAGD,wBAAc,SAAS,CAAC,qBAAqB;AAC3C,kBAAM,OAAO,CAAC,GAAG,kBAAkB,GAAG,YAAY;AAClD,yBAAa;cAAQ,CAAC,aACpB;gBACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;gBAC3C;cAAA;YACF;AAEF,yBAAa,SAAS;AACtB,mBAAO;UACT,CAAC;AAKD,yBAAe,SAAS,MAAM,IAAI;AAElC,uCAAA;QACF;MACF,CAAC;AAID,aAAO;QACL,YAAY,qDAAkB;QAC9B,SAAS,MAAM;AAEb,4BAAA;AAEA,0BAAgB,MAAA;AAEhB,+DAAkB;QACpB;MAAA;IAEJ;;IAEA;EAAA;AAEJ;",
  "names": ["fetch", "_a", "value", "pos", "debug", "_fetchClient", "_a", "_b", "fetch", "_subscribers", "_error", "_subscribers", "_error", "compileOrderBy", "quoteIdentifier", "compileFunction", "DebugModule", "isUpToDateMessage"]
}
