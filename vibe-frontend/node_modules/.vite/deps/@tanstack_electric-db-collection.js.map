{
  "version": 3,
  "sources": ["../../../../node_modules/.pnpm/@microsoft+fetch-event-source@2.0.1/node_modules/@microsoft/fetch-event-source/src/parse.ts", "../../../../node_modules/.pnpm/@microsoft+fetch-event-source@2.0.1/node_modules/@microsoft/fetch-event-source/src/fetch.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/error.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/parser.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/column-mapper.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/helpers.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/constants.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/fetch.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/client.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/expired-shapes-cache.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/up-to-date-tracker.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/snapshot-tracker.ts", "../../../../node_modules/.pnpm/@electric-sql+client@1.2.0/node_modules/@electric-sql/client/src/shape.ts", "../../../../node_modules/.pnpm/@tanstack+store@0.8.0/node_modules/@tanstack/store/src/scheduler.ts", "../../../../node_modules/.pnpm/@tanstack+store@0.8.0/node_modules/@tanstack/store/src/types.ts", "../../../../node_modules/.pnpm/@tanstack+store@0.8.0/node_modules/@tanstack/store/src/store.ts", "../../../../node_modules/.pnpm/@tanstack+electric-db-collection@0.2.6_typescript@5.9.2/node_modules/@tanstack/electric-db-collection/src/errors.ts", "../../../../node_modules/.pnpm/@tanstack+electric-db-collection@0.2.6_typescript@5.9.2/node_modules/@tanstack/electric-db-collection/src/pg-serializer.ts", "../../../../node_modules/.pnpm/@tanstack+electric-db-collection@0.2.6_typescript@5.9.2/node_modules/@tanstack/electric-db-collection/src/sql-compiler.ts", "../../../../node_modules/.pnpm/@tanstack+electric-db-collection@0.2.6_typescript@5.9.2/node_modules/@tanstack/electric-db-collection/src/electric.ts"],
  "sourcesContent": [null, null, "export class FetchError extends Error {\n  status: number\n  text?: string\n  json?: object\n  headers: Record<string, string>\n\n  constructor(\n    status: number,\n    text: string | undefined,\n    json: object | undefined,\n    headers: Record<string, string>,\n    public url: string,\n    message?: string\n  ) {\n    super(\n      message ||\n        `HTTP Error ${status} at ${url}: ${text ?? JSON.stringify(json)}`\n    )\n    this.name = `FetchError`\n    this.status = status\n    this.text = text\n    this.json = json\n    this.headers = headers\n  }\n\n  static async fromResponse(\n    response: Response,\n    url: string\n  ): Promise<FetchError> {\n    const status = response.status\n    const headers = Object.fromEntries([...response.headers.entries()])\n    let text: string | undefined = undefined\n    let json: object | undefined = undefined\n\n    const contentType = response.headers.get(`content-type`)\n    if (!response.bodyUsed) {\n      if (contentType && contentType.includes(`application/json`)) {\n        json = (await response.json()) as object\n      } else {\n        text = await response.text()\n      }\n    }\n\n    return new FetchError(status, text, json, headers, url)\n  }\n}\n\nexport class FetchBackoffAbortError extends Error {\n  constructor() {\n    super(`Fetch with backoff aborted`)\n    this.name = `FetchBackoffAbortError`\n  }\n}\n\nexport class InvalidShapeOptionsError extends Error {\n  constructor(message: string) {\n    super(message)\n    this.name = `InvalidShapeOptionsError`\n  }\n}\n\nexport class MissingShapeUrlError extends Error {\n  constructor() {\n    super(`Invalid shape options: missing required url parameter`)\n    this.name = `MissingShapeUrlError`\n  }\n}\n\nexport class InvalidSignalError extends Error {\n  constructor() {\n    super(`Invalid signal option. It must be an instance of AbortSignal.`)\n    this.name = `InvalidSignalError`\n  }\n}\n\nexport class MissingShapeHandleError extends Error {\n  constructor() {\n    super(\n      `shapeHandle is required if this isn't an initial fetch (i.e. offset > -1)`\n    )\n    this.name = `MissingShapeHandleError`\n  }\n}\n\nexport class ReservedParamError extends Error {\n  constructor(reservedParams: string[]) {\n    super(\n      `Cannot use reserved Electric parameter names in custom params: ${reservedParams.join(`, `)}`\n    )\n    this.name = `ReservedParamError`\n  }\n}\n\nexport class ParserNullValueError extends Error {\n  constructor(columnName: string) {\n    super(`Column \"${columnName ?? `unknown`}\" does not allow NULL values`)\n    this.name = `ParserNullValueError`\n  }\n}\n\nexport class ShapeStreamAlreadyRunningError extends Error {\n  constructor() {\n    super(`ShapeStream is already running`)\n    this.name = `ShapeStreamAlreadyRunningError`\n  }\n}\n\nexport class MissingHeadersError extends Error {\n  constructor(url: string, missingHeaders: Array<string>) {\n    let msg = `The response for the shape request to ${url} didn't include the following required headers:\\n`\n    missingHeaders.forEach((h) => {\n      msg += `- ${h}\\n`\n    })\n    msg += `\\nThis is often due to a proxy not setting CORS correctly so that all Electric headers can be read by the client.`\n    msg += `\\nFor more information visit the troubleshooting guide: /docs/guides/troubleshooting/missing-headers`\n    super(msg)\n  }\n}\n", "import { ColumnInfo, GetExtensions, Row, Schema, Value } from './types'\nimport { ParserNullValueError } from './error'\n\ntype Token = string\ntype NullableToken = Token | null\nexport type ParseFunction<Extensions = never> = (\n  value: Token,\n  additionalInfo?: Omit<ColumnInfo, `type` | `dims`>\n) => Value<Extensions>\ntype NullableParseFunction<Extensions = never> = (\n  value: NullableToken,\n  additionalInfo?: Omit<ColumnInfo, `type` | `dims`>\n) => Value<Extensions>\n/**\n * @typeParam Extensions - Additional types that can be parsed by this parser beyond the standard SQL types.\n *                         Defaults to no additional types.\n */\nexport type Parser<Extensions = never> = {\n  [key: string]: ParseFunction<Extensions>\n}\n\nexport type TransformFunction<Extensions = never> = (\n  message: Row<Extensions>\n) => Row<Extensions>\n\nconst parseNumber = (value: string) => Number(value)\nconst parseBool = (value: string) => value === `true` || value === `t`\nconst parseBigInt = (value: string) => BigInt(value)\nconst parseJson = (value: string) => JSON.parse(value)\nconst identityParser: ParseFunction = (v: string) => v\n\nexport const defaultParser: Parser = {\n  int2: parseNumber,\n  int4: parseNumber,\n  int8: parseBigInt,\n  bool: parseBool,\n  float4: parseNumber,\n  float8: parseNumber,\n  json: parseJson,\n  jsonb: parseJson,\n}\n\n// Taken from: https://github.com/electric-sql/pglite/blob/main/packages/pglite/src/types.ts#L233-L279\nexport function pgArrayParser<Extensions>(\n  value: Token,\n  parser?: NullableParseFunction<Extensions>\n): Value<Extensions> {\n  let i = 0\n  let char = null\n  let str = ``\n  let quoted = false\n  let last = 0\n  let p: string | undefined = undefined\n\n  function extractValue(x: Token, start: number, end: number) {\n    let val: Token | null = x.slice(start, end)\n    val = val === `NULL` ? null : val\n    return parser ? parser(val) : val\n  }\n\n  function loop(x: string): Array<Value<Extensions>> {\n    const xs = []\n    for (; i < x.length; i++) {\n      char = x[i]\n      if (quoted) {\n        if (char === `\\\\`) {\n          str += x[++i]\n        } else if (char === `\"`) {\n          xs.push(parser ? parser(str) : str)\n          str = ``\n          quoted = x[i + 1] === `\"`\n          last = i + 2\n        } else {\n          str += char\n        }\n      } else if (char === `\"`) {\n        quoted = true\n      } else if (char === `{`) {\n        last = ++i\n        xs.push(loop(x))\n      } else if (char === `}`) {\n        quoted = false\n        last < i && xs.push(extractValue(x, last, i))\n        last = i + 1\n        break\n      } else if (char === `,` && p !== `}` && p !== `\"`) {\n        xs.push(extractValue(x, last, i))\n        last = i + 1\n      }\n      p = char\n    }\n    last < i && xs.push(xs.push(extractValue(x, last, i + 1)))\n    return xs\n  }\n\n  return loop(value)[0]\n}\n\nexport class MessageParser<T extends Row<unknown>> {\n  private parser: Parser<GetExtensions<T>>\n  private transformer?: TransformFunction<GetExtensions<T>>\n  constructor(\n    parser?: Parser<GetExtensions<T>>,\n    transformer?: TransformFunction<GetExtensions<T>>\n  ) {\n    // Merge the provided parser with the default parser\n    // to use the provided parser whenever defined\n    // and otherwise fall back to the default parser\n    this.parser = { ...defaultParser, ...parser }\n    this.transformer = transformer\n  }\n\n  parse<Result>(messages: string, schema: Schema): Result {\n    return JSON.parse(messages, (key, value) => {\n      // typeof value === `object` && value !== null\n      // is needed because there could be a column named `value`\n      // and the value associated to that column will be a string or null.\n      // But `typeof null === 'object'` so we need to make an explicit check.\n      // We also parse the `old_value`, which appears on updates when `replica=full`.\n      if (\n        (key === `value` || key === `old_value`) &&\n        typeof value === `object` &&\n        value !== null\n      ) {\n        return this.transformMessageValue(value, schema)\n      }\n      return value\n    }) as Result\n  }\n\n  /**\n   * Parse an array of ChangeMessages from a snapshot response.\n   * Applies type parsing and transformations to the value and old_value properties.\n   */\n  parseSnapshotData<Result>(\n    messages: Array<unknown>,\n    schema: Schema\n  ): Array<Result> {\n    return messages.map((message) => {\n      const msg = message as Record<string, unknown>\n\n      // Transform the value property if it exists\n      if (msg.value && typeof msg.value === `object` && msg.value !== null) {\n        msg.value = this.transformMessageValue(msg.value, schema)\n      }\n\n      // Transform the old_value property if it exists\n      if (\n        msg.old_value &&\n        typeof msg.old_value === `object` &&\n        msg.old_value !== null\n      ) {\n        msg.old_value = this.transformMessageValue(msg.old_value, schema)\n      }\n\n      return msg as Result\n    })\n  }\n\n  /**\n   * Transform a message value or old_value object by parsing its columns.\n   */\n  private transformMessageValue(\n    value: unknown,\n    schema: Schema\n  ): Row<GetExtensions<T>> {\n    const row = value as Record<string, Value<GetExtensions<T>>>\n    Object.keys(row).forEach((key) => {\n      row[key] = this.parseRow(key, row[key] as NullableToken, schema)\n    })\n\n    return this.transformer ? this.transformer(row) : row\n  }\n\n  // Parses the message values using the provided parser based on the schema information\n  private parseRow(\n    key: string,\n    value: NullableToken,\n    schema: Schema\n  ): Value<GetExtensions<T>> {\n    const columnInfo = schema[key]\n    if (!columnInfo) {\n      // We don't have information about the value\n      // so we just return it\n      return value\n    }\n\n    // Copy the object but don't include `dimensions` and `type`\n    const { type: typ, dims: dimensions, ...additionalInfo } = columnInfo\n\n    // Pick the right parser for the type\n    // and support parsing null values if needed\n    // if no parser is provided for the given type, just return the value as is\n    const typeParser = this.parser[typ] ?? identityParser\n    const parser = makeNullableParser(typeParser, columnInfo, key)\n\n    if (dimensions && dimensions > 0) {\n      // It's an array\n      const nullablePgArrayParser = makeNullableParser(\n        (value, _) => pgArrayParser(value, parser),\n        columnInfo,\n        key\n      )\n      return nullablePgArrayParser(value)\n    }\n\n    return parser(value, additionalInfo)\n  }\n}\n\nfunction makeNullableParser<Extensions>(\n  parser: ParseFunction<Extensions>,\n  columnInfo: ColumnInfo,\n  columnName?: string\n): NullableParseFunction<Extensions> {\n  const isNullable = !(columnInfo.not_null ?? false)\n  // The sync service contains `null` value for a column whose value is NULL\n  // but if the column value is an array that contains a NULL value\n  // then it will be included in the array string as `NULL`, e.g.: `\"{1,NULL,3}\"`\n  return (value: NullableToken) => {\n    if (value === null) {\n      if (!isNullable) {\n        throw new ParserNullValueError(columnName ?? `unknown`)\n      }\n      return null\n    }\n    return parser(value, columnInfo)\n  }\n}\n", "import { Schema } from './types'\n\ntype DbColumnName = string\ntype AppColumnName = string\n\n/**\n * A bidirectional column mapper that handles transforming column **names**\n * between database format (e.g., snake_case) and application format (e.g., camelCase).\n *\n * **Important**: ColumnMapper only transforms column names, not column values or types.\n * For type conversions (e.g., string → Date), use the `parser` option.\n * For value transformations (e.g., encryption), use the `transformer` option.\n *\n * @example\n * ```typescript\n * const mapper = snakeCamelMapper()\n * mapper.decode('user_id') // 'userId'\n * mapper.encode('userId') // 'user_id'\n * ```\n */\nexport interface ColumnMapper {\n  /**\n   * Transform a column name from database format to application format.\n   * Applied to column names in query results.\n   */\n  decode: (dbColumnName: DbColumnName) => AppColumnName\n\n  /**\n   * Transform a column name from application format to database format.\n   * Applied to column names in WHERE clauses and other query parameters.\n   */\n  encode: (appColumnName: AppColumnName) => DbColumnName\n}\n\n/**\n * Converts a snake_case string to camelCase.\n *\n * Handles edge cases:\n * - Preserves leading underscores: `_user_id` → `_userId`\n * - Preserves trailing underscores: `user_id_` → `userId_`\n * - Collapses multiple underscores: `user__id` → `userId`\n * - Normalizes to lowercase first: `user_Column` → `userColumn`\n *\n * @example\n * snakeToCamel('user_id') // 'userId'\n * snakeToCamel('project_id') // 'projectId'\n * snakeToCamel('created_at') // 'createdAt'\n * snakeToCamel('_private') // '_private'\n * snakeToCamel('user__id') // 'userId'\n * snakeToCamel('user_id_') // 'userId_'\n */\nexport function snakeToCamel(str: string): string {\n  // Preserve leading underscores\n  const leadingUnderscores = str.match(/^_+/)?.[0] ?? ``\n  const withoutLeading = str.slice(leadingUnderscores.length)\n\n  // Preserve trailing underscores for round-trip safety\n  const trailingUnderscores = withoutLeading.match(/_+$/)?.[0] ?? ``\n  const core = trailingUnderscores\n    ? withoutLeading.slice(\n        0,\n        withoutLeading.length - trailingUnderscores.length\n      )\n    : withoutLeading\n\n  // Convert to lowercase\n  const normalized = core.toLowerCase()\n\n  // Convert snake_case to camelCase (handling multiple underscores)\n  const camelCased = normalized.replace(/_+([a-z])/g, (_, letter) =>\n    letter.toUpperCase()\n  )\n\n  return leadingUnderscores + camelCased + trailingUnderscores\n}\n\n/**\n * Converts a camelCase string to snake_case.\n *\n * Handles consecutive capitals (acronyms) properly:\n * - `userID` → `user_id`\n * - `userHTTPSURL` → `user_https_url`\n *\n * @example\n * camelToSnake('userId') // 'user_id'\n * camelToSnake('projectId') // 'project_id'\n * camelToSnake('createdAt') // 'created_at'\n * camelToSnake('userID') // 'user_id'\n * camelToSnake('parseHTMLString') // 'parse_html_string'\n */\nexport function camelToSnake(str: string): string {\n  return (\n    str\n      // Insert underscore before uppercase letters that follow lowercase letters\n      // e.g., userId -> user_Id\n      .replace(/([a-z])([A-Z])/g, `$1_$2`)\n      // Insert underscore before uppercase letters that are followed by lowercase letters\n      // This handles acronyms: userID -> user_ID, but parseHTMLString -> parse_HTML_String\n      .replace(/([A-Z]+)([A-Z][a-z])/g, `$1_$2`)\n      .toLowerCase()\n  )\n}\n\n/**\n * Creates a column mapper from an explicit mapping of database columns to application columns.\n *\n * @param mapping - Object mapping database column names (keys) to application column names (values)\n * @returns A ColumnMapper that can encode and decode column names bidirectionally\n *\n * @example\n * const mapper = createColumnMapper({\n *   user_id: 'userId',\n *   project_id: 'projectId',\n *   created_at: 'createdAt'\n * })\n *\n * // Use with ShapeStream\n * const stream = new ShapeStream({\n *   url: 'http://localhost:3000/v1/shape',\n *   params: { table: 'todos' },\n *   columnMapper: mapper\n * })\n */\nexport function createColumnMapper(\n  mapping: Record<string, string>\n): ColumnMapper {\n  // Build reverse mapping: app name -> db name\n  const reverseMapping: Record<string, string> = {}\n  for (const [dbName, appName] of Object.entries(mapping)) {\n    reverseMapping[appName] = dbName\n  }\n\n  return {\n    decode: (dbColumnName: string) => {\n      return mapping[dbColumnName] ?? dbColumnName\n    },\n\n    encode: (appColumnName: string) => {\n      return reverseMapping[appColumnName] ?? appColumnName\n    },\n  }\n}\n\n/**\n * Encodes column names in a WHERE clause using the provided encoder function.\n * Uses regex to identify column references and replace them.\n *\n * Handles common SQL patterns:\n * - Simple comparisons: columnName = $1\n * - Function calls: LOWER(columnName)\n * - Qualified names: table.columnName\n * - Operators: columnName IS NULL, columnName IN (...)\n * - Quoted strings: Preserves string literals unchanged\n *\n * Note: This uses regex-based replacement which works for most common cases\n * but may not handle all complex SQL expressions perfectly. For complex queries,\n * test thoroughly or use database column names directly in WHERE clauses.\n *\n * @param whereClause - The WHERE clause string to encode\n * @param encode - Optional encoder function. If undefined, returns whereClause unchanged.\n * @returns The encoded WHERE clause\n *\n * @internal\n */\nexport function encodeWhereClause(\n  whereClause: string | undefined,\n  encode?: (columnName: string) => string\n): string {\n  if (!whereClause || !encode) return whereClause ?? ``\n\n  // SQL keywords that should not be transformed (common ones)\n  const sqlKeywords = new Set([\n    `SELECT`,\n    `FROM`,\n    `WHERE`,\n    `AND`,\n    `OR`,\n    `NOT`,\n    `IN`,\n    `IS`,\n    `NULL`,\n    `NULLS`,\n    `FIRST`,\n    `LAST`,\n    `TRUE`,\n    `FALSE`,\n    `LIKE`,\n    `ILIKE`,\n    `BETWEEN`,\n    `ASC`,\n    `DESC`,\n    `LIMIT`,\n    `OFFSET`,\n    `ORDER`,\n    `BY`,\n    `GROUP`,\n    `HAVING`,\n    `DISTINCT`,\n    `AS`,\n    `ON`,\n    `JOIN`,\n    `LEFT`,\n    `RIGHT`,\n    `INNER`,\n    `OUTER`,\n    `CROSS`,\n    `CASE`,\n    `WHEN`,\n    `THEN`,\n    `ELSE`,\n    `END`,\n    `CAST`,\n    `LOWER`,\n    `UPPER`,\n    `COALESCE`,\n    `NULLIF`,\n  ])\n\n  // Track positions of quoted strings and double-quoted identifiers to skip them\n  const quotedRanges: Array<{ start: number; end: number }> = []\n\n  // Find all single-quoted strings and double-quoted identifiers\n  let pos = 0\n  while (pos < whereClause.length) {\n    const ch = whereClause[pos]\n    if (ch === `'` || ch === `\"`) {\n      const start = pos\n      const quoteChar = ch\n      pos++ // Skip opening quote\n      // Find closing quote, handling escaped quotes ('' or \"\")\n      while (pos < whereClause.length) {\n        if (whereClause[pos] === quoteChar) {\n          if (whereClause[pos + 1] === quoteChar) {\n            pos += 2 // Skip escaped quote\n          } else {\n            pos++ // Skip closing quote\n            break\n          }\n        } else {\n          pos++\n        }\n      }\n      quotedRanges.push({ start, end: pos })\n    } else {\n      pos++\n    }\n  }\n\n  // Helper to check if position is within a quoted string or double-quoted identifier\n  const isInQuotedString = (pos: number): boolean => {\n    return quotedRanges.some((range) => pos >= range.start && pos < range.end)\n  }\n\n  // Pattern explanation:\n  // (?<![a-zA-Z0-9_]) - negative lookbehind: not preceded by identifier char\n  // ([a-zA-Z_][a-zA-Z0-9_]*) - capture: valid SQL identifier\n  // (?![a-zA-Z0-9_]) - negative lookahead: not followed by identifier char\n  //\n  // This avoids matching:\n  // - Parts of longer identifiers\n  // - SQL keywords (handled by checking if result differs from input)\n  const identifierPattern =\n    /(?<![a-zA-Z0-9_])([a-zA-Z_][a-zA-Z0-9_]*)(?![a-zA-Z0-9_])/g\n\n  return whereClause.replace(identifierPattern, (match, _p1, offset) => {\n    // Don't transform if inside quoted string\n    if (isInQuotedString(offset)) {\n      return match\n    }\n\n    // Don't transform SQL keywords\n    if (sqlKeywords.has(match.toUpperCase())) {\n      return match\n    }\n\n    // Don't transform parameter placeholders ($1, $2, etc.)\n    // This regex won't match them anyway, but being explicit\n    if (match.startsWith(`$`)) {\n      return match\n    }\n\n    // Apply encoding\n    const encoded = encode(match)\n    return encoded\n  })\n}\n\n/**\n * Creates a column mapper that automatically converts between snake_case and camelCase.\n * This is the most common use case for column mapping.\n *\n * When a schema is provided, it will only map columns that exist in the schema.\n * Otherwise, it will map any column name it encounters.\n *\n * **⚠️ Limitations and Edge Cases:**\n * - **WHERE clause encoding**: Uses regex-based parsing which may not handle all complex\n *   SQL expressions. Test thoroughly with your queries, especially those with:\n *   - Complex nested expressions\n *   - Custom operators or functions\n *   - Column names that conflict with SQL keywords\n *   - Quoted identifiers (e.g., `\"$price\"`, `\"user-id\"`) - not supported\n *   - Column names with special characters (non-alphanumeric except underscore)\n * - **Acronym ambiguity**: `userID` → `user_id` → `userId` (ID becomes Id after roundtrip)\n *   Use `createColumnMapper()` with explicit mapping if you need exact control\n * - **Type conversion**: This only renames columns, not values. Use `parser` for type conversion\n *\n * **When to use explicit mapping instead:**\n * - You have column names that don't follow snake_case/camelCase patterns\n * - You need exact control over mappings (e.g., `id` → `identifier`)\n * - Your WHERE clauses are complex and automatic encoding fails\n * - You have quoted identifiers or column names with special characters\n *\n * @param schema - Optional database schema to constrain mapping to known columns\n * @returns A ColumnMapper for snake_case ↔ camelCase conversion\n *\n * @example\n * // Basic usage\n * const mapper = snakeCamelMapper()\n *\n * // With schema - only maps columns in schema (recommended)\n * const mapper = snakeCamelMapper(schema)\n *\n * // Use with ShapeStream\n * const stream = new ShapeStream({\n *   url: 'http://localhost:3000/v1/shape',\n *   params: { table: 'todos' },\n *   columnMapper: snakeCamelMapper()\n * })\n *\n * @example\n * // If automatic encoding fails, fall back to manual column names in WHERE clauses:\n * stream.requestSnapshot({\n *   where: \"user_id = $1\", // Use database column names directly if needed\n *   params: { \"1\": \"123\" }\n * })\n */\nexport function snakeCamelMapper(schema?: Schema): ColumnMapper {\n  // If schema provided, build explicit mapping\n  if (schema) {\n    const mapping: Record<string, string> = {}\n    for (const dbColumn of Object.keys(schema)) {\n      mapping[dbColumn] = snakeToCamel(dbColumn)\n    }\n    return createColumnMapper(mapping)\n  }\n\n  // Otherwise, map dynamically\n  return {\n    decode: (dbColumnName: string) => {\n      return snakeToCamel(dbColumnName)\n    },\n\n    encode: (appColumnName: string) => {\n      return camelToSnake(appColumnName)\n    },\n  }\n}\n", "import {\n  ChangeMessage,\n  ControlMessage,\n  Message,\n  NormalizedPgSnapshot,\n  Offset,\n  PostgresSnapshot,\n  Row,\n} from './types'\n\n/**\n * Type guard for checking {@link Message} is {@link ChangeMessage}.\n *\n * See [TS docs](https://www.typescriptlang.org/docs/handbook/advanced-types.html#user-defined-type-guards)\n * for information on how to use type guards.\n *\n * @param message - the message to check\n * @returns true if the message is a {@link ChangeMessage}\n *\n * @example\n * ```ts\n * if (isChangeMessage(message)) {\n *   const msgChng: ChangeMessage = message // Ok\n *   const msgCtrl: ControlMessage = message // Err, type mismatch\n * }\n * ```\n */\nexport function isChangeMessage<T extends Row<unknown> = Row>(\n  message: Message<T>\n): message is ChangeMessage<T> {\n  return `key` in message\n}\n\n/**\n * Type guard for checking {@link Message} is {@link ControlMessage}.\n *\n * See [TS docs](https://www.typescriptlang.org/docs/handbook/advanced-types.html#user-defined-type-guards)\n * for information on how to use type guards.\n *\n * @param message - the message to check\n * @returns true if the message is a {@link ControlMessage}\n *\n *  * @example\n * ```ts\n * if (isControlMessage(message)) {\n *   const msgChng: ChangeMessage = message // Err, type mismatch\n *   const msgCtrl: ControlMessage = message // Ok\n * }\n * ```\n */\nexport function isControlMessage<T extends Row<unknown> = Row>(\n  message: Message<T>\n): message is ControlMessage {\n  return !isChangeMessage(message)\n}\n\nexport function isUpToDateMessage<T extends Row<unknown> = Row>(\n  message: Message<T>\n): message is ControlMessage & { up_to_date: true } {\n  return isControlMessage(message) && message.headers.control === `up-to-date`\n}\n\n/**\n * Parses the LSN from the up-to-date message and turns it into an offset.\n * The LSN is only present in the up-to-date control message when in SSE mode.\n * If we are not in SSE mode this function will return undefined.\n */\nexport function getOffset(message: ControlMessage): Offset | undefined {\n  const lsn = message.headers.global_last_seen_lsn\n  if (!lsn) {\n    return\n  }\n  return `${lsn}_0` as Offset\n}\n\n/**\n * Checks if a transaction is visible in a snapshot.\n *\n * @param txid - the transaction id to check\n * @param snapshot - the information about the snapshot\n * @returns true if the transaction is visible in the snapshot\n */\nexport function isVisibleInSnapshot(\n  txid: number | bigint | `${bigint}`,\n  snapshot: PostgresSnapshot | NormalizedPgSnapshot\n): boolean {\n  const xid = BigInt(txid)\n  const xmin = BigInt(snapshot.xmin)\n  const xmax = BigInt(snapshot.xmax)\n  const xip = snapshot.xip_list.map(BigInt)\n\n  // If the transaction id is less than the minimum transaction id, it is visible in the snapshot.\n  // If the transaction id is less than the maximum transaction id and not in the list of active\n  //   transactions at the time of the snapshot, it has been committed before the snapshot was taken\n  //   and is therefore visible in the snapshot.\n  // Otherwise, it is not visible in the snapshot.\n\n  return xid < xmin || (xid < xmax && !xip.includes(xid))\n}\n", "export const LIVE_CACHE_BUSTER_HEADER = `electric-cursor`\nexport const SHAPE_HANDLE_HEADER = `electric-handle`\nexport const CHUNK_LAST_OFFSET_HEADER = `electric-offset`\nexport const SHAPE_SCHEMA_HEADER = `electric-schema`\nexport const CHUNK_UP_TO_DATE_HEADER = `electric-up-to-date`\nexport const COLUMNS_QUERY_PARAM = `columns`\nexport const LIVE_CACHE_BUSTER_QUERY_PARAM = `cursor`\nexport const EXPIRED_HANDLE_QUERY_PARAM = `expired_handle`\nexport const SHAPE_HANDLE_QUERY_PARAM = `handle`\nexport const LIVE_QUERY_PARAM = `live`\nexport const OFFSET_QUERY_PARAM = `offset`\nexport const TABLE_QUERY_PARAM = `table`\nexport const WHERE_QUERY_PARAM = `where`\nexport const REPLICA_PARAM = `replica`\nexport const WHERE_PARAMS_PARAM = `params`\n/**\n * @deprecated Use {@link LIVE_SSE_QUERY_PARAM} instead.\n */\nexport const EXPERIMENTAL_LIVE_SSE_QUERY_PARAM = `experimental_live_sse`\nexport const LIVE_SSE_QUERY_PARAM = `live_sse`\nexport const FORCE_DISCONNECT_AND_REFRESH = `force-disconnect-and-refresh`\nexport const PAUSE_STREAM = `pause-stream`\nexport const LOG_MODE_QUERY_PARAM = `log`\nexport const SUBSET_PARAM_WHERE = `subset__where`\nexport const SUBSET_PARAM_LIMIT = `subset__limit`\nexport const SUBSET_PARAM_OFFSET = `subset__offset`\nexport const SUBSET_PARAM_ORDER_BY = `subset__order_by`\nexport const SUBSET_PARAM_WHERE_PARAMS = `subset__params`\n\n// Query parameters that should be passed through when proxying Electric requests\nexport const ELECTRIC_PROTOCOL_QUERY_PARAMS: Array<string> = [\n  LIVE_QUERY_PARAM,\n  LIVE_SSE_QUERY_PARAM,\n  SHAPE_HANDLE_QUERY_PARAM,\n  OFFSET_QUERY_PARAM,\n  LIVE_CACHE_BUSTER_QUERY_PARAM,\n  EXPIRED_HANDLE_QUERY_PARAM,\n  LOG_MODE_QUERY_PARAM,\n  SUBSET_PARAM_WHERE,\n  SUBSET_PARAM_LIMIT,\n  SUBSET_PARAM_OFFSET,\n  SUBSET_PARAM_ORDER_BY,\n  SUBSET_PARAM_WHERE_PARAMS,\n]\n", "import {\n  CHUNK_LAST_OFFSET_HEADER,\n  CHUNK_UP_TO_DATE_HEADER,\n  LIVE_QUERY_PARAM,\n  OFFSET_QUERY_PARAM,\n  SHAPE_HANDLE_HEADER,\n  SHAPE_HANDLE_QUERY_PARAM,\n  SUBSET_PARAM_LIMIT,\n  SUBSET_PARAM_OFFSET,\n  SUBSET_PARAM_ORDER_BY,\n  SUBSET_PARAM_WHERE,\n  SUBSET_PARAM_WHERE_PARAMS,\n} from './constants'\nimport {\n  FetchError,\n  FetchBackoffAbortError,\n  MissingHeadersError,\n} from './error'\n\n// Some specific 4xx and 5xx HTTP status codes that we definitely\n// want to retry\nconst HTTP_RETRY_STATUS_CODES = [429]\n\nexport interface BackoffOptions {\n  /**\n   * Initial delay before retrying in milliseconds\n   */\n  initialDelay: number\n  /**\n   * Maximum retry delay in milliseconds\n   * After reaching this, delay stays constant (e.g., retry every 60s)\n   */\n  maxDelay: number\n  multiplier: number\n  onFailedAttempt?: () => void\n  debug?: boolean\n  /**\n   * Maximum number of retry attempts before giving up.\n   * Set to Infinity (default) for indefinite retries - needed for offline scenarios\n   * where clients may go offline and come back later.\n   */\n  maxRetries?: number\n}\n\nexport const BackoffDefaults = {\n  initialDelay: 100,\n  maxDelay: 60_000, // Cap at 60s - reasonable for long-lived connections\n  multiplier: 1.3,\n  maxRetries: Infinity, // Retry forever - clients may go offline and come back\n}\n\n/**\n * Parse Retry-After header value and return delay in milliseconds\n * Supports both delta-seconds format and HTTP-date format\n * Returns 0 if header is not present or invalid\n */\nexport function parseRetryAfterHeader(retryAfter: string | undefined): number {\n  if (!retryAfter) return 0\n\n  // Try parsing as seconds (delta-seconds format)\n  const retryAfterSec = Number(retryAfter)\n  if (Number.isFinite(retryAfterSec) && retryAfterSec > 0) {\n    return retryAfterSec * 1000\n  }\n\n  // Try parsing as HTTP-date\n  const retryDate = Date.parse(retryAfter)\n  if (!isNaN(retryDate)) {\n    // Handle clock skew: clamp to non-negative, cap at reasonable max\n    const deltaMs = retryDate - Date.now()\n    return Math.max(0, Math.min(deltaMs, 3600_000)) // Cap at 1 hour\n  }\n\n  return 0\n}\n\nexport function createFetchWithBackoff(\n  fetchClient: typeof fetch,\n  backoffOptions: BackoffOptions = BackoffDefaults\n): typeof fetch {\n  const {\n    initialDelay,\n    maxDelay,\n    multiplier,\n    debug = false,\n    onFailedAttempt,\n    maxRetries = Infinity,\n  } = backoffOptions\n  return async (...args: Parameters<typeof fetch>): Promise<Response> => {\n    const url = args[0]\n    const options = args[1]\n\n    let delay = initialDelay\n    let attempt = 0\n\n    while (true) {\n      try {\n        const result = await fetchClient(...args)\n        if (result.ok) {\n          return result\n        }\n\n        const err = await FetchError.fromResponse(result, url.toString())\n\n        throw err\n      } catch (e) {\n        onFailedAttempt?.()\n        if (options?.signal?.aborted) {\n          throw new FetchBackoffAbortError()\n        } else if (\n          e instanceof FetchError &&\n          !HTTP_RETRY_STATUS_CODES.includes(e.status) &&\n          e.status >= 400 &&\n          e.status < 500\n        ) {\n          // Any client errors cannot be backed off on, leave it to the caller to handle.\n          throw e\n        } else {\n          // Check max retries\n          attempt++\n          if (attempt > maxRetries) {\n            if (debug) {\n              console.log(\n                `Max retries reached (${attempt}/${maxRetries}), giving up`\n              )\n            }\n            throw e\n          }\n\n          // Calculate wait time honoring server-driven backoff as a floor\n          // Precedence: max(serverMinimum, min(clientMaxDelay, backoffWithJitter))\n\n          // 1. Parse server-provided Retry-After (if present)\n          const serverMinimumMs =\n            e instanceof FetchError && e.headers\n              ? parseRetryAfterHeader(e.headers[`retry-after`])\n              : 0\n\n          // 2. Calculate client backoff with full jitter strategy\n          // Full jitter: random_between(0, min(cap, exponential_backoff))\n          // See: https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/\n          const jitter = Math.random() * delay // random value between 0 and current delay\n          const clientBackoffMs = Math.min(jitter, maxDelay) // cap at maxDelay\n\n          // 3. Server minimum is the floor, client cap is the ceiling\n          const waitMs = Math.max(serverMinimumMs, clientBackoffMs)\n\n          if (debug) {\n            const source = serverMinimumMs > 0 ? `server+client` : `client`\n            console.log(\n              `Retry attempt #${attempt} after ${waitMs}ms (${source}, serverMin=${serverMinimumMs}ms, clientBackoff=${clientBackoffMs}ms)`\n            )\n          }\n\n          // Wait for the calculated duration\n          await new Promise((resolve) => setTimeout(resolve, waitMs))\n\n          // Increase the delay for the next attempt (capped at maxDelay)\n          delay = Math.min(delay * multiplier, maxDelay)\n        }\n      }\n    }\n  }\n}\n\nconst NO_BODY_STATUS_CODES = [201, 204, 205]\n\n// Ensure body can actually be read in its entirety\nexport function createFetchWithConsumedMessages(fetchClient: typeof fetch) {\n  return async (...args: Parameters<typeof fetch>): Promise<Response> => {\n    const url = args[0]\n    const res = await fetchClient(...args)\n    try {\n      if (res.status < 200 || NO_BODY_STATUS_CODES.includes(res.status)) {\n        return res\n      }\n\n      const text = await res.text()\n      return new Response(text, res)\n    } catch (err) {\n      if (args[1]?.signal?.aborted) {\n        throw new FetchBackoffAbortError()\n      }\n\n      throw new FetchError(\n        res.status,\n        undefined,\n        undefined,\n        Object.fromEntries([...res.headers.entries()]),\n        url.toString(),\n        err instanceof Error\n          ? err.message\n          : typeof err === `string`\n            ? err\n            : `failed to read body`\n      )\n    }\n  }\n}\n\ninterface ChunkPrefetchOptions {\n  maxChunksToPrefetch: number\n}\n\nconst ChunkPrefetchDefaults = {\n  maxChunksToPrefetch: 2,\n}\n\n/**\n * Creates a fetch client that prefetches subsequent log chunks for\n * consumption by the shape stream without waiting for the chunk bodies\n * themselves to be loaded.\n *\n * @param fetchClient the client to wrap\n * @param prefetchOptions options to configure prefetching\n * @returns wrapped client with prefetch capabilities\n */\nexport function createFetchWithChunkBuffer(\n  fetchClient: typeof fetch,\n  prefetchOptions: ChunkPrefetchOptions = ChunkPrefetchDefaults\n): typeof fetch {\n  const { maxChunksToPrefetch } = prefetchOptions\n\n  let prefetchQueue: PrefetchQueue\n\n  const prefetchClient = async (...args: Parameters<typeof fetchClient>) => {\n    const url = args[0].toString()\n\n    // try to consume from the prefetch queue first, and if request is\n    // not present abort the prefetch queue as it must no longer be valid\n    const prefetchedRequest = prefetchQueue?.consume(...args)\n    if (prefetchedRequest) {\n      return prefetchedRequest\n    }\n\n    prefetchQueue?.abort()\n\n    // perform request and fire off prefetch queue if request is eligible\n    const response = await fetchClient(...args)\n    const nextUrl = getNextChunkUrl(url, response)\n    if (nextUrl) {\n      prefetchQueue = new PrefetchQueue({\n        fetchClient,\n        maxPrefetchedRequests: maxChunksToPrefetch,\n        url: nextUrl,\n        requestInit: args[1],\n      })\n    }\n\n    return response\n  }\n\n  return prefetchClient\n}\n\nexport const requiredElectricResponseHeaders = [\n  `electric-offset`,\n  `electric-handle`,\n]\n\nexport const requiredLiveResponseHeaders = [`electric-cursor`]\n\nexport const requiredNonLiveResponseHeaders = [`electric-schema`]\n\nexport function createFetchWithResponseHeadersCheck(\n  fetchClient: typeof fetch\n): typeof fetch {\n  return async (...args: Parameters<typeof fetchClient>) => {\n    const response = await fetchClient(...args)\n\n    if (response.ok) {\n      // Check that the necessary Electric headers are present on the response\n      const headers = response.headers\n      const missingHeaders: Array<string> = []\n\n      const addMissingHeaders = (requiredHeaders: Array<string>) =>\n        missingHeaders.push(...requiredHeaders.filter((h) => !headers.has(h)))\n\n      const input = args[0]\n      const urlString = input.toString()\n      const url = new URL(urlString)\n\n      // Snapshot responses (subset params) return a JSON object and do not include Electric chunk headers\n      const isSnapshotRequest = [\n        SUBSET_PARAM_WHERE,\n        SUBSET_PARAM_WHERE_PARAMS,\n        SUBSET_PARAM_LIMIT,\n        SUBSET_PARAM_OFFSET,\n        SUBSET_PARAM_ORDER_BY,\n      ].some((p) => url.searchParams.has(p))\n      if (isSnapshotRequest) {\n        return response\n      }\n\n      addMissingHeaders(requiredElectricResponseHeaders)\n      if (url.searchParams.get(LIVE_QUERY_PARAM) === `true`) {\n        addMissingHeaders(requiredLiveResponseHeaders)\n      }\n\n      if (\n        !url.searchParams.has(LIVE_QUERY_PARAM) ||\n        url.searchParams.get(LIVE_QUERY_PARAM) === `false`\n      ) {\n        addMissingHeaders(requiredNonLiveResponseHeaders)\n      }\n\n      if (missingHeaders.length > 0) {\n        throw new MissingHeadersError(urlString, missingHeaders)\n      }\n    }\n\n    return response\n  }\n}\n\nclass PrefetchQueue {\n  readonly #fetchClient: typeof fetch\n  readonly #maxPrefetchedRequests: number\n  readonly #prefetchQueue = new Map<\n    string,\n    [Promise<Response>, AbortController]\n  >()\n  #queueHeadUrl: string | void\n  #queueTailUrl: string | void\n\n  constructor(options: {\n    url: Parameters<typeof fetch>[0]\n    requestInit: Parameters<typeof fetch>[1]\n    maxPrefetchedRequests: number\n    fetchClient?: typeof fetch\n  }) {\n    this.#fetchClient =\n      options.fetchClient ??\n      ((...args: Parameters<typeof fetch>) => fetch(...args))\n    this.#maxPrefetchedRequests = options.maxPrefetchedRequests\n    this.#queueHeadUrl = options.url.toString()\n    this.#queueTailUrl = this.#queueHeadUrl\n    this.#prefetch(options.url, options.requestInit)\n  }\n\n  abort(): void {\n    this.#prefetchQueue.forEach(([_, aborter]) => aborter.abort())\n  }\n\n  consume(...args: Parameters<typeof fetch>): Promise<Response> | void {\n    const url = args[0].toString()\n\n    const request = this.#prefetchQueue.get(url)?.[0]\n    // only consume if request is in queue and is the queue \"head\"\n    // if request is in the queue but not the head, the queue is being\n    // consumed out of order and should be restarted\n    if (!request || url !== this.#queueHeadUrl) return\n    this.#prefetchQueue.delete(url)\n\n    // fire off new prefetch since request has been consumed\n    request\n      .then((response) => {\n        const nextUrl = getNextChunkUrl(url, response)\n        this.#queueHeadUrl = nextUrl\n        if (\n          this.#queueTailUrl &&\n          !this.#prefetchQueue.has(this.#queueTailUrl)\n        ) {\n          this.#prefetch(this.#queueTailUrl, args[1])\n        }\n      })\n      .catch(() => {})\n\n    return request\n  }\n\n  #prefetch(...args: Parameters<typeof fetch>): void {\n    const url = args[0].toString()\n\n    // only prefetch when queue is not full\n    if (this.#prefetchQueue.size >= this.#maxPrefetchedRequests) return\n\n    // initialize aborter per request, to avoid aborting consumed requests that\n    // are still streaming their bodies to the consumer\n    const aborter = new AbortController()\n\n    try {\n      const { signal, cleanup } = chainAborter(aborter, args[1]?.signal)\n      const request = this.#fetchClient(url, { ...(args[1] ?? {}), signal })\n      this.#prefetchQueue.set(url, [request, aborter])\n      request\n        .then((response) => {\n          // only keep prefetching if response chain is uninterrupted\n          if (!response.ok || aborter.signal.aborted) return\n\n          const nextUrl = getNextChunkUrl(url, response)\n\n          // only prefetch when there is a next URL\n          if (!nextUrl || nextUrl === url) {\n            this.#queueTailUrl = undefined\n            return\n          }\n\n          this.#queueTailUrl = nextUrl\n          return this.#prefetch(nextUrl, args[1])\n        })\n        .catch(() => {})\n        .finally(cleanup)\n    } catch (_) {\n      // ignore prefetch errors\n    }\n  }\n}\n\n/**\n * Generate the next chunk's URL if the url and response are valid\n */\nfunction getNextChunkUrl(url: string, res: Response): string | void {\n  const shapeHandle = res.headers.get(SHAPE_HANDLE_HEADER)\n  const lastOffset = res.headers.get(CHUNK_LAST_OFFSET_HEADER)\n  const isUpToDate = res.headers.has(CHUNK_UP_TO_DATE_HEADER)\n\n  // only prefetch if shape handle and offset for next chunk are available, and\n  // response is not already up-to-date\n  if (!shapeHandle || !lastOffset || isUpToDate) return\n\n  const nextUrl = new URL(url)\n\n  // don't prefetch live requests, rushing them will only\n  // potentially miss more recent data\n  if (nextUrl.searchParams.has(LIVE_QUERY_PARAM)) return\n\n  nextUrl.searchParams.set(SHAPE_HANDLE_QUERY_PARAM, shapeHandle)\n  nextUrl.searchParams.set(OFFSET_QUERY_PARAM, lastOffset)\n  nextUrl.searchParams.sort()\n  return nextUrl.toString()\n}\n\n/**\n * Chains an abort controller on an optional source signal's\n * aborted state - if the source signal is aborted, the provided abort\n * controller will also abort\n */\nfunction chainAborter(\n  aborter: AbortController,\n  sourceSignal?: AbortSignal | null\n): {\n  signal: AbortSignal\n  cleanup: () => void\n} {\n  let cleanup = noop\n  if (!sourceSignal) {\n    // no-op, nothing to chain to\n  } else if (sourceSignal.aborted) {\n    // source signal is already aborted, abort immediately\n    aborter.abort()\n  } else {\n    // chain to source signal abort event, and add callback to unlink\n    // the aborter to avoid memory leaks\n    const abortParent = () => aborter.abort()\n    sourceSignal.addEventListener(`abort`, abortParent, {\n      once: true,\n      signal: aborter.signal,\n    })\n    cleanup = () => sourceSignal.removeEventListener(`abort`, abortParent)\n  }\n\n  return {\n    signal: aborter.signal,\n    cleanup,\n  }\n}\n\nfunction noop() {}\n", "import {\n  Message,\n  Offset,\n  Schema,\n  Row,\n  MaybePromise,\n  GetExtensions,\n  ChangeMessage,\n  SnapshotMetadata,\n} from './types'\nimport { MessageParser, Parser, TransformFunction } from './parser'\nimport { ColumnMapper, encodeWhereClause } from './column-mapper'\nimport { getOffset, isUpToDateMessage, isChangeMessage } from './helpers'\nimport {\n  FetchError,\n  FetchBackoffAbortError,\n  MissingShapeUrlError,\n  InvalidSignalError,\n  MissingShapeHandleError,\n  ReservedParamError,\n  MissingHeadersError,\n} from './error'\nimport {\n  BackoffDefaults,\n  BackoffOptions,\n  createFetchWithBackoff,\n  createFetchWithChunkBuffer,\n  createFetchWithConsumedMessages,\n  createFetchWithResponseHeadersCheck,\n} from './fetch'\nimport {\n  CHUNK_LAST_OFFSET_HEADER,\n  LIVE_CACHE_BUSTER_HEADER,\n  LIVE_CACHE_BUSTER_QUERY_PARAM,\n  EXPIRED_HANDLE_QUERY_PARAM,\n  COLUMNS_QUERY_PARAM,\n  LIVE_QUERY_PARAM,\n  OFFSET_QUERY_PARAM,\n  SHAPE_HANDLE_HEADER,\n  SHAPE_HANDLE_QUERY_PARAM,\n  SHAPE_SCHEMA_HEADER,\n  WHERE_QUERY_PARAM,\n  WHERE_PARAMS_PARAM,\n  TABLE_QUERY_PARAM,\n  REPLICA_PARAM,\n  FORCE_DISCONNECT_AND_REFRESH,\n  PAUSE_STREAM,\n  EXPERIMENTAL_LIVE_SSE_QUERY_PARAM,\n  LIVE_SSE_QUERY_PARAM,\n  ELECTRIC_PROTOCOL_QUERY_PARAMS,\n  LOG_MODE_QUERY_PARAM,\n  SUBSET_PARAM_WHERE,\n  SUBSET_PARAM_WHERE_PARAMS,\n  SUBSET_PARAM_LIMIT,\n  SUBSET_PARAM_OFFSET,\n  SUBSET_PARAM_ORDER_BY,\n} from './constants'\nimport {\n  EventSourceMessage,\n  fetchEventSource,\n} from '@microsoft/fetch-event-source'\nimport { expiredShapesCache } from './expired-shapes-cache'\nimport { upToDateTracker } from './up-to-date-tracker'\nimport { SnapshotTracker } from './snapshot-tracker'\n\nconst RESERVED_PARAMS: Set<ReservedParamKeys> = new Set([\n  LIVE_CACHE_BUSTER_QUERY_PARAM,\n  SHAPE_HANDLE_QUERY_PARAM,\n  LIVE_QUERY_PARAM,\n  OFFSET_QUERY_PARAM,\n])\n\ntype Replica = `full` | `default`\nexport type LogMode = `changes_only` | `full`\n\n/**\n * PostgreSQL-specific shape parameters that can be provided externally\n */\nexport interface PostgresParams<T extends Row<unknown> = Row> {\n  /** The root table for the shape. Not required if you set the table in your proxy. */\n  table?: string\n\n  /**\n   * The columns to include in the shape.\n   * Must include primary keys, and can only include valid columns.\n   * Defaults to all columns of the type `T`. If provided, must include primary keys, and can only include valid columns.\n\n   */\n  columns?: (keyof T)[]\n\n  /** The where clauses for the shape */\n  where?: string\n\n  /**\n   * Positional where clause paramater values. These will be passed to the server\n   * and will substitute `$i` parameters in the where clause.\n   *\n   * It can be an array (note that positional arguments start at 1, the array will be mapped\n   * accordingly), or an object with keys matching the used positional parameters in the where clause.\n   *\n   * If where clause is `id = $1 or id = $2`, params must have keys `\"1\"` and `\"2\"`, or be an array with length 2.\n   */\n  params?: Record<`${number}`, string> | string[]\n\n  /**\n   * If `replica` is `default` (the default) then Electric will only send the\n   * changed columns in an update.\n   *\n   * If it's `full` Electric will send the entire row with both changed and\n   * unchanged values. `old_value` will also be present on update messages,\n   * containing the previous value for changed columns.\n   *\n   * Setting `replica` to `full` will result in higher bandwidth\n   * usage and so is not generally recommended.\n   */\n  replica?: Replica\n}\ntype SerializableParamValue = string | string[] | Record<string, string>\ntype ParamValue =\n  | SerializableParamValue\n  | (() => SerializableParamValue | Promise<SerializableParamValue>)\n\n/**\n * External params type - what users provide.\n * Excludes reserved parameters to prevent dynamic variations that could cause stream shape changes.\n */\nexport type ExternalParamsRecord<T extends Row<unknown> = Row> = {\n  [K in string]: ParamValue | undefined\n} & Partial<PostgresParams<T>> & { [K in ReservedParamKeys]?: never }\n\nexport type SubsetParams = {\n  where?: string\n  params?: Record<string, string>\n  limit?: number\n  offset?: number\n  orderBy?: string\n}\n\ntype ReservedParamKeys =\n  | typeof LIVE_CACHE_BUSTER_QUERY_PARAM\n  | typeof SHAPE_HANDLE_QUERY_PARAM\n  | typeof LIVE_QUERY_PARAM\n  | typeof OFFSET_QUERY_PARAM\n  | `subset__${string}`\n\n/**\n * External headers type - what users provide.\n * Allows string or function values for any header.\n */\nexport type ExternalHeadersRecord = {\n  [key: string]: string | (() => string | Promise<string>)\n}\n\n/**\n * Internal params type - used within the library.\n * All values are converted to strings.\n */\ntype InternalParamsRecord = {\n  [K in string as K extends ReservedParamKeys ? never : K]:\n    | string\n    | Record<string, string>\n}\n\n/**\n * Helper function to resolve a function or value to its final value\n */\nexport async function resolveValue<T>(\n  value: T | (() => T | Promise<T>)\n): Promise<T> {\n  if (typeof value === `function`) {\n    return (value as () => T | Promise<T>)()\n  }\n  return value\n}\n\n/**\n * Helper function to convert external params to internal format\n */\nasync function toInternalParams(\n  params: ExternalParamsRecord<Row>\n): Promise<InternalParamsRecord> {\n  const entries = Object.entries(params)\n  const resolvedEntries = await Promise.all(\n    entries.map(async ([key, value]) => {\n      if (value === undefined) return [key, undefined]\n      const resolvedValue = await resolveValue(value)\n      return [\n        key,\n        Array.isArray(resolvedValue) ? resolvedValue.join(`,`) : resolvedValue,\n      ]\n    })\n  )\n\n  return Object.fromEntries(\n    resolvedEntries.filter(([_, value]) => value !== undefined)\n  )\n}\n\n/**\n * Helper function to resolve headers\n */\nasync function resolveHeaders(\n  headers?: ExternalHeadersRecord\n): Promise<Record<string, string>> {\n  if (!headers) return {}\n\n  const entries = Object.entries(headers)\n  const resolvedEntries = await Promise.all(\n    entries.map(async ([key, value]) => [key, await resolveValue(value)])\n  )\n\n  return Object.fromEntries(resolvedEntries)\n}\n\ntype RetryOpts = {\n  params?: ExternalParamsRecord\n  headers?: ExternalHeadersRecord\n}\n\ntype ShapeStreamErrorHandler = (\n  error: Error\n) => void | RetryOpts | Promise<void | RetryOpts>\n\n/**\n * Options for constructing a ShapeStream.\n */\nexport interface ShapeStreamOptions<T = never> {\n  /**\n   * The full URL to where the Shape is served. This can either be the Electric server\n   * directly or a proxy. E.g. for a local Electric instance, you might set `http://localhost:3000/v1/shape`\n   */\n  url: string\n\n  /**\n   * The \"offset\" on the shape log. This is typically not set as the ShapeStream\n   * will handle this automatically. A common scenario where you might pass an offset\n   * is if you're maintaining a local cache of the log. If you've gone offline\n   * and are re-starting a ShapeStream to catch-up to the latest state of the Shape,\n   * you'd pass in the last offset and shapeHandle you'd seen from the Electric server\n   * so it knows at what point in the shape to catch you up from.\n   */\n  offset?: Offset\n\n  /**\n   * Similar to `offset`, this isn't typically used unless you're maintaining\n   * a cache of the shape log.\n   */\n  handle?: string\n\n  /**\n   * HTTP headers to attach to requests made by the client.\n   * Values can be strings or functions (sync or async) that return strings.\n   * Function values are resolved in parallel when needed, making this useful\n   * for authentication tokens or other dynamic headers.\n   */\n  headers?: ExternalHeadersRecord\n\n  /**\n   * Additional request parameters to attach to the URL.\n   * Values can be strings, string arrays, or functions (sync or async) that return these types.\n   * Function values are resolved in parallel when needed, making this useful\n   * for user-specific parameters or dynamic filters.\n   *\n   * These will be merged with Electric's standard parameters.\n   * Note: You cannot use Electric's reserved parameter names\n   * (offset, handle, live, cursor).\n   *\n   * PostgreSQL-specific options like table, where, columns, and replica\n   * should be specified here.\n   */\n  params?: ExternalParamsRecord\n\n  /**\n   * Automatically fetch updates to the Shape. If you just want to sync the current\n   * shape and stop, pass false.\n   */\n  subscribe?: boolean\n\n  /**\n   * @deprecated No longer experimental, use {@link liveSse} instead.\n   */\n  experimentalLiveSse?: boolean\n\n  /**\n   * Use Server-Sent Events (SSE) for live updates.\n   */\n  liveSse?: boolean\n\n  /**\n   * Initial data loading mode\n   */\n  log?: LogMode\n\n  signal?: AbortSignal\n  fetchClient?: typeof fetch\n  backoffOptions?: BackoffOptions\n  parser?: Parser<T>\n\n  /**\n   * Function to transform rows after parsing (e.g., for encryption, type coercion).\n   * Applied to data received from Electric.\n   *\n   * **Note**: If you're using `transformer` solely for column name transformation\n   * (e.g., snake_case → camelCase), consider using `columnMapper` instead, which\n   * provides bidirectional transformation and automatically encodes WHERE clauses.\n   *\n   * **Execution order** when both are provided:\n   * 1. `columnMapper.decode` runs first (renames columns)\n   * 2. `transformer` runs second (transforms values)\n   *\n   * @example\n   * ```typescript\n   * // For column renaming only - use columnMapper\n   * import { snakeCamelMapper } from '@electric-sql/client'\n   * const stream = new ShapeStream({ columnMapper: snakeCamelMapper() })\n   * ```\n   *\n   * @example\n   * ```typescript\n   * // For value transformation (encryption, etc.) - use transformer\n   * const stream = new ShapeStream({\n   *   transformer: (row) => ({\n   *     ...row,\n   *     encrypted_field: decrypt(row.encrypted_field)\n   *   })\n   * })\n   * ```\n   *\n   * @example\n   * ```typescript\n   * // Use both together\n   * const stream = new ShapeStream({\n   *   columnMapper: snakeCamelMapper(), // Runs first: renames columns\n   *   transformer: (row) => ({         // Runs second: transforms values\n   *     ...row,\n   *     encryptedData: decrypt(row.encryptedData)\n   *   })\n   * })\n   * ```\n   */\n  transformer?: TransformFunction<T>\n\n  /**\n   * Bidirectional column name mapper for transforming between database column names\n   * (e.g., snake_case) and application column names (e.g., camelCase).\n   *\n   * The mapper handles both:\n   * - **Decoding**: Database → Application (applied to query results)\n   * - **Encoding**: Application → Database (applied to WHERE clauses)\n   *\n   * @example\n   * ```typescript\n   * // Most common case: snake_case ↔ camelCase\n   * import { snakeCamelMapper } from '@electric-sql/client'\n   *\n   * const stream = new ShapeStream({\n   *   url: 'http://localhost:3000/v1/shape',\n   *   params: { table: 'todos' },\n   *   columnMapper: snakeCamelMapper()\n   * })\n   * ```\n   *\n   * @example\n   * ```typescript\n   * // Custom mapping\n   * import { createColumnMapper } from '@electric-sql/client'\n   *\n   * const stream = new ShapeStream({\n   *   columnMapper: createColumnMapper({\n   *     user_id: 'userId',\n   *     project_id: 'projectId',\n   *     created_at: 'createdAt'\n   *   })\n   * })\n   * ```\n   */\n  columnMapper?: ColumnMapper\n\n  /**\n   * A function for handling shapestream errors.\n   *\n   * **Automatic retries**: The client automatically retries 5xx server errors, network\n   * errors, and 429 rate limits with exponential backoff. The `onError` callback is\n   * only invoked after these automatic retries are exhausted, or for non-retryable\n   * errors like 4xx client errors.\n   *\n   * When not provided, non-retryable errors will be thrown and syncing will stop.\n   *\n   * **Return value behavior**:\n   * - Return an **object** (RetryOpts or empty `{}`) to retry syncing:\n   *   - `{}` - Retry with the same params and headers\n   *   - `{ params }` - Retry with modified params\n   *   - `{ headers }` - Retry with modified headers (e.g., refreshed auth token)\n   *   - `{ params, headers }` - Retry with both modified\n   * - Return **void** or **undefined** to stop the stream permanently\n   *\n   * **Important**: If you want syncing to continue after an error (e.g., to retry\n   * on network failures), you MUST return at least an empty object `{}`. Simply\n   * logging the error and returning nothing will stop syncing.\n   *\n   * Supports async functions that return `Promise<void | RetryOpts>`.\n   *\n   * @example\n   * ```typescript\n   * // Retry on network errors, stop on others\n   * onError: (error) => {\n   *   console.error('Stream error:', error)\n   *   if (error instanceof FetchError && error.status >= 500) {\n   *     return {} // Retry with same params\n   *   }\n   *   // Return void to stop on other errors\n   * }\n   * ```\n   *\n   * @example\n   * ```typescript\n   * // Refresh auth token on 401\n   * onError: async (error) => {\n   *   if (error instanceof FetchError && error.status === 401) {\n   *     const newToken = await refreshAuthToken()\n   *     return { headers: { Authorization: `Bearer ${newToken}` } }\n   *   }\n   *   return {} // Retry other errors\n   * }\n   * ```\n   */\n  onError?: ShapeStreamErrorHandler\n}\n\nexport interface ShapeStreamInterface<T extends Row<unknown> = Row> {\n  subscribe(\n    callback: (\n      messages: Message<T>[]\n    ) => MaybePromise<void> | { columns?: (keyof T)[] },\n    onError?: (error: FetchError | Error) => void\n  ): () => void\n  unsubscribeAll(): void\n\n  isLoading(): boolean\n  lastSyncedAt(): number | undefined\n  lastSynced(): number\n  isConnected(): boolean\n  hasStarted(): boolean\n\n  isUpToDate: boolean\n  lastOffset: Offset\n  shapeHandle?: string\n  error?: unknown\n  mode: LogMode\n\n  forceDisconnectAndRefresh(): Promise<void>\n\n  requestSnapshot(params: SubsetParams): Promise<{\n    metadata: SnapshotMetadata\n    data: Array<Message<T>>\n  }>\n\n  fetchSnapshot(opts: SubsetParams): Promise<{\n    metadata: SnapshotMetadata\n    data: Array<ChangeMessage<T>>\n  }>\n}\n\n/**\n * Creates a canonical shape key from a URL excluding only Electric protocol parameters\n */\nfunction canonicalShapeKey(url: URL): string {\n  const cleanUrl = new URL(url.origin + url.pathname)\n\n  // Copy all params except Electric protocol ones that vary between requests\n  for (const [key, value] of url.searchParams) {\n    if (!ELECTRIC_PROTOCOL_QUERY_PARAMS.includes(key)) {\n      cleanUrl.searchParams.set(key, value)\n    }\n  }\n\n  cleanUrl.searchParams.sort()\n  return cleanUrl.toString()\n}\n\n/**\n * Reads updates to a shape from Electric using HTTP requests and long polling or\n * Server-Sent Events (SSE).\n * Notifies subscribers when new messages come in. Doesn't maintain any history of the\n * log but does keep track of the offset position and is the best way\n * to consume the HTTP `GET /v1/shape` api.\n *\n * @constructor\n * @param {ShapeStreamOptions} options - configure the shape stream\n * @example\n * Register a callback function to subscribe to the messages.\n * ```\n * const stream = new ShapeStream(options)\n * stream.subscribe(messages => {\n *   // messages is 1 or more row updates\n * })\n * ```\n *\n * To use Server-Sent Events (SSE) for real-time updates:\n * ```\n * const stream = new ShapeStream({\n *   url: `http://localhost:3000/v1/shape`,\n *   liveSse: true\n * })\n * ```\n *\n * To abort the stream, abort the `signal`\n * passed in via the `ShapeStreamOptions`.\n * ```\n * const aborter = new AbortController()\n * const issueStream = new ShapeStream({\n *   url: `${BASE_URL}/${table}`\n *   subscribe: true,\n *   signal: aborter.signal,\n * })\n * // Later...\n * aborter.abort()\n * ```\n */\n\nexport class ShapeStream<T extends Row<unknown> = Row>\n  implements ShapeStreamInterface<T>\n{\n  static readonly Replica = {\n    FULL: `full` as Replica,\n    DEFAULT: `default` as Replica,\n  }\n\n  readonly options: ShapeStreamOptions<GetExtensions<T>>\n  #error: unknown = null\n\n  readonly #fetchClient: typeof fetch\n  readonly #sseFetchClient: typeof fetch\n  readonly #messageParser: MessageParser<T>\n\n  readonly #subscribers = new Map<\n    number,\n    [\n      (messages: Message<T>[]) => MaybePromise<void>,\n      ((error: Error) => void) | undefined,\n    ]\n  >()\n\n  #started = false\n  #state = `active` as `active` | `pause-requested` | `paused`\n  #lastOffset: Offset\n  #liveCacheBuster: string // Seconds since our Electric Epoch 😎\n  #lastSyncedAt?: number // unix time\n  #isUpToDate: boolean = false\n  #isMidStream: boolean = true\n  #connected: boolean = false\n  #shapeHandle?: string\n  #mode: LogMode\n  #schema?: Schema\n  #onError?: ShapeStreamErrorHandler\n  #requestAbortController?: AbortController\n  #isRefreshing = false\n  #tickPromise?: Promise<void>\n  #tickPromiseResolver?: () => void\n  #tickPromiseRejecter?: (reason?: unknown) => void\n  #messageChain = Promise.resolve<void[]>([]) // promise chain for incoming messages\n  #snapshotTracker = new SnapshotTracker()\n  #activeSnapshotRequests = 0 // counter for concurrent snapshot requests\n  #midStreamPromise?: Promise<void>\n  #midStreamPromiseResolver?: () => void\n  #lastSeenCursor?: string // Last seen cursor from previous session (used to detect cached responses)\n  #currentFetchUrl?: URL // Current fetch URL for computing shape key\n  #lastSseConnectionStartTime?: number\n  #minSseConnectionDuration = 1000 // Minimum expected SSE connection duration (1 second)\n  #consecutiveShortSseConnections = 0\n  #maxShortSseConnections = 3 // Fall back to long polling after this many short connections\n  #sseFallbackToLongPolling = false\n  #sseBackoffBaseDelay = 100 // Base delay for exponential backoff (ms)\n  #sseBackoffMaxDelay = 5000 // Maximum delay cap (ms)\n  #unsubscribeFromVisibilityChanges?: () => void\n\n  // Derived state: we're in replay mode if we have a last seen cursor\n  get #replayMode(): boolean {\n    return this.#lastSeenCursor !== undefined\n  }\n\n  constructor(options: ShapeStreamOptions<GetExtensions<T>>) {\n    this.options = { subscribe: true, ...options }\n    validateOptions(this.options)\n    this.#lastOffset = this.options.offset ?? `-1`\n    this.#liveCacheBuster = ``\n    this.#shapeHandle = this.options.handle\n\n    // Build transformer chain: columnMapper.decode -> transformer\n    // columnMapper transforms column names, transformer transforms values\n    let transformer: TransformFunction<GetExtensions<T>> | undefined\n\n    if (options.columnMapper) {\n      const applyColumnMapper = (\n        row: Row<GetExtensions<T>>\n      ): Row<GetExtensions<T>> => {\n        const result: Record<string, unknown> = {}\n        for (const [dbKey, value] of Object.entries(row)) {\n          const appKey = options.columnMapper!.decode(dbKey)\n          result[appKey] = value\n        }\n        return result as Row<GetExtensions<T>>\n      }\n\n      transformer = options.transformer\n        ? (row: Row<GetExtensions<T>>) =>\n            options.transformer!(applyColumnMapper(row))\n        : applyColumnMapper\n    } else {\n      transformer = options.transformer\n    }\n\n    this.#messageParser = new MessageParser<T>(options.parser, transformer)\n\n    this.#onError = this.options.onError\n    this.#mode = this.options.log ?? `full`\n\n    const baseFetchClient =\n      options.fetchClient ??\n      ((...args: Parameters<typeof fetch>) => fetch(...args))\n\n    const backOffOpts = {\n      ...(options.backoffOptions ?? BackoffDefaults),\n      onFailedAttempt: () => {\n        this.#connected = false\n        options.backoffOptions?.onFailedAttempt?.()\n      },\n    }\n    const fetchWithBackoffClient = createFetchWithBackoff(\n      baseFetchClient,\n      backOffOpts\n    )\n\n    this.#sseFetchClient = createFetchWithResponseHeadersCheck(\n      createFetchWithChunkBuffer(fetchWithBackoffClient)\n    )\n\n    this.#fetchClient = createFetchWithConsumedMessages(this.#sseFetchClient)\n\n    this.#subscribeToVisibilityChanges()\n  }\n\n  get shapeHandle() {\n    return this.#shapeHandle\n  }\n\n  get error() {\n    return this.#error\n  }\n\n  get isUpToDate() {\n    return this.#isUpToDate\n  }\n\n  get lastOffset() {\n    return this.#lastOffset\n  }\n\n  get mode() {\n    return this.#mode\n  }\n\n  async #start(): Promise<void> {\n    this.#started = true\n\n    try {\n      await this.#requestShape()\n    } catch (err) {\n      this.#error = err\n\n      // Check if onError handler wants to retry\n      if (this.#onError) {\n        const retryOpts = await this.#onError(err as Error)\n        // Guard against null (typeof null === \"object\" in JavaScript)\n        if (retryOpts && typeof retryOpts === `object`) {\n          // Update params/headers but don't reset offset\n          // We want to continue from where we left off, not refetch everything\n          if (retryOpts.params) {\n            // Merge new params with existing params to preserve other parameters\n            this.options.params = {\n              ...(this.options.params ?? {}),\n              ...retryOpts.params,\n            }\n          }\n\n          if (retryOpts.headers) {\n            // Merge new headers with existing headers to preserve other headers\n            this.options.headers = {\n              ...(this.options.headers ?? {}),\n              ...retryOpts.headers,\n            }\n          }\n\n          // Clear the error since we're retrying\n          this.#error = null\n\n          // Restart from current offset\n          this.#started = false\n          await this.#start()\n          return\n        }\n        // onError returned void, meaning it doesn't want to retry\n        // This is an unrecoverable error, notify subscribers\n        if (err instanceof Error) {\n          this.#sendErrorToSubscribers(err)\n        }\n        this.#connected = false\n        this.#tickPromiseRejecter?.()\n        return\n      }\n\n      // No onError handler provided, this is an unrecoverable error\n      // Notify subscribers and throw\n      if (err instanceof Error) {\n        this.#sendErrorToSubscribers(err)\n      }\n      this.#connected = false\n      this.#tickPromiseRejecter?.()\n      throw err\n    }\n\n    // Normal completion, clean up\n    this.#connected = false\n    this.#tickPromiseRejecter?.()\n  }\n\n  async #requestShape(): Promise<void> {\n    if (this.#state === `pause-requested`) {\n      this.#state = `paused`\n\n      return\n    }\n\n    if (\n      !this.options.subscribe &&\n      (this.options.signal?.aborted || this.#isUpToDate)\n    ) {\n      return\n    }\n\n    const resumingFromPause = this.#state === `paused`\n    this.#state = `active`\n\n    const { url, signal } = this.options\n    const { fetchUrl, requestHeaders } = await this.#constructUrl(\n      url,\n      resumingFromPause\n    )\n    const abortListener = await this.#createAbortListener(signal)\n    const requestAbortController = this.#requestAbortController! // we know that it is not undefined because it is set by `this.#createAbortListener`\n\n    try {\n      await this.#fetchShape({\n        fetchUrl,\n        requestAbortController,\n        headers: requestHeaders,\n        resumingFromPause,\n      })\n    } catch (e) {\n      // Handle abort error triggered by refresh\n      if (\n        (e instanceof FetchError || e instanceof FetchBackoffAbortError) &&\n        requestAbortController.signal.aborted &&\n        requestAbortController.signal.reason === FORCE_DISCONNECT_AND_REFRESH\n      ) {\n        // Start a new request\n        return this.#requestShape()\n      }\n\n      if (e instanceof FetchBackoffAbortError) {\n        // Check current state - it may have changed due to concurrent pause/resume calls\n        // from the visibility change handler during the async fetch operation.\n        // TypeScript's flow analysis doesn't account for concurrent state changes.\n        const currentState = this.#state as\n          | `active`\n          | `pause-requested`\n          | `paused`\n        if (\n          requestAbortController.signal.aborted &&\n          requestAbortController.signal.reason === PAUSE_STREAM &&\n          currentState === `pause-requested`\n        ) {\n          this.#state = `paused`\n        }\n        return // interrupted\n      }\n      if (!(e instanceof FetchError)) throw e // should never happen\n\n      if (e.status == 409) {\n        // Upon receiving a 409, we should start from scratch\n        // with the newly provided shape handle, or a fallback\n        // pseudo-handle based on the current one to act as a\n        // consistent cache buster\n\n        // Store the current shape URL as expired to avoid future 409s\n        if (this.#shapeHandle) {\n          const shapeKey = canonicalShapeKey(fetchUrl)\n          expiredShapesCache.markExpired(shapeKey, this.#shapeHandle)\n        }\n\n        const newShapeHandle =\n          e.headers[SHAPE_HANDLE_HEADER] || `${this.#shapeHandle!}-next`\n        this.#reset(newShapeHandle)\n\n        // must refetch control message might be in a list or not depending\n        // on whether it came from an SSE request or long poll - handle both\n        // cases for safety here but worth revisiting 409 handling\n        await this.#publish(\n          (Array.isArray(e.json) ? e.json : [e.json]) as Message<T>[]\n        )\n        return this.#requestShape()\n      } else {\n        // errors that have reached this point are not actionable without\n        // additional user input, such as 400s or failures to read the\n        // body of a response, so we exit the loop and let #start handle it\n        // Note: We don't notify subscribers here because onError might recover\n        throw e\n      }\n    } finally {\n      if (abortListener && signal) {\n        signal.removeEventListener(`abort`, abortListener)\n      }\n      this.#requestAbortController = undefined\n    }\n\n    this.#tickPromiseResolver?.()\n    return this.#requestShape()\n  }\n\n  async #constructUrl(\n    url: string,\n    resumingFromPause: boolean,\n    subsetParams?: SubsetParams\n  ) {\n    // Resolve headers and params in parallel\n    const [requestHeaders, params] = await Promise.all([\n      resolveHeaders(this.options.headers),\n      this.options.params\n        ? toInternalParams(convertWhereParamsToObj(this.options.params))\n        : undefined,\n    ])\n\n    // Validate params after resolution\n    if (params) validateParams(params)\n\n    const fetchUrl = new URL(url)\n\n    // Add PostgreSQL-specific parameters\n    if (params) {\n      if (params.table) setQueryParam(fetchUrl, TABLE_QUERY_PARAM, params.table)\n      if (params.where && typeof params.where === `string`) {\n        const encodedWhere = encodeWhereClause(\n          params.where,\n          this.options.columnMapper?.encode\n        )\n        setQueryParam(fetchUrl, WHERE_QUERY_PARAM, encodedWhere)\n      }\n      if (params.columns)\n        setQueryParam(fetchUrl, COLUMNS_QUERY_PARAM, params.columns)\n      if (params.replica) setQueryParam(fetchUrl, REPLICA_PARAM, params.replica)\n      if (params.params)\n        setQueryParam(fetchUrl, WHERE_PARAMS_PARAM, params.params)\n\n      // Add any remaining custom parameters\n      const customParams = { ...params }\n      delete customParams.table\n      delete customParams.where\n      delete customParams.columns\n      delete customParams.replica\n      delete customParams.params\n\n      for (const [key, value] of Object.entries(customParams)) {\n        setQueryParam(fetchUrl, key, value)\n      }\n    }\n\n    if (subsetParams) {\n      if (subsetParams.where && typeof subsetParams.where === `string`) {\n        const encodedWhere = encodeWhereClause(\n          subsetParams.where,\n          this.options.columnMapper?.encode\n        )\n        setQueryParam(fetchUrl, SUBSET_PARAM_WHERE, encodedWhere)\n      }\n      if (subsetParams.params)\n        // Serialize params as JSON to keep the parameter name constant for proxy configs\n        fetchUrl.searchParams.set(\n          SUBSET_PARAM_WHERE_PARAMS,\n          JSON.stringify(subsetParams.params)\n        )\n      if (subsetParams.limit)\n        setQueryParam(fetchUrl, SUBSET_PARAM_LIMIT, subsetParams.limit)\n      if (subsetParams.offset)\n        setQueryParam(fetchUrl, SUBSET_PARAM_OFFSET, subsetParams.offset)\n      if (subsetParams.orderBy && typeof subsetParams.orderBy === `string`) {\n        const encodedOrderBy = encodeWhereClause(\n          subsetParams.orderBy,\n          this.options.columnMapper?.encode\n        )\n        setQueryParam(fetchUrl, SUBSET_PARAM_ORDER_BY, encodedOrderBy)\n      }\n    }\n\n    // Add Electric's internal parameters\n    fetchUrl.searchParams.set(OFFSET_QUERY_PARAM, this.#lastOffset)\n    fetchUrl.searchParams.set(LOG_MODE_QUERY_PARAM, this.#mode)\n\n    // Snapshot requests (with subsetParams) should never use live polling\n    const isSnapshotRequest = subsetParams !== undefined\n\n    if (this.#isUpToDate && !isSnapshotRequest) {\n      // If we are resuming from a paused state, we don't want to perform a live request\n      // because it could be a long poll that holds for 20sec\n      // and during all that time `isConnected` will be false\n      if (!this.#isRefreshing && !resumingFromPause) {\n        fetchUrl.searchParams.set(LIVE_QUERY_PARAM, `true`)\n      }\n      fetchUrl.searchParams.set(\n        LIVE_CACHE_BUSTER_QUERY_PARAM,\n        this.#liveCacheBuster\n      )\n    }\n\n    if (this.#shapeHandle) {\n      // This should probably be a header for better cache breaking?\n      fetchUrl.searchParams.set(SHAPE_HANDLE_QUERY_PARAM, this.#shapeHandle!)\n    }\n\n    // Add cache buster for shapes known to be expired to prevent 409s\n    const shapeKey = canonicalShapeKey(fetchUrl)\n    const expiredHandle = expiredShapesCache.getExpiredHandle(shapeKey)\n    if (expiredHandle) {\n      fetchUrl.searchParams.set(EXPIRED_HANDLE_QUERY_PARAM, expiredHandle)\n    }\n\n    // sort query params in-place for stable URLs and improved cache hits\n    fetchUrl.searchParams.sort()\n\n    return {\n      fetchUrl,\n      requestHeaders,\n    }\n  }\n\n  async #createAbortListener(signal?: AbortSignal) {\n    // Create a new AbortController for this request\n    this.#requestAbortController = new AbortController()\n\n    // If user provided a signal, listen to it and pass on the reason for the abort\n    if (signal) {\n      const abortListener = () => {\n        this.#requestAbortController?.abort(signal.reason)\n      }\n\n      signal.addEventListener(`abort`, abortListener, { once: true })\n\n      if (signal.aborted) {\n        // If the signal is already aborted, abort the request immediately\n        this.#requestAbortController?.abort(signal.reason)\n      }\n\n      return abortListener\n    }\n  }\n\n  async #onInitialResponse(response: Response) {\n    const { headers, status } = response\n    const shapeHandle = headers.get(SHAPE_HANDLE_HEADER)\n    if (shapeHandle) {\n      this.#shapeHandle = shapeHandle\n    }\n\n    const lastOffset = headers.get(CHUNK_LAST_OFFSET_HEADER)\n    if (lastOffset) {\n      this.#lastOffset = lastOffset as Offset\n    }\n\n    const liveCacheBuster = headers.get(LIVE_CACHE_BUSTER_HEADER)\n    if (liveCacheBuster) {\n      this.#liveCacheBuster = liveCacheBuster\n    }\n\n    this.#schema = this.#schema ?? getSchemaFromHeaders(headers)\n\n    // NOTE: 204s are deprecated, the Electric server should not\n    // send these in latest versions but this is here for backwards\n    // compatibility\n    if (status === 204) {\n      // There's no content so we are live and up to date\n      this.#lastSyncedAt = Date.now()\n    }\n  }\n\n  async #onMessages(batch: Array<Message<T>>, isSseMessage = false) {\n    // Update isUpToDate\n    if (batch.length > 0) {\n      // Set isMidStream to true when we receive any data\n      this.#isMidStream = true\n\n      const lastMessage = batch[batch.length - 1]\n      if (isUpToDateMessage(lastMessage)) {\n        if (isSseMessage) {\n          // Only use the offset from the up-to-date message if this was an SSE message.\n          // If we would use this offset from a regular fetch, then it will be wrong\n          // and we will get an \"offset is out of bounds for this shape\" error\n          const offset = getOffset(lastMessage)\n          if (offset) {\n            this.#lastOffset = offset\n          }\n        }\n        this.#lastSyncedAt = Date.now()\n        this.#isUpToDate = true\n        // Set isMidStream to false when we see an up-to-date message\n        this.#isMidStream = false\n        // Resolve the promise waiting for mid-stream to end\n        this.#midStreamPromiseResolver?.()\n\n        // Check if we should suppress this up-to-date notification\n        // to prevent multiple renders from cached responses\n        if (this.#replayMode && !isSseMessage) {\n          // We're in replay mode (replaying cached responses during initial sync).\n          // Check if the cursor has changed - cursors are time-based and always\n          // increment, so a new cursor means fresh data from the server.\n          const currentCursor = this.#liveCacheBuster\n\n          if (currentCursor === this.#lastSeenCursor) {\n            // Same cursor = still replaying cached responses\n            // Suppress this up-to-date notification\n            return\n          }\n        }\n\n        // We're either:\n        // 1. Not in replay mode (normal operation), or\n        // 2. This is a live/SSE message (always fresh), or\n        // 3. Cursor has changed (exited replay mode with fresh data)\n        // In all cases, notify subscribers and record the up-to-date.\n        this.#lastSeenCursor = undefined // Exit replay mode\n\n        if (this.#currentFetchUrl) {\n          const shapeKey = canonicalShapeKey(this.#currentFetchUrl)\n          upToDateTracker.recordUpToDate(shapeKey, this.#liveCacheBuster)\n        }\n      }\n\n      // Filter messages using snapshot tracker\n      const messagesToProcess = batch.filter((message) => {\n        if (isChangeMessage(message)) {\n          return !this.#snapshotTracker.shouldRejectMessage(message)\n        }\n        return true // Always process control messages\n      })\n\n      await this.#publish(messagesToProcess)\n    }\n  }\n\n  /**\n   * Fetches the shape from the server using either long polling or SSE.\n   * Upon receiving a successfull response, the #onInitialResponse method is called.\n   * Afterwards, the #onMessages method is called for all the incoming updates.\n   * @param opts - The options for the request.\n   * @returns A promise that resolves when the request is complete (i.e. the long poll receives a response or the SSE connection is closed).\n   */\n  async #fetchShape(opts: {\n    fetchUrl: URL\n    requestAbortController: AbortController\n    headers: Record<string, string>\n    resumingFromPause?: boolean\n  }): Promise<void> {\n    // Store current fetch URL for shape key computation\n    this.#currentFetchUrl = opts.fetchUrl\n\n    // Check if we should enter replay mode (replaying cached responses)\n    // This happens when we're starting fresh (offset=-1 or before first up-to-date)\n    // and there's a recent up-to-date in localStorage (< 60s)\n    if (!this.#isUpToDate && !this.#replayMode) {\n      const shapeKey = canonicalShapeKey(opts.fetchUrl)\n      const lastSeenCursor = upToDateTracker.shouldEnterReplayMode(shapeKey)\n      if (lastSeenCursor) {\n        // Enter replay mode and store the last seen cursor\n        this.#lastSeenCursor = lastSeenCursor\n      }\n    }\n\n    const useSse = this.options.liveSse ?? this.options.experimentalLiveSse\n    if (\n      this.#isUpToDate &&\n      useSse &&\n      !this.#isRefreshing &&\n      !opts.resumingFromPause &&\n      !this.#sseFallbackToLongPolling\n    ) {\n      opts.fetchUrl.searchParams.set(EXPERIMENTAL_LIVE_SSE_QUERY_PARAM, `true`)\n      opts.fetchUrl.searchParams.set(LIVE_SSE_QUERY_PARAM, `true`)\n      return this.#requestShapeSSE(opts)\n    }\n\n    return this.#requestShapeLongPoll(opts)\n  }\n\n  async #requestShapeLongPoll(opts: {\n    fetchUrl: URL\n    requestAbortController: AbortController\n    headers: Record<string, string>\n  }): Promise<void> {\n    const { fetchUrl, requestAbortController, headers } = opts\n    const response = await this.#fetchClient(fetchUrl.toString(), {\n      signal: requestAbortController.signal,\n      headers,\n    })\n\n    this.#connected = true\n    await this.#onInitialResponse(response)\n\n    const schema = this.#schema! // we know that it is not undefined because it is set by `this.#onInitialResponse`\n    const res = await response.text()\n    const messages = res || `[]`\n    const batch = this.#messageParser.parse<Array<Message<T>>>(messages, schema)\n\n    await this.#onMessages(batch)\n  }\n\n  async #requestShapeSSE(opts: {\n    fetchUrl: URL\n    requestAbortController: AbortController\n    headers: Record<string, string>\n  }): Promise<void> {\n    const { fetchUrl, requestAbortController, headers } = opts\n    const fetch = this.#sseFetchClient\n\n    // Track when the SSE connection starts\n    this.#lastSseConnectionStartTime = Date.now()\n\n    try {\n      let buffer: Array<Message<T>> = []\n      await fetchEventSource(fetchUrl.toString(), {\n        headers,\n        fetch,\n        onopen: async (response: Response) => {\n          this.#connected = true\n          await this.#onInitialResponse(response)\n        },\n        onmessage: (event: EventSourceMessage) => {\n          if (event.data) {\n            // event.data is a single JSON object\n            const schema = this.#schema! // we know that it is not undefined because it is set in onopen when we call this.#onInitialResponse\n            const message = this.#messageParser.parse<Message<T>>(\n              event.data,\n              schema\n            )\n            buffer.push(message)\n\n            if (isUpToDateMessage(message)) {\n              // Flush the buffer on up-to-date message.\n              // Ensures that we only process complete batches of operations.\n              this.#onMessages(buffer, true)\n              buffer = []\n            }\n          }\n        },\n        onerror: (error: Error) => {\n          // rethrow to close the SSE connection\n          throw error\n        },\n        signal: requestAbortController.signal,\n      })\n    } catch (error) {\n      if (requestAbortController.signal.aborted) {\n        // During an SSE request, the fetch might have succeeded\n        // and we are parsing the incoming stream.\n        // If the abort happens while we're parsing the stream,\n        // then it won't be caught by our `createFetchWithBackoff` wrapper\n        // and instead we will get a raw AbortError here\n        // which we need to turn into a `FetchBackoffAbortError`\n        // such that #start handles it correctly.`\n        throw new FetchBackoffAbortError()\n      }\n      throw error\n    } finally {\n      // Check if the SSE connection closed too quickly\n      // This can happen when responses are cached or when the proxy/server\n      // is misconfigured for SSE and closes the connection immediately\n      const connectionDuration = Date.now() - this.#lastSseConnectionStartTime!\n      const wasAborted = requestAbortController.signal.aborted\n\n      if (connectionDuration < this.#minSseConnectionDuration && !wasAborted) {\n        // Connection was too short - likely a cached response or misconfiguration\n        this.#consecutiveShortSseConnections++\n\n        if (\n          this.#consecutiveShortSseConnections >= this.#maxShortSseConnections\n        ) {\n          // Too many short connections - fall back to long polling\n          this.#sseFallbackToLongPolling = true\n          console.warn(\n            `[Electric] SSE connections are closing immediately (possibly due to proxy buffering or misconfiguration). ` +\n              `Falling back to long polling. ` +\n              `Your proxy must support streaming SSE responses (not buffer the complete response). ` +\n              `Configuration: Nginx add 'X-Accel-Buffering: no', Caddy add 'flush_interval -1' to reverse_proxy. ` +\n              `Note: Do NOT disable caching entirely - Electric uses cache headers to enable request collapsing for efficiency.`\n          )\n        } else {\n          // Add exponential backoff with full jitter to prevent tight infinite loop\n          // Formula: random(0, min(cap, base * 2^attempt))\n          const maxDelay = Math.min(\n            this.#sseBackoffMaxDelay,\n            this.#sseBackoffBaseDelay *\n              Math.pow(2, this.#consecutiveShortSseConnections)\n          )\n          const delayMs = Math.floor(Math.random() * maxDelay)\n          await new Promise((resolve) => setTimeout(resolve, delayMs))\n        }\n      } else if (connectionDuration >= this.#minSseConnectionDuration) {\n        // Connection was healthy - reset counter\n        this.#consecutiveShortSseConnections = 0\n      }\n    }\n  }\n\n  #pause() {\n    if (this.#started && this.#state === `active`) {\n      this.#state = `pause-requested`\n      this.#requestAbortController?.abort(PAUSE_STREAM)\n    }\n  }\n\n  #resume() {\n    if (\n      this.#started &&\n      (this.#state === `paused` || this.#state === `pause-requested`)\n    ) {\n      // If we're resuming from pause-requested state, we need to set state back to active\n      // to prevent the pause from completing\n      if (this.#state === `pause-requested`) {\n        this.#state = `active`\n      }\n      this.#start()\n    }\n  }\n\n  subscribe(\n    callback: (messages: Message<T>[]) => MaybePromise<void>,\n    onError: (error: Error) => void = () => {}\n  ) {\n    const subscriptionId = Math.random()\n\n    this.#subscribers.set(subscriptionId, [callback, onError])\n    if (!this.#started) this.#start()\n\n    return () => {\n      this.#subscribers.delete(subscriptionId)\n    }\n  }\n\n  unsubscribeAll(): void {\n    this.#subscribers.clear()\n    this.#unsubscribeFromVisibilityChanges?.()\n  }\n\n  /** Unix time at which we last synced. Undefined when `isLoading` is true. */\n  lastSyncedAt(): number | undefined {\n    return this.#lastSyncedAt\n  }\n\n  /** Time elapsed since last sync (in ms). Infinity if we did not yet sync. */\n  lastSynced(): number {\n    if (this.#lastSyncedAt === undefined) return Infinity\n    return Date.now() - this.#lastSyncedAt\n  }\n\n  /** Indicates if we are connected to the Electric sync service. */\n  isConnected(): boolean {\n    return this.#connected\n  }\n\n  /** True during initial fetch. False afterwise.  */\n  isLoading(): boolean {\n    return !this.#isUpToDate\n  }\n\n  hasStarted(): boolean {\n    return this.#started\n  }\n\n  isPaused(): boolean {\n    return this.#state === `paused`\n  }\n\n  /** Await the next tick of the request loop */\n  async #nextTick() {\n    if (this.#tickPromise) {\n      return this.#tickPromise\n    }\n    this.#tickPromise = new Promise((resolve, reject) => {\n      this.#tickPromiseResolver = resolve\n      this.#tickPromiseRejecter = reject\n    })\n    this.#tickPromise.finally(() => {\n      this.#tickPromise = undefined\n      this.#tickPromiseResolver = undefined\n      this.#tickPromiseRejecter = undefined\n    })\n    return this.#tickPromise\n  }\n\n  /** Await until we're not in the middle of a stream (i.e., until we see an up-to-date message) */\n  async #waitForStreamEnd() {\n    if (!this.#isMidStream) {\n      return\n    }\n    if (this.#midStreamPromise) {\n      return this.#midStreamPromise\n    }\n    this.#midStreamPromise = new Promise((resolve) => {\n      this.#midStreamPromiseResolver = resolve\n    })\n    this.#midStreamPromise.finally(() => {\n      this.#midStreamPromise = undefined\n      this.#midStreamPromiseResolver = undefined\n    })\n    return this.#midStreamPromise\n  }\n\n  /**\n   * Refreshes the shape stream.\n   * This preemptively aborts any ongoing long poll and reconnects without\n   * long polling, ensuring that the stream receives an up to date message with the\n   * latest LSN from Postgres at that point in time.\n   */\n  async forceDisconnectAndRefresh(): Promise<void> {\n    this.#isRefreshing = true\n    if (this.#isUpToDate && !this.#requestAbortController?.signal.aborted) {\n      // If we are \"up to date\", any current request will be a \"live\" request\n      // and needs to be aborted\n      this.#requestAbortController?.abort(FORCE_DISCONNECT_AND_REFRESH)\n    }\n    await this.#nextTick()\n    this.#isRefreshing = false\n  }\n\n  async #publish(messages: Message<T>[]): Promise<void[]> {\n    // We process messages asynchronously\n    // but SSE's `onmessage` handler is synchronous.\n    // We use a promise chain to ensure that the handlers\n    // execute sequentially in the order the messages were received.\n    this.#messageChain = this.#messageChain.then(() =>\n      Promise.all(\n        Array.from(this.#subscribers.values()).map(async ([callback, __]) => {\n          try {\n            await callback(messages)\n          } catch (err) {\n            queueMicrotask(() => {\n              throw err\n            })\n          }\n        })\n      )\n    )\n\n    return this.#messageChain\n  }\n\n  #sendErrorToSubscribers(error: Error) {\n    this.#subscribers.forEach(([_, errorFn]) => {\n      errorFn?.(error)\n    })\n  }\n\n  #subscribeToVisibilityChanges() {\n    if (\n      typeof document === `object` &&\n      typeof document.hidden === `boolean` &&\n      typeof document.addEventListener === `function`\n    ) {\n      const visibilityHandler = () => {\n        if (document.hidden) {\n          this.#pause()\n        } else {\n          this.#resume()\n        }\n      }\n\n      document.addEventListener(`visibilitychange`, visibilityHandler)\n\n      // Store cleanup function to remove the event listener\n      this.#unsubscribeFromVisibilityChanges = () => {\n        document.removeEventListener(`visibilitychange`, visibilityHandler)\n      }\n    }\n  }\n\n  /**\n   * Resets the state of the stream, optionally with a provided\n   * shape handle\n   */\n  #reset(handle?: string) {\n    this.#lastOffset = `-1`\n    this.#liveCacheBuster = ``\n    this.#shapeHandle = handle\n    this.#isUpToDate = false\n    this.#isMidStream = true\n    this.#connected = false\n    this.#schema = undefined\n    this.#activeSnapshotRequests = 0\n    // Reset SSE fallback state to try SSE again after reset\n    this.#consecutiveShortSseConnections = 0\n    this.#sseFallbackToLongPolling = false\n  }\n\n  /**\n   * Request a snapshot for subset of data and inject it into the subscribed data stream.\n   *\n   * Only available when mode is `changes_only`.\n   * Returns the insertion point & the data, but more importantly injects the data\n   * into the subscribed data stream. Returned value is unlikely to be useful for the caller,\n   * unless the caller has complicated additional logic.\n   *\n   * Data will be injected in a way that's also tracking further incoming changes, and it'll\n   * skip the ones that are already in the snapshot.\n   *\n   * @param opts - The options for the snapshot request.\n   * @returns The metadata and the data for the snapshot.\n   */\n  async requestSnapshot(opts: SubsetParams): Promise<{\n    metadata: SnapshotMetadata\n    data: Array<ChangeMessage<T>>\n  }> {\n    if (this.#mode === `full`) {\n      throw new Error(\n        `Snapshot requests are not supported in ${this.#mode} mode, as the consumer is guaranteed to observe all data`\n      )\n    }\n    // We shouldn't be getting a snapshot on a shape that's not started\n    if (!this.#started) await this.#start()\n\n    // Wait until we're not mid-stream before pausing\n    // This ensures we don't pause in the middle of a transaction\n    await this.#waitForStreamEnd()\n\n    // Pause the stream if this is the first snapshot request\n    this.#activeSnapshotRequests++\n\n    try {\n      if (this.#activeSnapshotRequests === 1) {\n        // Currently this cannot throw, but in case it can later it's in this try block to not have a stuck counter\n        this.#pause()\n      }\n\n      const { metadata, data } = await this.fetchSnapshot(opts)\n\n      const dataWithEndBoundary = (data as Array<Message<T>>).concat([\n        { headers: { control: `snapshot-end`, ...metadata } },\n      ])\n\n      this.#snapshotTracker.addSnapshot(\n        metadata,\n        new Set(data.map((message) => message.key))\n      )\n      this.#onMessages(dataWithEndBoundary, false)\n\n      return {\n        metadata,\n        data,\n      }\n    } finally {\n      // Resume the stream if this was the last snapshot request\n      this.#activeSnapshotRequests--\n      if (this.#activeSnapshotRequests === 0) {\n        this.#resume()\n      }\n    }\n  }\n\n  /**\n   * Fetch a snapshot for subset of data.\n   * Returns the metadata and the data, but does not inject it into the subscribed data stream.\n   *\n   * @param opts - The options for the snapshot request.\n   * @returns The metadata and the data for the snapshot.\n   */\n  async fetchSnapshot(opts: SubsetParams): Promise<{\n    metadata: SnapshotMetadata\n    data: Array<ChangeMessage<T>>\n  }> {\n    const { fetchUrl, requestHeaders } = await this.#constructUrl(\n      this.options.url,\n      true,\n      opts\n    )\n\n    const response = await this.#fetchClient(fetchUrl.toString(), {\n      headers: requestHeaders,\n    })\n\n    if (!response.ok) {\n      throw new FetchError(\n        response.status,\n        undefined,\n        undefined,\n        Object.fromEntries([...response.headers.entries()]),\n        fetchUrl.toString()\n      )\n    }\n\n    // Use schema from stream if available, otherwise extract from response header\n    const schema: Schema =\n      this.#schema ??\n      getSchemaFromHeaders(response.headers, {\n        required: true,\n        url: fetchUrl.toString(),\n      })\n\n    const { metadata, data: rawData } = await response.json()\n    const data = this.#messageParser.parseSnapshotData<ChangeMessage<T>>(\n      rawData,\n      schema\n    )\n\n    return {\n      metadata,\n      data,\n    }\n  }\n}\n\n/**\n * Extracts the schema from response headers.\n * @param headers - The response headers\n * @param options - Options for schema extraction\n * @param options.required - If true, throws MissingHeadersError when header is missing. Defaults to false.\n * @param options.url - The URL to include in the error message if required is true\n * @returns The parsed schema, or an empty object if not required and header is missing\n * @throws {MissingHeadersError} if required is true and the header is missing\n */\nfunction getSchemaFromHeaders(\n  headers: Headers,\n  options?: { required?: boolean; url?: string }\n): Schema {\n  const schemaHeader = headers.get(SHAPE_SCHEMA_HEADER)\n  if (!schemaHeader) {\n    if (options?.required && options?.url) {\n      throw new MissingHeadersError(options.url, [SHAPE_SCHEMA_HEADER])\n    }\n    return {}\n  }\n  return JSON.parse(schemaHeader)\n}\n\n/**\n * Validates that no reserved parameter names are used in the provided params object\n * @throws {ReservedParamError} if any reserved parameter names are found\n */\nfunction validateParams(params: Record<string, unknown> | undefined): void {\n  if (!params) return\n\n  const reservedParams = Object.keys(params).filter((key) =>\n    RESERVED_PARAMS.has(key as ReservedParamKeys)\n  )\n  if (reservedParams.length > 0) {\n    throw new ReservedParamError(reservedParams)\n  }\n}\n\nfunction validateOptions<T>(options: Partial<ShapeStreamOptions<T>>): void {\n  if (!options.url) {\n    throw new MissingShapeUrlError()\n  }\n  if (options.signal && !(options.signal instanceof AbortSignal)) {\n    throw new InvalidSignalError()\n  }\n\n  if (\n    options.offset !== undefined &&\n    options.offset !== `-1` &&\n    options.offset !== `now` &&\n    !options.handle\n  ) {\n    throw new MissingShapeHandleError()\n  }\n\n  validateParams(options.params)\n\n  return\n}\n\n// `unknown` being in the value is a bit of defensive programming if user doesn't use TS\nfunction setQueryParam(\n  url: URL,\n  key: string,\n  value: Record<string, string> | string | unknown\n): void {\n  if (value === undefined || value == null) {\n    return\n  } else if (typeof value === `string`) {\n    url.searchParams.set(key, value)\n  } else if (typeof value === `object`) {\n    for (const [k, v] of Object.entries(value)) {\n      url.searchParams.set(`${key}[${k}]`, v)\n    }\n  } else {\n    url.searchParams.set(key, value.toString())\n  }\n}\n\nfunction convertWhereParamsToObj(\n  allPgParams: ExternalParamsRecord<Row>\n): ExternalParamsRecord<Row> {\n  if (Array.isArray(allPgParams.params)) {\n    return {\n      ...allPgParams,\n      params: Object.fromEntries(allPgParams.params.map((v, i) => [i + 1, v])),\n    }\n  }\n  return allPgParams\n}\n", "interface ExpiredShapeCacheEntry {\n  expiredHandle: string\n  lastUsed: number\n}\n\n/**\n * LRU cache for tracking expired shapes with automatic cleanup\n */\nexport class ExpiredShapesCache {\n  private data: Record<string, ExpiredShapeCacheEntry> = {}\n  private max: number = 250\n  private readonly storageKey = `electric_expired_shapes`\n\n  getExpiredHandle(shapeUrl: string): string | null {\n    const entry = this.data[shapeUrl]\n    if (entry) {\n      // Update last used time when accessed\n      entry.lastUsed = Date.now()\n      this.save()\n      return entry.expiredHandle\n    }\n    return null\n  }\n\n  markExpired(shapeUrl: string, handle: string): void {\n    this.data[shapeUrl] = { expiredHandle: handle, lastUsed: Date.now() }\n\n    const keys = Object.keys(this.data)\n    if (keys.length > this.max) {\n      const oldest = keys.reduce((min, k) =>\n        this.data[k].lastUsed < this.data[min].lastUsed ? k : min\n      )\n      delete this.data[oldest]\n    }\n\n    this.save()\n  }\n\n  private save(): void {\n    if (typeof localStorage === `undefined`) return\n    try {\n      localStorage.setItem(this.storageKey, JSON.stringify(this.data))\n    } catch {\n      // Ignore localStorage errors\n    }\n  }\n\n  private load(): void {\n    if (typeof localStorage === `undefined`) return\n    try {\n      const stored = localStorage.getItem(this.storageKey)\n      if (stored) {\n        this.data = JSON.parse(stored)\n      }\n    } catch {\n      // Ignore localStorage errors, start fresh\n      this.data = {}\n    }\n  }\n\n  constructor() {\n    this.load()\n  }\n\n  clear(): void {\n    this.data = {}\n    this.save()\n  }\n}\n\n// Module-level singleton instance\nexport const expiredShapesCache = new ExpiredShapesCache()\n", "interface UpToDateEntry {\n  timestamp: number\n  cursor: string\n}\n\n/**\n * Tracks up-to-date messages to detect when we're replaying cached responses.\n *\n * When a shape receives an up-to-date, we record the timestamp and cursor in localStorage.\n * On page refresh, if we find a recent timestamp (< 60s), we know we'll be replaying\n * cached responses. We suppress their up-to-date notifications until we see a NEW cursor\n * (different from the last recorded one), which indicates fresh data from the server.\n *\n * localStorage writes are throttled to once per 60 seconds to avoid performance issues\n * with frequent updates. In-memory data is always kept current.\n */\nexport class UpToDateTracker {\n  private data: Record<string, UpToDateEntry> = {}\n  private readonly storageKey = `electric_up_to_date_tracker`\n  private readonly cacheTTL = 60_000 // 60s to match typical CDN s-maxage cache duration\n  private readonly maxEntries = 250\n  private readonly writeThrottleMs = 60_000 // Throttle localStorage writes to once per 60s\n  private lastWriteTime = 0\n  private pendingSaveTimer?: ReturnType<typeof setTimeout>\n\n  constructor() {\n    this.load()\n    this.cleanup()\n  }\n\n  /**\n   * Records that a shape received an up-to-date message with a specific cursor.\n   * This timestamp and cursor are used to detect cache replay scenarios.\n   * Updates in-memory immediately, but throttles localStorage writes.\n   */\n  recordUpToDate(shapeKey: string, cursor: string): void {\n    this.data[shapeKey] = {\n      timestamp: Date.now(),\n      cursor,\n    }\n\n    // Implement LRU eviction if we exceed max entries\n    const keys = Object.keys(this.data)\n    if (keys.length > this.maxEntries) {\n      const oldest = keys.reduce((min, k) =>\n        this.data[k].timestamp < this.data[min].timestamp ? k : min\n      )\n      delete this.data[oldest]\n    }\n\n    this.scheduleSave()\n  }\n\n  /**\n   * Schedules a throttled save to localStorage.\n   * Writes immediately if enough time has passed, otherwise schedules for later.\n   */\n  private scheduleSave(): void {\n    const now = Date.now()\n    const timeSinceLastWrite = now - this.lastWriteTime\n\n    if (timeSinceLastWrite >= this.writeThrottleMs) {\n      // Enough time has passed, write immediately\n      this.lastWriteTime = now\n      this.save()\n    } else if (!this.pendingSaveTimer) {\n      // Schedule a write for when the throttle period expires\n      const delay = this.writeThrottleMs - timeSinceLastWrite\n      this.pendingSaveTimer = setTimeout(() => {\n        this.lastWriteTime = Date.now()\n        this.pendingSaveTimer = undefined\n        this.save()\n      }, delay)\n    }\n    // else: a save is already scheduled, no need to do anything\n  }\n\n  /**\n   * Checks if we should enter replay mode for this shape.\n   * Returns the last seen cursor if there's a recent up-to-date (< 60s),\n   * which means we'll likely be replaying cached responses.\n   * Returns null if no recent up-to-date exists.\n   */\n  shouldEnterReplayMode(shapeKey: string): string | null {\n    const entry = this.data[shapeKey]\n    if (!entry) {\n      return null\n    }\n\n    const age = Date.now() - entry.timestamp\n    if (age >= this.cacheTTL) {\n      return null\n    }\n\n    return entry.cursor\n  }\n\n  /**\n   * Cleans up expired entries from the cache.\n   * Called on initialization and can be called periodically.\n   */\n  private cleanup(): void {\n    const now = Date.now()\n    const keys = Object.keys(this.data)\n    let modified = false\n\n    for (const key of keys) {\n      const age = now - this.data[key].timestamp\n      if (age > this.cacheTTL) {\n        delete this.data[key]\n        modified = true\n      }\n    }\n\n    if (modified) {\n      this.save()\n    }\n  }\n\n  private save(): void {\n    if (typeof localStorage === `undefined`) return\n    try {\n      localStorage.setItem(this.storageKey, JSON.stringify(this.data))\n    } catch {\n      // Ignore localStorage errors (quota exceeded, etc.)\n    }\n  }\n\n  private load(): void {\n    if (typeof localStorage === `undefined`) return\n    try {\n      const stored = localStorage.getItem(this.storageKey)\n      if (stored) {\n        this.data = JSON.parse(stored)\n      }\n    } catch {\n      // Ignore localStorage errors, start fresh\n      this.data = {}\n    }\n  }\n\n  /**\n   * Clears all tracked up-to-date timestamps.\n   * Useful for testing or manual cache invalidation.\n   */\n  clear(): void {\n    this.data = {}\n    if (this.pendingSaveTimer) {\n      clearTimeout(this.pendingSaveTimer)\n      this.pendingSaveTimer = undefined\n    }\n    this.save()\n  }\n}\n\n// Module-level singleton instance\nexport const upToDateTracker = new UpToDateTracker()\n", "import { isVisibleInSnapshot } from './helpers'\nimport { Row, SnapshotMetadata } from './types'\nimport { ChangeMessage } from './types'\n\n/**\n * Tracks active snapshots and filters out duplicate change messages that are already included in snapshots.\n *\n * When requesting a snapshot in changes_only mode, we need to track which transactions were included in the\n * snapshot to avoid processing duplicate changes that arrive via the live stream. This class maintains that\n * tracking state and provides methods to:\n *\n * - Add new snapshots for tracking via addSnapshot()\n * - Remove completed snapshots via removeSnapshot()\n * - Check if incoming changes should be filtered via shouldRejectMessage()\n */\nexport class SnapshotTracker {\n  private activeSnapshots: Map<\n    number,\n    { xmin: bigint; xmax: bigint; xip_list: bigint[]; keys: Set<string> }\n  > = new Map()\n  private xmaxSnapshots: Map<bigint, Set<number>> = new Map()\n  private snapshotsByDatabaseLsn: Map<bigint, Set<number>> = new Map()\n\n  /**\n   * Add a new snapshot for tracking\n   */\n  addSnapshot(metadata: SnapshotMetadata, keys: Set<string>): void {\n    this.activeSnapshots.set(metadata.snapshot_mark, {\n      xmin: BigInt(metadata.xmin),\n      xmax: BigInt(metadata.xmax),\n      xip_list: metadata.xip_list.map(BigInt),\n      keys,\n    })\n    const xmaxSet =\n      this.xmaxSnapshots\n        .get(BigInt(metadata.xmax))\n        ?.add(metadata.snapshot_mark) ?? new Set([metadata.snapshot_mark])\n    this.xmaxSnapshots.set(BigInt(metadata.xmax), xmaxSet)\n    const databaseLsnSet =\n      this.snapshotsByDatabaseLsn\n        .get(BigInt(metadata.database_lsn))\n        ?.add(metadata.snapshot_mark) ?? new Set([metadata.snapshot_mark])\n    this.snapshotsByDatabaseLsn.set(\n      BigInt(metadata.database_lsn),\n      databaseLsnSet\n    )\n  }\n\n  /**\n   * Remove a snapshot from tracking\n   */\n  removeSnapshot(snapshotMark: number): void {\n    this.activeSnapshots.delete(snapshotMark)\n  }\n\n  /**\n   * Check if a change message should be filtered because its already in an active snapshot\n   * Returns true if the message should be filtered out (not processed)\n   */\n  shouldRejectMessage(message: ChangeMessage<Row<unknown>>): boolean {\n    const txids = message.headers.txids || []\n    if (txids.length === 0) return false\n\n    const xid = Math.max(...txids) // Use the maximum transaction ID\n\n    for (const [xmax, snapshots] of this.xmaxSnapshots.entries()) {\n      if (xid >= xmax) {\n        for (const snapshot of snapshots) {\n          this.removeSnapshot(snapshot)\n        }\n      }\n    }\n\n    return [...this.activeSnapshots.values()].some(\n      (x) => x.keys.has(message.key) && isVisibleInSnapshot(xid, x)\n    )\n  }\n\n  lastSeenUpdate(newDatabaseLsn: bigint): void {\n    for (const [dbLsn, snapshots] of this.snapshotsByDatabaseLsn.entries()) {\n      if (dbLsn <= newDatabaseLsn) {\n        for (const snapshot of snapshots) {\n          this.removeSnapshot(snapshot)\n        }\n      }\n    }\n  }\n}\n", "import { Message, Offset, Row } from './types'\nimport { isChangeMessage, isControlMessage } from './helpers'\nimport { FetchError } from './error'\nimport { LogMode, ShapeStreamInterface } from './client'\n\nexport type ShapeData<T extends Row<unknown> = Row> = Map<string, T>\nexport type ShapeChangedCallback<T extends Row<unknown> = Row> = (data: {\n  value: ShapeData<T>\n  rows: T[]\n}) => void\n\ntype ShapeStatus = `syncing` | `up-to-date`\n\n/**\n * A Shape is an object that subscribes to a shape log,\n * keeps a materialised shape `.rows` in memory and\n * notifies subscribers when the value has changed.\n *\n * It can be used without a framework and as a primitive\n * to simplify developing framework hooks.\n *\n * @constructor\n * @param {ShapeStream<T extends Row>} - the underlying shape stream\n * @example\n * ```\n * const shapeStream = new ShapeStream<{ foo: number }>({\n *   url: `http://localhost:3000/v1/shape`,\n *   params: {\n *     table: `foo`\n *   }\n * })\n * const shape = new Shape(shapeStream)\n * ```\n *\n * `rows` returns a promise that resolves the Shape data once the Shape has been\n * fully loaded (and when resuming from being offline):\n *\n *     const rows = await shape.rows\n *\n * `currentRows` returns the current data synchronously:\n *\n *     const rows = shape.currentRows\n *\n *  Subscribe to updates. Called whenever the shape updates in Postgres.\n *\n *     shape.subscribe(({ rows }) => {\n *       console.log(rows)\n *     })\n */\nexport class Shape<T extends Row<unknown> = Row> {\n  readonly stream: ShapeStreamInterface<T>\n\n  readonly #data: ShapeData<T> = new Map()\n  readonly #subscribers = new Map<number, ShapeChangedCallback<T>>()\n  readonly #insertedKeys = new Set<string>()\n  readonly #requestedSubSnapshots = new Set<string>()\n  #reexecuteSnapshotsPending = false\n  #status: ShapeStatus = `syncing`\n  #error: FetchError | false = false\n\n  constructor(stream: ShapeStreamInterface<T>) {\n    this.stream = stream\n    this.stream.subscribe(\n      this.#process.bind(this),\n      this.#handleError.bind(this)\n    )\n  }\n\n  get isUpToDate(): boolean {\n    return this.#status === `up-to-date`\n  }\n\n  get lastOffset(): Offset {\n    return this.stream.lastOffset\n  }\n\n  get handle(): string | undefined {\n    return this.stream.shapeHandle\n  }\n\n  get rows(): Promise<T[]> {\n    return this.value.then((v) => Array.from(v.values()))\n  }\n\n  get currentRows(): T[] {\n    return Array.from(this.currentValue.values())\n  }\n\n  get value(): Promise<ShapeData<T>> {\n    return new Promise((resolve, reject) => {\n      if (this.stream.isUpToDate) {\n        resolve(this.currentValue)\n      } else {\n        const unsubscribe = this.subscribe(({ value }) => {\n          unsubscribe()\n          if (this.#error) reject(this.#error)\n          resolve(value)\n        })\n      }\n    })\n  }\n\n  get currentValue() {\n    return this.#data\n  }\n\n  get error() {\n    return this.#error\n  }\n\n  /** Unix time at which we last synced. Undefined when `isLoading` is true. */\n  lastSyncedAt(): number | undefined {\n    return this.stream.lastSyncedAt()\n  }\n\n  /** Time elapsed since last sync (in ms). Infinity if we did not yet sync. */\n  lastSynced() {\n    return this.stream.lastSynced()\n  }\n\n  /** True during initial fetch. False afterwise.  */\n  isLoading() {\n    return this.stream.isLoading()\n  }\n\n  /** Indicates if we are connected to the Electric sync service. */\n  isConnected(): boolean {\n    return this.stream.isConnected()\n  }\n\n  /** Current log mode of the underlying stream */\n  get mode(): LogMode {\n    return this.stream.mode\n  }\n\n  /**\n   * Request a snapshot for subset of data. Only available when mode is changes_only.\n   * Returns void; data will be emitted via the stream and processed by this Shape.\n   */\n  async requestSnapshot(\n    params: Parameters<ShapeStreamInterface<T>[`requestSnapshot`]>[0]\n  ): Promise<void> {\n    // Track this snapshot request for future re-execution on shape rotation\n    const key = JSON.stringify(params)\n    this.#requestedSubSnapshots.add(key)\n    // Ensure the stream is up-to-date so schema is available for parsing\n    await this.#awaitUpToDate()\n    await this.stream.requestSnapshot(params)\n  }\n\n  subscribe(callback: ShapeChangedCallback<T>): () => void {\n    const subscriptionId = Math.random()\n\n    this.#subscribers.set(subscriptionId, callback)\n\n    return () => {\n      this.#subscribers.delete(subscriptionId)\n    }\n  }\n\n  unsubscribeAll(): void {\n    this.#subscribers.clear()\n  }\n\n  get numSubscribers() {\n    return this.#subscribers.size\n  }\n\n  #process(messages: Message<T>[]): void {\n    let shouldNotify = false\n\n    messages.forEach((message) => {\n      if (isChangeMessage(message)) {\n        shouldNotify = this.#updateShapeStatus(`syncing`)\n        if (this.mode === `full`) {\n          switch (message.headers.operation) {\n            case `insert`:\n              this.#data.set(message.key, message.value)\n              break\n            case `update`:\n              this.#data.set(message.key, {\n                ...this.#data.get(message.key)!,\n                ...message.value,\n              })\n              break\n            case `delete`:\n              this.#data.delete(message.key)\n              break\n          }\n        } else {\n          // changes_only: only apply updates/deletes for keys for which we observed an insert\n          switch (message.headers.operation) {\n            case `insert`:\n              this.#insertedKeys.add(message.key)\n              this.#data.set(message.key, message.value)\n              break\n            case `update`:\n              if (this.#insertedKeys.has(message.key)) {\n                this.#data.set(message.key, {\n                  ...this.#data.get(message.key)!,\n                  ...message.value,\n                })\n              }\n              break\n            case `delete`:\n              if (this.#insertedKeys.has(message.key)) {\n                this.#data.delete(message.key)\n                this.#insertedKeys.delete(message.key)\n              }\n              break\n          }\n        }\n      }\n\n      if (isControlMessage(message)) {\n        switch (message.headers.control) {\n          case `up-to-date`:\n            shouldNotify = this.#updateShapeStatus(`up-to-date`)\n            if (this.#reexecuteSnapshotsPending) {\n              this.#reexecuteSnapshotsPending = false\n              void this.#reexecuteSnapshots()\n            }\n            break\n          case `must-refetch`:\n            this.#data.clear()\n            this.#insertedKeys.clear()\n            this.#error = false\n            shouldNotify = this.#updateShapeStatus(`syncing`)\n            // Flag to re-execute sub-snapshots once the new shape is up-to-date\n            this.#reexecuteSnapshotsPending = true\n            break\n        }\n      }\n    })\n\n    if (shouldNotify) this.#notify()\n  }\n\n  async #reexecuteSnapshots(): Promise<void> {\n    // Wait until stream is up-to-date again (ensures schema is available)\n    await this.#awaitUpToDate()\n\n    // Re-execute all snapshots concurrently\n    await Promise.all(\n      Array.from(this.#requestedSubSnapshots).map(async (jsonParams) => {\n        try {\n          const snapshot = JSON.parse(jsonParams)\n          await this.stream.requestSnapshot(snapshot)\n        } catch (_) {\n          // Ignore and continue; errors will be surfaced via stream onError\n        }\n      })\n    )\n  }\n\n  async #awaitUpToDate(): Promise<void> {\n    if (this.stream.isUpToDate) return\n    await new Promise<void>((resolve) => {\n      const check = () => {\n        if (this.stream.isUpToDate) {\n          clearInterval(interval)\n          unsub()\n          resolve()\n        }\n      }\n      const interval = setInterval(check, 10)\n      const unsub = this.stream.subscribe(\n        () => check(),\n        () => check()\n      )\n      check()\n    })\n  }\n\n  #updateShapeStatus(status: ShapeStatus): boolean {\n    const stateChanged = this.#status !== status\n    this.#status = status\n    return stateChanged && status === `up-to-date`\n  }\n\n  #handleError(e: Error): void {\n    if (e instanceof FetchError) {\n      this.#error = e\n      this.#notify()\n    }\n  }\n\n  #notify(): void {\n    this.#subscribers.forEach((callback) => {\n      callback({ value: this.currentValue, rows: this.currentRows })\n    })\n  }\n}\n", "import type { Derived } from './derived'\nimport type { Store } from './store'\n\n/**\n * This is here to solve the pyramid dependency problem where:\n *       A\n *      / \\\n *     B   C\n *      \\ /\n *       D\n *\n * Where we deeply traverse this tree, how do we avoid D being recomputed twice; once when B is updated, once when C is.\n *\n * To solve this, we create linkedDeps that allows us to sync avoid writes to the state until all of the deps have been\n * resolved.\n *\n * This is a record of stores, because derived stores are not able to write values to, but stores are\n */\nexport const __storeToDerived = new WeakMap<\n  Store<unknown>,\n  Array<Derived<unknown>>\n>()\nexport const __derivedToStore = new WeakMap<\n  Derived<unknown>,\n  Set<Store<unknown>>\n>()\n\nexport const __depsThatHaveWrittenThisTick = {\n  current: [] as Array<Derived<unknown> | Store<unknown>>,\n}\n\nlet __isFlushing = false\nlet __batchDepth = 0\nconst __pendingUpdates = new Set<Store<unknown>>()\n// Add a map to store initial values before batch\nconst __initialBatchValues = new Map<Store<unknown>, unknown>()\n\nfunction __flush_internals(relatedVals: ReadonlyArray<Derived<unknown>>) {\n  for (const derived of relatedVals) {\n    if (__depsThatHaveWrittenThisTick.current.includes(derived)) {\n      continue\n    }\n\n    __depsThatHaveWrittenThisTick.current.push(derived)\n    derived.recompute()\n\n    const stores = __derivedToStore.get(derived)\n    if (stores) {\n      for (const store of stores) {\n        const relatedLinkedDerivedVals = __storeToDerived.get(store)\n        if (!relatedLinkedDerivedVals?.length) continue\n        __flush_internals(relatedLinkedDerivedVals)\n      }\n    }\n  }\n}\n\nfunction __notifyListeners(store: Store<unknown>) {\n  const value = {\n    prevVal: store.prevState as never,\n    currentVal: store.state as never,\n  }\n  for (const listener of store.listeners) {\n    listener(value)\n  }\n}\n\nfunction __notifyDerivedListeners(derived: Derived<unknown>) {\n  const value = {\n    prevVal: derived.prevState as never,\n    currentVal: derived.state as never,\n  }\n  for (const listener of derived.listeners) {\n    listener(value)\n  }\n}\n\n/**\n * @private only to be called from `Store` on write\n */\nexport function __flush(store: Store<unknown>) {\n  // If we're starting a batch, store the initial values\n  if (__batchDepth > 0 && !__initialBatchValues.has(store)) {\n    __initialBatchValues.set(store, store.prevState)\n  }\n\n  __pendingUpdates.add(store)\n\n  if (__batchDepth > 0) return\n  if (__isFlushing) return\n\n  try {\n    __isFlushing = true\n\n    while (__pendingUpdates.size > 0) {\n      const stores = Array.from(__pendingUpdates)\n      __pendingUpdates.clear()\n\n      // First notify listeners with updated values\n      for (const store of stores) {\n        // Use initial batch values for prevState if we have them\n        const prevState = __initialBatchValues.get(store) ?? store.prevState\n        store.prevState = prevState\n        __notifyListeners(store)\n      }\n\n      // Then update all derived values\n      for (const store of stores) {\n        const derivedVals = __storeToDerived.get(store)\n        if (!derivedVals) continue\n\n        __depsThatHaveWrittenThisTick.current.push(store)\n        __flush_internals(derivedVals)\n      }\n\n      // Notify derived listeners after recomputing\n      for (const store of stores) {\n        const derivedVals = __storeToDerived.get(store)\n        if (!derivedVals) continue\n\n        for (const derived of derivedVals) {\n          __notifyDerivedListeners(derived)\n        }\n      }\n    }\n  } finally {\n    __isFlushing = false\n    __depsThatHaveWrittenThisTick.current = []\n    __initialBatchValues.clear()\n  }\n}\n\nexport function batch(fn: () => void) {\n  __batchDepth++\n  try {\n    fn()\n  } finally {\n    __batchDepth--\n    if (__batchDepth === 0) {\n      const pendingUpdateToFlush = __pendingUpdates.values().next().value\n      if (pendingUpdateToFlush) {\n        __flush(pendingUpdateToFlush) // Trigger flush of all pending updates\n      }\n    }\n  }\n}\n", "/**\n * @private\n */\nexport type AnyUpdater = (prev: any) => any\n\n/**\n * Type-safe updater that can be either a function or direct value\n */\nexport type Updater<T> = ((prev: T) => T) | T\n\n/**\n * @private\n */\nexport interface ListenerValue<T> {\n  readonly prevVal: T\n  readonly currentVal: T\n}\n\n/**\n * @private\n */\nexport type Listener<T> = (value: ListenerValue<T>) => void\n\n/**\n * Type guard to check if updater is a function\n */\nexport function isUpdaterFunction<T>(\n  updater: Updater<T>,\n): updater is (prev: T) => T {\n  return typeof updater === 'function'\n}\n", "import { __flush } from './scheduler'\nimport { isUpdaterFunction } from './types'\nimport type { AnyUpdater, Listener, Updater } from './types'\n\nexport interface StoreOptions<\n  TState,\n  TUpdater extends AnyUpdater = (cb: TState) => TState,\n> {\n  /**\n   * Replace the default update function with a custom one.\n   */\n  updateFn?: (previous: TState) => (updater: TUpdater) => TState\n  /**\n   * Called when a listener subscribes to the store.\n   *\n   * @return a function to unsubscribe the listener\n   */\n  onSubscribe?: (\n    listener: Listener<TState>,\n    store: Store<TState, TUpdater>,\n  ) => () => void\n  /**\n   * Called after the state has been updated, used to derive other state.\n   */\n  onUpdate?: () => void\n}\n\nexport class Store<\n  TState,\n  TUpdater extends AnyUpdater = (cb: TState) => TState,\n> {\n  listeners = new Set<Listener<TState>>()\n  state: TState\n  prevState: TState\n  options?: StoreOptions<TState, TUpdater>\n\n  constructor(initialState: TState, options?: StoreOptions<TState, TUpdater>) {\n    this.prevState = initialState\n    this.state = initialState\n    this.options = options\n  }\n\n  subscribe = (listener: Listener<TState>) => {\n    this.listeners.add(listener)\n    const unsub = this.options?.onSubscribe?.(listener, this)\n    return () => {\n      this.listeners.delete(listener)\n      unsub?.()\n    }\n  }\n\n  /**\n   * Update the store state safely with improved type checking\n   */\n  setState(updater: (prevState: TState) => TState): void\n  setState(updater: TState): void\n  setState(updater: TUpdater): void\n  setState(updater: Updater<TState> | TUpdater): void {\n    this.prevState = this.state\n\n    if (this.options?.updateFn) {\n      this.state = this.options.updateFn(this.prevState)(updater as TUpdater)\n    } else {\n      if (isUpdaterFunction(updater)) {\n        this.state = updater(this.prevState)\n      } else {\n        this.state = updater as TState\n      }\n    }\n\n    // Always run onUpdate, regardless of batching\n    this.options?.onUpdate?.()\n\n    // Attempt to flush\n    __flush(this as never)\n  }\n}\n", "import { TanStackDBError } from \"@tanstack/db\"\n\n// Electric DB Collection Errors\nexport class ElectricDBCollectionError extends TanStackDBError {\n  constructor(message: string, collectionId?: string) {\n    super(`${collectionId ? `[${collectionId}] ` : ``}${message}`)\n    this.name = `ElectricDBCollectionError`\n  }\n}\n\nexport class ExpectedNumberInAwaitTxIdError extends ElectricDBCollectionError {\n  constructor(txIdType: string, collectionId?: string) {\n    super(`Expected number in awaitTxId, received ${txIdType}`, collectionId)\n    this.name = `ExpectedNumberInAwaitTxIdError`\n  }\n}\n\nexport class TimeoutWaitingForTxIdError extends ElectricDBCollectionError {\n  constructor(txId: number, collectionId?: string) {\n    super(`Timeout waiting for txId: ${txId}`, collectionId)\n    this.name = `TimeoutWaitingForTxIdError`\n  }\n}\n\nexport class TimeoutWaitingForMatchError extends ElectricDBCollectionError {\n  constructor(collectionId?: string) {\n    super(`Timeout waiting for custom match function`, collectionId)\n    this.name = `TimeoutWaitingForMatchError`\n  }\n}\n\nexport class StreamAbortedError extends ElectricDBCollectionError {\n  constructor(collectionId?: string) {\n    super(`Stream aborted`, collectionId)\n    this.name = `StreamAbortedError`\n  }\n}\n", "/**\n * Serialize values for Electric SQL subset parameters.\n *\n * IMPORTANT: Electric expects RAW values, NOT SQL-formatted literals.\n * Electric handles all type casting and escaping on the server side.\n * The params Record<string, string> contains the actual values as strings,\n * and Electric will parse/cast them based on the column type in the WHERE clause.\n *\n * @param value - The value to serialize\n * @returns The raw value as a string (no SQL formatting/quoting)\n */\nexport function serialize(value: unknown): string {\n  // Handle null/undefined - return empty string\n  // Electric interprets empty string as NULL in typed column context\n  if (value === null || value === undefined) {\n    return ``\n  }\n\n  // Handle strings - return as-is (NO quotes, Electric handles escaping)\n  if (typeof value === `string`) {\n    return value\n  }\n\n  // Handle numbers - convert to string\n  if (typeof value === `number`) {\n    return value.toString()\n  }\n\n  // Handle booleans - return as lowercase string\n  if (typeof value === `boolean`) {\n    return value ? `true` : `false`\n  }\n\n  // Handle dates - return ISO format (NO quotes)\n  if (value instanceof Date) {\n    return value.toISOString()\n  }\n\n  // Handle arrays - for = ANY() operator, serialize as Postgres array literal\n  // Format: {val1,val2,val3} with proper escaping\n  if (Array.isArray(value)) {\n    // Postgres array literal format uses curly braces\n    const elements = value.map((item) => {\n      if (item === null || item === undefined) {\n        return `NULL`\n      }\n      if (typeof item === `string`) {\n        // Escape quotes and backslashes for Postgres array literals\n        const escaped = item.replace(/\\\\/g, `\\\\\\\\`).replace(/\"/g, `\\\\\"`)\n        return `\"${escaped}\"`\n      }\n      return serialize(item)\n    })\n    return `{${elements.join(`,`)}}`\n  }\n\n  throw new Error(`Cannot serialize value: ${JSON.stringify(value)}`)\n}\n", "import { serialize } from \"./pg-serializer\"\nimport type { SubsetParams } from \"@electric-sql/client\"\nimport type { IR, LoadSubsetOptions } from \"@tanstack/db\"\n\nexport type CompiledSqlRecord = Omit<SubsetParams, `params`> & {\n  params?: Array<unknown>\n}\n\nexport function compileSQL<T>(options: LoadSubsetOptions): SubsetParams {\n  const { where, orderBy, limit } = options\n\n  const params: Array<T> = []\n  const compiledSQL: CompiledSqlRecord = { params }\n\n  if (where) {\n    // TODO: this only works when the where expression's PropRefs directly reference a column of the collection\n    //       doesn't work if it goes through aliases because then we need to know the entire query to be able to follow the reference until the base collection (cf. followRef function)\n    compiledSQL.where = compileBasicExpression(where, params)\n  }\n\n  if (orderBy) {\n    compiledSQL.orderBy = compileOrderBy(orderBy, params)\n  }\n\n  if (limit) {\n    compiledSQL.limit = limit\n  }\n\n  // WORKAROUND for Electric bug: Empty subset requests don't load data\n  // Add dummy \"true = true\" predicate when there's no where clause\n  // This is always true so doesn't filter data, just tricks Electric into loading\n  if (!where) {\n    compiledSQL.where = `true = true`\n  }\n\n  // Serialize the values in the params array into PG formatted strings\n  // and transform the array into a Record<string, string>\n  const paramsRecord = params.reduce(\n    (acc, param, index) => {\n      const serialized = serialize(param)\n      // Only include non-empty values in params\n      // Empty strings from null/undefined should be omitted\n      if (serialized !== ``) {\n        acc[`${index + 1}`] = serialized\n      }\n      return acc\n    },\n    {} as Record<string, string>\n  )\n\n  return {\n    ...compiledSQL,\n    params: paramsRecord,\n  }\n}\n\n/**\n * Quote PostgreSQL identifiers to handle mixed case column names correctly.\n * Electric/Postgres requires quotes for case-sensitive identifiers.\n * @param name - The identifier to quote\n * @returns The quoted identifier\n */\nfunction quoteIdentifier(name: string): string {\n  return `\"${name}\"`\n}\n\n/**\n * Compiles the expression to a SQL string and mutates the params array with the values.\n * @param exp - The expression to compile\n * @param params - The params array\n * @returns The compiled SQL string\n */\nfunction compileBasicExpression(\n  exp: IR.BasicExpression<unknown>,\n  params: Array<unknown>\n): string {\n  switch (exp.type) {\n    case `val`:\n      params.push(exp.value)\n      return `$${params.length}`\n    case `ref`:\n      // TODO: doesn't yet support JSON(B) values which could be accessed with nested props\n      if (exp.path.length !== 1) {\n        throw new Error(\n          `Compiler can't handle nested properties: ${exp.path.join(`.`)}`\n        )\n      }\n      return quoteIdentifier(exp.path[0]!)\n    case `func`:\n      return compileFunction(exp, params)\n    default:\n      throw new Error(`Unknown expression type`)\n  }\n}\n\nfunction compileOrderBy(orderBy: IR.OrderBy, params: Array<unknown>): string {\n  const compiledOrderByClauses = orderBy.map((clause: IR.OrderByClause) =>\n    compileOrderByClause(clause, params)\n  )\n  return compiledOrderByClauses.join(`,`)\n}\n\nfunction compileOrderByClause(\n  clause: IR.OrderByClause,\n  params: Array<unknown>\n): string {\n  // FIXME: We should handle stringSort and locale.\n  //        Correctly supporting them is tricky as it depends on Postgres' collation\n  const { expression, compareOptions } = clause\n  let sql = compileBasicExpression(expression, params)\n\n  if (compareOptions.direction === `desc`) {\n    sql = `${sql} DESC`\n  }\n\n  if (compareOptions.nulls === `first`) {\n    sql = `${sql} NULLS FIRST`\n  }\n\n  if (compareOptions.nulls === `last`) {\n    sql = `${sql} NULLS LAST`\n  }\n\n  return sql\n}\n\nfunction compileFunction(\n  exp: IR.Func<unknown>,\n  params: Array<unknown> = []\n): string {\n  const { name, args } = exp\n\n  const opName = getOpName(name)\n\n  const compiledArgs = args.map((arg: IR.BasicExpression) =>\n    compileBasicExpression(arg, params)\n  )\n\n  // Special case for IS NULL / IS NOT NULL - these are postfix operators\n  if (name === `isNull` || name === `isUndefined`) {\n    if (compiledArgs.length !== 1) {\n      throw new Error(`${name} expects 1 argument`)\n    }\n    return `${compiledArgs[0]} ${opName}`\n  }\n\n  // Special case for NOT - unary prefix operator\n  if (name === `not`) {\n    if (compiledArgs.length !== 1) {\n      throw new Error(`NOT expects 1 argument`)\n    }\n    // Check if the argument is IS NULL to generate IS NOT NULL\n    const arg = args[0]\n    if (arg && arg.type === `func`) {\n      const funcArg = arg\n      if (funcArg.name === `isNull` || funcArg.name === `isUndefined`) {\n        const innerArg = compileBasicExpression(funcArg.args[0]!, params)\n        return `${innerArg} IS NOT NULL`\n      }\n    }\n    return `${opName} (${compiledArgs[0]})`\n  }\n\n  if (isBinaryOp(name)) {\n    // Special handling for AND/OR which can be variadic\n    if ((name === `and` || name === `or`) && compiledArgs.length > 2) {\n      // Chain multiple arguments: (a AND b AND c) or (a OR b OR c)\n      return compiledArgs.map((arg) => `(${arg})`).join(` ${opName} `)\n    }\n\n    if (compiledArgs.length !== 2) {\n      throw new Error(`Binary operator ${name} expects 2 arguments`)\n    }\n    const [lhs, rhs] = compiledArgs\n    // Special case for = ANY operator which needs parentheses around the array parameter\n    if (name === `in`) {\n      return `${lhs} ${opName}(${rhs})`\n    }\n    return `${lhs} ${opName} ${rhs}`\n  }\n\n  return `${opName}(${compiledArgs.join(`,`)})`\n}\n\nfunction isBinaryOp(name: string): boolean {\n  const binaryOps = [\n    `eq`,\n    `gt`,\n    `gte`,\n    `lt`,\n    `lte`,\n    `and`,\n    `or`,\n    `in`,\n    `like`,\n    `ilike`,\n  ]\n  return binaryOps.includes(name)\n}\n\nfunction getOpName(name: string): string {\n  const opNames = {\n    eq: `=`,\n    gt: `>`,\n    gte: `>=`,\n    lt: `<`,\n    lte: `<=`,\n    add: `+`,\n    and: `AND`,\n    or: `OR`,\n    not: `NOT`,\n    isUndefined: `IS NULL`,\n    isNull: `IS NULL`,\n    in: `= ANY`, // Use = ANY syntax for array parameters\n    like: `LIKE`,\n    ilike: `ILIKE`,\n    upper: `UPPER`,\n    lower: `LOWER`,\n    length: `LENGTH`,\n    concat: `CONCAT`,\n    coalesce: `COALESCE`,\n  }\n\n  const opName = opNames[name as keyof typeof opNames]\n\n  if (!opName) {\n    throw new Error(`Unknown operator/function: ${name}`)\n  }\n\n  return opName\n}\n", "import {\n  ShapeStream,\n  isChangeMessage,\n  isControlMessage,\n  isVisibleInSnapshot,\n} from \"@electric-sql/client\"\nimport { Store } from \"@tanstack/store\"\nimport DebugModule from \"debug\"\nimport { DeduplicatedLoadSubset } from \"@tanstack/db\"\nimport {\n  ExpectedNumberInAwaitTxIdError,\n  StreamAbortedError,\n  TimeoutWaitingForMatchError,\n  TimeoutWaitingForTxIdError,\n} from \"./errors\"\nimport { compileSQL } from \"./sql-compiler\"\nimport type {\n  BaseCollectionConfig,\n  CollectionConfig,\n  DeleteMutationFnParams,\n  InsertMutationFnParams,\n  LoadSubsetOptions,\n  SyncConfig,\n  SyncMode,\n  UpdateMutationFnParams,\n  UtilsRecord,\n} from \"@tanstack/db\"\nimport type { StandardSchemaV1 } from \"@standard-schema/spec\"\nimport type {\n  ControlMessage,\n  GetExtensions,\n  Message,\n  PostgresSnapshot,\n  Row,\n  ShapeStreamOptions,\n} from \"@electric-sql/client\"\n\n// Re-export for user convenience in custom match functions\nexport { isChangeMessage, isControlMessage } from \"@electric-sql/client\"\n\nconst debug = DebugModule.debug(`ts/db:electric`)\n\n/**\n * Symbol for internal test hooks (hidden from public API)\n */\nexport const ELECTRIC_TEST_HOOKS = Symbol(`electricTestHooks`)\n\n/**\n * Internal test hooks interface (for testing only)\n */\nexport interface ElectricTestHooks {\n  /**\n   * Called before marking collection ready after first up-to-date in progressive mode\n   * Allows tests to pause and validate snapshot phase before atomic swap completes\n   */\n  beforeMarkingReady?: () => Promise<void>\n}\n\n/**\n * Type representing a transaction ID in ElectricSQL\n */\nexport type Txid = number\n\n/**\n * Custom match function type - receives stream messages and returns boolean\n * indicating if the mutation has been synchronized\n */\nexport type MatchFunction<T extends Row<unknown>> = (\n  message: Message<T>\n) => boolean\n\n/**\n * Matching strategies for Electric synchronization\n * Handlers can return:\n * - Txid strategy: { txid: number | number[], timeout?: number } (recommended)\n * - Void (no return value) - mutation completes without waiting\n *\n * The optional timeout property specifies how long to wait for the txid(s) in milliseconds.\n * If not specified, defaults to 5000ms.\n */\nexport type MatchingStrategy = {\n  txid: Txid | Array<Txid>\n  timeout?: number\n} | void\n\n/**\n * Type representing a snapshot end message\n */\ntype SnapshotEndMessage = ControlMessage & {\n  headers: { control: `snapshot-end` }\n}\n// The `InferSchemaOutput` and `ResolveType` are copied from the `@tanstack/db` package\n// but we modified `InferSchemaOutput` slightly to restrict the schema output to `Row<unknown>`\n// This is needed in order for `GetExtensions` to be able to infer the parser extensions type from the schema\ntype InferSchemaOutput<T> = T extends StandardSchemaV1\n  ? StandardSchemaV1.InferOutput<T> extends Row<unknown>\n    ? StandardSchemaV1.InferOutput<T>\n    : Record<string, unknown>\n  : Record<string, unknown>\n\n/**\n * The mode of sync to use for the collection.\n * @default `eager`\n * @description\n * - `eager`:\n *   - syncs all data immediately on preload\n *   - collection will be marked as ready once the sync is complete\n *   - there is no incremental sync\n * - `on-demand`:\n *   - syncs data in incremental snapshots when the collection is queried\n *   - collection will be marked as ready immediately after the first snapshot is synced\n * - `progressive`:\n *   - syncs all data for the collection in the background\n *   - uses incremental snapshots during the initial sync to provide a fast path to the data required for queries\n *   - collection will be marked as ready once the full sync is complete\n */\nexport type ElectricSyncMode = SyncMode | `progressive`\n\n/**\n * Configuration interface for Electric collection options\n * @template T - The type of items in the collection\n * @template TSchema - The schema type for validation\n */\nexport interface ElectricCollectionConfig<\n  T extends Row<unknown> = Row<unknown>,\n  TSchema extends StandardSchemaV1 = never,\n> extends Omit<\n    BaseCollectionConfig<T, string | number, TSchema, UtilsRecord, any>,\n    `onInsert` | `onUpdate` | `onDelete` | `syncMode`\n  > {\n  /**\n   * Configuration options for the ElectricSQL ShapeStream\n   */\n  shapeOptions: ShapeStreamOptions<GetExtensions<T>>\n  syncMode?: ElectricSyncMode\n\n  /**\n   * Internal test hooks (for testing only)\n   * Hidden via Symbol to prevent accidental usage in production\n   */\n  [ELECTRIC_TEST_HOOKS]?: ElectricTestHooks\n\n  /**\n   * Optional asynchronous handler function called before an insert operation\n   * @param params Object containing transaction and collection information\n   * @returns Promise resolving to { txid, timeout? } or void\n   * @example\n   * // Basic Electric insert handler with txid (recommended)\n   * onInsert: async ({ transaction }) => {\n   *   const newItem = transaction.mutations[0].modified\n   *   const result = await api.todos.create({\n   *     data: newItem\n   *   })\n   *   return { txid: result.txid }\n   * }\n   *\n   * @example\n   * // Insert handler with custom timeout\n   * onInsert: async ({ transaction }) => {\n   *   const newItem = transaction.mutations[0].modified\n   *   const result = await api.todos.create({\n   *     data: newItem\n   *   })\n   *   return { txid: result.txid, timeout: 10000 } // Wait up to 10 seconds\n   * }\n   *\n   * @example\n   * // Insert handler with multiple items - return array of txids\n   * onInsert: async ({ transaction }) => {\n   *   const items = transaction.mutations.map(m => m.modified)\n   *   const results = await Promise.all(\n   *     items.map(item => api.todos.create({ data: item }))\n   *   )\n   *   return { txid: results.map(r => r.txid) }\n   * }\n   *\n   * @example\n   * // Use awaitMatch utility for custom matching\n   * onInsert: async ({ transaction, collection }) => {\n   *   const newItem = transaction.mutations[0].modified\n   *   await api.todos.create({ data: newItem })\n   *   await collection.utils.awaitMatch(\n   *     (message) => isChangeMessage(message) &&\n   *                  message.headers.operation === 'insert' &&\n   *                  message.value.name === newItem.name\n   *   )\n   * }\n   */\n  onInsert?: (params: InsertMutationFnParams<T>) => Promise<MatchingStrategy>\n\n  /**\n   * Optional asynchronous handler function called before an update operation\n   * @param params Object containing transaction and collection information\n   * @returns Promise resolving to { txid, timeout? } or void\n   * @example\n   * // Basic Electric update handler with txid (recommended)\n   * onUpdate: async ({ transaction }) => {\n   *   const { original, changes } = transaction.mutations[0]\n   *   const result = await api.todos.update({\n   *     where: { id: original.id },\n   *     data: changes\n   *   })\n   *   return { txid: result.txid }\n   * }\n   *\n   * @example\n   * // Use awaitMatch utility for custom matching\n   * onUpdate: async ({ transaction, collection }) => {\n   *   const { original, changes } = transaction.mutations[0]\n   *   await api.todos.update({ where: { id: original.id }, data: changes })\n   *   await collection.utils.awaitMatch(\n   *     (message) => isChangeMessage(message) &&\n   *                  message.headers.operation === 'update' &&\n   *                  message.value.id === original.id\n   *   )\n   * }\n   */\n  onUpdate?: (params: UpdateMutationFnParams<T>) => Promise<MatchingStrategy>\n\n  /**\n   * Optional asynchronous handler function called before a delete operation\n   * @param params Object containing transaction and collection information\n   * @returns Promise resolving to { txid, timeout? } or void\n   * @example\n   * // Basic Electric delete handler with txid (recommended)\n   * onDelete: async ({ transaction }) => {\n   *   const mutation = transaction.mutations[0]\n   *   const result = await api.todos.delete({\n   *     id: mutation.original.id\n   *   })\n   *   return { txid: result.txid }\n   * }\n   *\n   * @example\n   * // Use awaitMatch utility for custom matching\n   * onDelete: async ({ transaction, collection }) => {\n   *   const mutation = transaction.mutations[0]\n   *   await api.todos.delete({ id: mutation.original.id })\n   *   await collection.utils.awaitMatch(\n   *     (message) => isChangeMessage(message) &&\n   *                  message.headers.operation === 'delete' &&\n   *                  message.value.id === mutation.original.id\n   *   )\n   * }\n   */\n  onDelete?: (params: DeleteMutationFnParams<T>) => Promise<MatchingStrategy>\n}\n\nfunction isUpToDateMessage<T extends Row<unknown>>(\n  message: Message<T>\n): message is ControlMessage & { up_to_date: true } {\n  return isControlMessage(message) && message.headers.control === `up-to-date`\n}\n\nfunction isMustRefetchMessage<T extends Row<unknown>>(\n  message: Message<T>\n): message is ControlMessage & { headers: { control: `must-refetch` } } {\n  return isControlMessage(message) && message.headers.control === `must-refetch`\n}\n\nfunction isSnapshotEndMessage<T extends Row<unknown>>(\n  message: Message<T>\n): message is SnapshotEndMessage {\n  return isControlMessage(message) && message.headers.control === `snapshot-end`\n}\n\nfunction parseSnapshotMessage(message: SnapshotEndMessage): PostgresSnapshot {\n  return {\n    xmin: message.headers.xmin,\n    xmax: message.headers.xmax,\n    xip_list: message.headers.xip_list,\n  }\n}\n\n// Check if a message contains txids in its headers\nfunction hasTxids<T extends Row<unknown>>(\n  message: Message<T>\n): message is Message<T> & { headers: { txids?: Array<Txid> } } {\n  return `txids` in message.headers && Array.isArray(message.headers.txids)\n}\n\n/**\n * Creates a deduplicated loadSubset handler for progressive/on-demand modes\n * Returns null for eager mode, or a DeduplicatedLoadSubset instance for other modes.\n * Handles fetching snapshots in progressive mode during buffering phase,\n * and requesting snapshots in on-demand mode\n */\nfunction createLoadSubsetDedupe<T extends Row<unknown>>({\n  stream,\n  syncMode,\n  isBufferingInitialSync,\n  begin,\n  write,\n  commit,\n  collectionId,\n}: {\n  stream: ShapeStream<T>\n  syncMode: ElectricSyncMode\n  isBufferingInitialSync: () => boolean\n  begin: () => void\n  write: (mutation: {\n    type: `insert` | `update` | `delete`\n    value: T\n    metadata: Record<string, unknown>\n  }) => void\n  commit: () => void\n  collectionId?: string\n}): DeduplicatedLoadSubset | null {\n  // Eager mode doesn't need subset loading\n  if (syncMode === `eager`) {\n    return null\n  }\n\n  const loadSubset = async (opts: LoadSubsetOptions) => {\n    // In progressive mode, use fetchSnapshot during snapshot phase\n    if (isBufferingInitialSync()) {\n      // Progressive mode snapshot phase: fetch and apply immediately\n      const snapshotParams = compileSQL<T>(opts)\n      try {\n        const { data: rows } = await stream.fetchSnapshot(snapshotParams)\n\n        // Check again if we're still buffering - we might have received up-to-date\n        // and completed the atomic swap while waiting for the snapshot\n        if (!isBufferingInitialSync()) {\n          debug(\n            `${collectionId ? `[${collectionId}] ` : ``}Ignoring snapshot - sync completed while fetching`\n          )\n          return\n        }\n\n        // Apply snapshot data in a sync transaction (only if we have data)\n        if (rows.length > 0) {\n          begin()\n          for (const row of rows) {\n            write({\n              type: `insert`,\n              value: row.value,\n              metadata: {\n                ...row.headers,\n              },\n            })\n          }\n          commit()\n\n          debug(\n            `${collectionId ? `[${collectionId}] ` : ``}Applied snapshot with ${rows.length} rows`\n          )\n        }\n      } catch (error) {\n        debug(\n          `${collectionId ? `[${collectionId}] ` : ``}Error fetching snapshot: %o`,\n          error\n        )\n        throw error\n      }\n    } else if (syncMode === `progressive`) {\n      // Progressive mode after full sync complete: no need to load more\n      return\n    } else {\n      // On-demand mode: use requestSnapshot\n      const snapshotParams = compileSQL<T>(opts)\n      await stream.requestSnapshot(snapshotParams)\n    }\n  }\n\n  return new DeduplicatedLoadSubset({ loadSubset })\n}\n\n/**\n * Type for the awaitTxId utility function\n */\nexport type AwaitTxIdFn = (txId: Txid, timeout?: number) => Promise<boolean>\n\n/**\n * Type for the awaitMatch utility function\n */\nexport type AwaitMatchFn<T extends Row<unknown>> = (\n  matchFn: MatchFunction<T>,\n  timeout?: number\n) => Promise<boolean>\n\n/**\n * Electric collection utilities type\n */\nexport interface ElectricCollectionUtils<T extends Row<unknown> = Row<unknown>>\n  extends UtilsRecord {\n  awaitTxId: AwaitTxIdFn\n  awaitMatch: AwaitMatchFn<T>\n}\n\n/**\n * Creates Electric collection options for use with a standard Collection\n *\n * @template T - The explicit type of items in the collection (highest priority)\n * @template TSchema - The schema type for validation and type inference (second priority)\n * @template TFallback - The fallback type if no explicit or schema type is provided\n * @param config - Configuration options for the Electric collection\n * @returns Collection options with utilities\n */\n\n// Overload for when schema is provided\nexport function electricCollectionOptions<T extends StandardSchemaV1>(\n  config: ElectricCollectionConfig<InferSchemaOutput<T>, T> & {\n    schema: T\n  }\n): CollectionConfig<InferSchemaOutput<T>, string | number, T> & {\n  id?: string\n  utils: ElectricCollectionUtils\n  schema: T\n}\n\n// Overload for when no schema is provided\nexport function electricCollectionOptions<T extends Row<unknown>>(\n  config: ElectricCollectionConfig<T> & {\n    schema?: never // prohibit schema\n  }\n): CollectionConfig<T, string | number> & {\n  id?: string\n  utils: ElectricCollectionUtils\n  schema?: never // no schema in the result\n}\n\nexport function electricCollectionOptions(\n  config: ElectricCollectionConfig<any, any>\n): CollectionConfig<any, string | number, any> & {\n  id?: string\n  utils: ElectricCollectionUtils\n  schema?: any\n} {\n  const seenTxids = new Store<Set<Txid>>(new Set([]))\n  const seenSnapshots = new Store<Array<PostgresSnapshot>>([])\n  const internalSyncMode = config.syncMode ?? `eager`\n  const finalSyncMode =\n    internalSyncMode === `progressive` ? `on-demand` : internalSyncMode\n  const pendingMatches = new Store<\n    Map<\n      string,\n      {\n        matchFn: (message: Message<any>) => boolean\n        resolve: (value: boolean) => void\n        reject: (error: Error) => void\n        timeoutId: ReturnType<typeof setTimeout>\n        matched: boolean\n      }\n    >\n  >(new Map())\n\n  // Buffer messages since last up-to-date to handle race conditions\n  const currentBatchMessages = new Store<Array<Message<any>>>([])\n\n  /**\n   * Helper function to remove multiple matches from the pendingMatches store\n   */\n  const removePendingMatches = (matchIds: Array<string>) => {\n    if (matchIds.length > 0) {\n      pendingMatches.setState((current) => {\n        const newMatches = new Map(current)\n        matchIds.forEach((id) => newMatches.delete(id))\n        return newMatches\n      })\n    }\n  }\n\n  /**\n   * Helper function to resolve and cleanup matched pending matches\n   */\n  const resolveMatchedPendingMatches = () => {\n    const matchesToResolve: Array<string> = []\n    pendingMatches.state.forEach((match, matchId) => {\n      if (match.matched) {\n        clearTimeout(match.timeoutId)\n        match.resolve(true)\n        matchesToResolve.push(matchId)\n        debug(\n          `${config.id ? `[${config.id}] ` : ``}awaitMatch resolved on up-to-date for match %s`,\n          matchId\n        )\n      }\n    })\n    removePendingMatches(matchesToResolve)\n  }\n  const sync = createElectricSync<any>(config.shapeOptions, {\n    seenTxids,\n    seenSnapshots,\n    syncMode: internalSyncMode,\n    pendingMatches,\n    currentBatchMessages,\n    removePendingMatches,\n    resolveMatchedPendingMatches,\n    collectionId: config.id,\n    testHooks: config[ELECTRIC_TEST_HOOKS],\n  })\n\n  /**\n   * Wait for a specific transaction ID to be synced\n   * @param txId The transaction ID to wait for as a number\n   * @param timeout Optional timeout in milliseconds (defaults to 5000ms)\n   * @returns Promise that resolves when the txId is synced\n   */\n  const awaitTxId: AwaitTxIdFn = async (\n    txId: Txid,\n    timeout: number = 5000\n  ): Promise<boolean> => {\n    debug(\n      `${config.id ? `[${config.id}] ` : ``}awaitTxId called with txid %d`,\n      txId\n    )\n    if (typeof txId !== `number`) {\n      throw new ExpectedNumberInAwaitTxIdError(typeof txId, config.id)\n    }\n\n    // First check if the txid is in the seenTxids store\n    const hasTxid = seenTxids.state.has(txId)\n    if (hasTxid) return true\n\n    // Then check if the txid is in any of the seen snapshots\n    const hasSnapshot = seenSnapshots.state.some((snapshot) =>\n      isVisibleInSnapshot(txId, snapshot)\n    )\n    if (hasSnapshot) return true\n\n    return new Promise((resolve, reject) => {\n      const timeoutId = setTimeout(() => {\n        unsubscribeSeenTxids()\n        unsubscribeSeenSnapshots()\n        reject(new TimeoutWaitingForTxIdError(txId, config.id))\n      }, timeout)\n\n      const unsubscribeSeenTxids = seenTxids.subscribe(() => {\n        if (seenTxids.state.has(txId)) {\n          debug(\n            `${config.id ? `[${config.id}] ` : ``}awaitTxId found match for txid %o`,\n            txId\n          )\n          clearTimeout(timeoutId)\n          unsubscribeSeenTxids()\n          unsubscribeSeenSnapshots()\n          resolve(true)\n        }\n      })\n\n      const unsubscribeSeenSnapshots = seenSnapshots.subscribe(() => {\n        const visibleSnapshot = seenSnapshots.state.find((snapshot) =>\n          isVisibleInSnapshot(txId, snapshot)\n        )\n        if (visibleSnapshot) {\n          debug(\n            `${config.id ? `[${config.id}] ` : ``}awaitTxId found match for txid %o in snapshot %o`,\n            txId,\n            visibleSnapshot\n          )\n          clearTimeout(timeoutId)\n          unsubscribeSeenSnapshots()\n          unsubscribeSeenTxids()\n          resolve(true)\n        }\n      })\n    })\n  }\n\n  /**\n   * Wait for a custom match function to find a matching message\n   * @param matchFn Function that returns true when a message matches\n   * @param timeout Optional timeout in milliseconds (defaults to 5000ms)\n   * @returns Promise that resolves when a matching message is found\n   */\n  const awaitMatch: AwaitMatchFn<any> = async (\n    matchFn: MatchFunction<any>,\n    timeout: number = 3000\n  ): Promise<boolean> => {\n    debug(\n      `${config.id ? `[${config.id}] ` : ``}awaitMatch called with custom function`\n    )\n\n    return new Promise((resolve, reject) => {\n      const matchId = Math.random().toString(36)\n\n      const cleanupMatch = () => {\n        pendingMatches.setState((current) => {\n          const newMatches = new Map(current)\n          newMatches.delete(matchId)\n          return newMatches\n        })\n      }\n\n      const onTimeout = () => {\n        cleanupMatch()\n        reject(new TimeoutWaitingForMatchError(config.id))\n      }\n\n      const timeoutId = setTimeout(onTimeout, timeout)\n\n      // We need access to the stream messages to check against the match function\n      // This will be handled by the sync configuration\n      const checkMatch = (message: Message<any>) => {\n        if (matchFn(message)) {\n          debug(\n            `${config.id ? `[${config.id}] ` : ``}awaitMatch found matching message, waiting for up-to-date`\n          )\n          // Mark as matched but don't resolve yet - wait for up-to-date\n          pendingMatches.setState((current) => {\n            const newMatches = new Map(current)\n            const existing = newMatches.get(matchId)\n            if (existing) {\n              newMatches.set(matchId, { ...existing, matched: true })\n            }\n            return newMatches\n          })\n          return true\n        }\n        return false\n      }\n\n      // Check against current batch messages first to handle race conditions\n      for (const message of currentBatchMessages.state) {\n        if (matchFn(message)) {\n          debug(\n            `${config.id ? `[${config.id}] ` : ``}awaitMatch found immediate match in current batch, waiting for up-to-date`\n          )\n          // Register match as already matched\n          pendingMatches.setState((current) => {\n            const newMatches = new Map(current)\n            newMatches.set(matchId, {\n              matchFn: checkMatch,\n              resolve,\n              reject,\n              timeoutId,\n              matched: true, // Already matched\n            })\n            return newMatches\n          })\n          return\n        }\n      }\n\n      // Store the match function for the sync process to use\n      // We'll add this to a pending matches store\n      pendingMatches.setState((current) => {\n        const newMatches = new Map(current)\n        newMatches.set(matchId, {\n          matchFn: checkMatch,\n          resolve,\n          reject,\n          timeoutId,\n          matched: false,\n        })\n        return newMatches\n      })\n    })\n  }\n\n  /**\n   * Process matching strategy and wait for synchronization\n   */\n  const processMatchingStrategy = async (\n    result: MatchingStrategy\n  ): Promise<void> => {\n    // Only wait if result contains txid\n    if (result && `txid` in result) {\n      const timeout = result.timeout\n      // Handle both single txid and array of txids\n      if (Array.isArray(result.txid)) {\n        await Promise.all(result.txid.map((txid) => awaitTxId(txid, timeout)))\n      } else {\n        await awaitTxId(result.txid, timeout)\n      }\n    }\n    // If result is void/undefined, don't wait - mutation completes immediately\n  }\n\n  // Create wrapper handlers for direct persistence operations that handle different matching strategies\n  const wrappedOnInsert = config.onInsert\n    ? async (params: InsertMutationFnParams<any>) => {\n        const handlerResult = await config.onInsert!(params)\n        await processMatchingStrategy(handlerResult)\n        return handlerResult\n      }\n    : undefined\n\n  const wrappedOnUpdate = config.onUpdate\n    ? async (params: UpdateMutationFnParams<any>) => {\n        const handlerResult = await config.onUpdate!(params)\n        await processMatchingStrategy(handlerResult)\n        return handlerResult\n      }\n    : undefined\n\n  const wrappedOnDelete = config.onDelete\n    ? async (params: DeleteMutationFnParams<any>) => {\n        const handlerResult = await config.onDelete!(params)\n        await processMatchingStrategy(handlerResult)\n        return handlerResult\n      }\n    : undefined\n\n  // Extract standard Collection config properties\n  const {\n    shapeOptions: _shapeOptions,\n    onInsert: _onInsert,\n    onUpdate: _onUpdate,\n    onDelete: _onDelete,\n    ...restConfig\n  } = config\n\n  return {\n    ...restConfig,\n    syncMode: finalSyncMode,\n    sync,\n    onInsert: wrappedOnInsert,\n    onUpdate: wrappedOnUpdate,\n    onDelete: wrappedOnDelete,\n    utils: {\n      awaitTxId,\n      awaitMatch,\n    } as ElectricCollectionUtils<any>,\n  }\n}\n\n/**\n * Internal function to create ElectricSQL sync configuration\n */\nfunction createElectricSync<T extends Row<unknown>>(\n  shapeOptions: ShapeStreamOptions<GetExtensions<T>>,\n  options: {\n    syncMode: ElectricSyncMode\n    seenTxids: Store<Set<Txid>>\n    seenSnapshots: Store<Array<PostgresSnapshot>>\n    pendingMatches: Store<\n      Map<\n        string,\n        {\n          matchFn: (message: Message<T>) => boolean\n          resolve: (value: boolean) => void\n          reject: (error: Error) => void\n          timeoutId: ReturnType<typeof setTimeout>\n          matched: boolean\n        }\n      >\n    >\n    currentBatchMessages: Store<Array<Message<T>>>\n    removePendingMatches: (matchIds: Array<string>) => void\n    resolveMatchedPendingMatches: () => void\n    collectionId?: string\n    testHooks?: ElectricTestHooks\n  }\n): SyncConfig<T> {\n  const {\n    seenTxids,\n    seenSnapshots,\n    syncMode,\n    pendingMatches,\n    currentBatchMessages,\n    removePendingMatches,\n    resolveMatchedPendingMatches,\n    collectionId,\n    testHooks,\n  } = options\n  const MAX_BATCH_MESSAGES = 1000 // Safety limit for message buffer\n\n  // Store for the relation schema information\n  const relationSchema = new Store<string | undefined>(undefined)\n\n  /**\n   * Get the sync metadata for insert operations\n   * @returns Record containing relation information\n   */\n  const getSyncMetadata = (): Record<string, unknown> => {\n    // Use the stored schema if available, otherwise default to 'public'\n    const schema = relationSchema.state || `public`\n\n    return {\n      relation: shapeOptions.params?.table\n        ? [schema, shapeOptions.params.table]\n        : undefined,\n    }\n  }\n\n  let unsubscribeStream: () => void\n\n  return {\n    sync: (params: Parameters<SyncConfig<T>[`sync`]>[0]) => {\n      const { begin, write, commit, markReady, truncate, collection } = params\n\n      // Wrap markReady to wait for test hook in progressive mode\n      let progressiveReadyGate: Promise<void> | null = null\n      const wrappedMarkReady = (isBuffering: boolean) => {\n        // Only create gate if we're in buffering phase (first up-to-date)\n        if (\n          isBuffering &&\n          syncMode === `progressive` &&\n          testHooks?.beforeMarkingReady\n        ) {\n          // Create a new gate promise for this sync cycle\n          progressiveReadyGate = testHooks.beforeMarkingReady()\n          progressiveReadyGate.then(() => {\n            markReady()\n          })\n        } else {\n          // No hook, not buffering, or already past first up-to-date\n          markReady()\n        }\n      }\n\n      // Abort controller for the stream - wraps the signal if provided\n      const abortController = new AbortController()\n\n      if (shapeOptions.signal) {\n        shapeOptions.signal.addEventListener(\n          `abort`,\n          () => {\n            abortController.abort()\n          },\n          {\n            once: true,\n          }\n        )\n        if (shapeOptions.signal.aborted) {\n          abortController.abort()\n        }\n      }\n\n      // Cleanup pending matches on abort\n      abortController.signal.addEventListener(`abort`, () => {\n        pendingMatches.setState((current) => {\n          current.forEach((match) => {\n            clearTimeout(match.timeoutId)\n            match.reject(new StreamAbortedError())\n          })\n          return new Map() // Clear all pending matches\n        })\n      })\n\n      const stream = new ShapeStream({\n        ...shapeOptions,\n        // In on-demand mode, we only want to sync changes, so we set the log to `changes_only`\n        log: syncMode === `on-demand` ? `changes_only` : undefined,\n        // In on-demand mode, we only need the changes from the point of time the collection was created\n        // so we default to `now` when there is no saved offset.\n        offset:\n          shapeOptions.offset ?? (syncMode === `on-demand` ? `now` : undefined),\n        signal: abortController.signal,\n        onError: (errorParams) => {\n          // Just immediately mark ready if there's an error to avoid blocking\n          // apps waiting for `.preload()` to finish.\n          // Note that Electric sends a 409 error on a `must-refetch` message, but the\n          // ShapeStream handled this and it will not reach this handler, therefor\n          // this markReady will not be triggers by a `must-refetch`.\n          markReady()\n\n          if (shapeOptions.onError) {\n            return shapeOptions.onError(errorParams)\n          } else {\n            console.error(\n              `An error occurred while syncing collection: ${collection.id}, \\n` +\n                `it has been marked as ready to avoid blocking apps waiting for '.preload()' to finish. \\n` +\n                `You can provide an 'onError' handler on the shapeOptions to handle this error, and this message will not be logged.`,\n              errorParams\n            )\n          }\n\n          return\n        },\n      })\n      let transactionStarted = false\n      const newTxids = new Set<Txid>()\n      const newSnapshots: Array<PostgresSnapshot> = []\n      let hasReceivedUpToDate = false // Track if we've completed initial sync in progressive mode\n\n      // Progressive mode state\n      // Helper to determine if we're buffering the initial sync\n      const isBufferingInitialSync = () =>\n        syncMode === `progressive` && !hasReceivedUpToDate\n      const bufferedMessages: Array<Message<T>> = [] // Buffer change messages during initial sync\n\n      // Create deduplicated loadSubset wrapper for non-eager modes\n      // This prevents redundant snapshot requests when multiple concurrent\n      // live queries request overlapping or subset predicates\n      const loadSubsetDedupe = createLoadSubsetDedupe({\n        stream,\n        syncMode,\n        isBufferingInitialSync,\n        begin,\n        write,\n        commit,\n        collectionId,\n      })\n\n      unsubscribeStream = stream.subscribe((messages: Array<Message<T>>) => {\n        let hasUpToDate = false\n        let hasSnapshotEnd = false\n\n        for (const message of messages) {\n          // Add message to current batch buffer (for race condition handling)\n          if (isChangeMessage(message)) {\n            currentBatchMessages.setState((currentBuffer) => {\n              const newBuffer = [...currentBuffer, message]\n              // Limit buffer size for safety\n              if (newBuffer.length > MAX_BATCH_MESSAGES) {\n                newBuffer.splice(0, newBuffer.length - MAX_BATCH_MESSAGES)\n              }\n              return newBuffer\n            })\n          }\n\n          // Check for txids in the message and add them to our store\n          // Skip during buffered initial sync in progressive mode (txids will be extracted during atomic swap)\n          if (hasTxids(message) && !isBufferingInitialSync()) {\n            message.headers.txids?.forEach((txid) => newTxids.add(txid))\n          }\n\n          // Check pending matches against this message\n          // Note: matchFn will mark matches internally, we don't resolve here\n          const matchesToRemove: Array<string> = []\n          pendingMatches.state.forEach((match, matchId) => {\n            if (!match.matched) {\n              try {\n                match.matchFn(message)\n              } catch (err) {\n                // If matchFn throws, clean up and reject the promise\n                clearTimeout(match.timeoutId)\n                match.reject(\n                  err instanceof Error ? err : new Error(String(err))\n                )\n                matchesToRemove.push(matchId)\n                debug(`matchFn error: %o`, err)\n              }\n            }\n          })\n\n          // Remove matches that errored\n          removePendingMatches(matchesToRemove)\n\n          if (isChangeMessage(message)) {\n            // Check if the message contains schema information\n            const schema = message.headers.schema\n            if (schema && typeof schema === `string`) {\n              // Store the schema for future use if it's a valid string\n              relationSchema.setState(() => schema)\n            }\n\n            // In buffered initial sync of progressive mode, buffer messages instead of writing\n            if (isBufferingInitialSync()) {\n              bufferedMessages.push(message)\n            } else {\n              // Normal processing: write changes immediately\n              if (!transactionStarted) {\n                begin()\n                transactionStarted = true\n              }\n\n              write({\n                type: message.headers.operation,\n                value: message.value,\n                // Include the primary key and relation info in the metadata\n                metadata: {\n                  ...message.headers,\n                },\n              })\n            }\n          } else if (isSnapshotEndMessage(message)) {\n            // Skip snapshot-end tracking during buffered initial sync (will be extracted during atomic swap)\n            if (!isBufferingInitialSync()) {\n              newSnapshots.push(parseSnapshotMessage(message))\n            }\n            hasSnapshotEnd = true\n          } else if (isUpToDateMessage(message)) {\n            hasUpToDate = true\n          } else if (isMustRefetchMessage(message)) {\n            debug(\n              `${collectionId ? `[${collectionId}] ` : ``}Received must-refetch message, starting transaction with truncate`\n            )\n\n            // Start a transaction and truncate the collection\n            if (!transactionStarted) {\n              begin()\n              transactionStarted = true\n            }\n\n            truncate()\n\n            // Reset the loadSubset deduplication state since we're starting fresh\n            // This ensures that previously loaded predicates don't prevent refetching after truncate\n            loadSubsetDedupe?.reset()\n\n            // Reset flags so we continue accumulating changes until next up-to-date\n            hasUpToDate = false\n            hasSnapshotEnd = false\n            hasReceivedUpToDate = false // Reset for progressive mode (isBufferingInitialSync will reflect this)\n            bufferedMessages.length = 0 // Clear buffered messages\n          }\n        }\n\n        if (hasUpToDate || hasSnapshotEnd) {\n          // PROGRESSIVE MODE: Atomic swap on first up-to-date\n          if (isBufferingInitialSync() && hasUpToDate) {\n            debug(\n              `${collectionId ? `[${collectionId}] ` : ``}Progressive mode: Performing atomic swap with ${bufferedMessages.length} buffered messages`\n            )\n\n            // Start atomic swap transaction\n            begin()\n\n            // Truncate to clear all snapshot data\n            truncate()\n\n            // Apply all buffered change messages and extract txids/snapshots\n            for (const bufferedMsg of bufferedMessages) {\n              if (isChangeMessage(bufferedMsg)) {\n                write({\n                  type: bufferedMsg.headers.operation,\n                  value: bufferedMsg.value,\n                  metadata: {\n                    ...bufferedMsg.headers,\n                  },\n                })\n\n                // Extract txids from buffered messages (will be committed to store after transaction)\n                if (hasTxids(bufferedMsg)) {\n                  bufferedMsg.headers.txids?.forEach((txid) =>\n                    newTxids.add(txid)\n                  )\n                }\n              } else if (isSnapshotEndMessage(bufferedMsg)) {\n                // Extract snapshots from buffered messages (will be committed to store after transaction)\n                newSnapshots.push(parseSnapshotMessage(bufferedMsg))\n              }\n            }\n\n            // Commit the atomic swap\n            commit()\n\n            // Exit buffering phase by marking that we've received up-to-date\n            // isBufferingInitialSync() will now return false\n            bufferedMessages.length = 0\n\n            debug(\n              `${collectionId ? `[${collectionId}] ` : ``}Progressive mode: Atomic swap complete, now in normal sync mode`\n            )\n          } else {\n            // Normal mode or on-demand: commit transaction if one was started\n            if (transactionStarted) {\n              commit()\n              transactionStarted = false\n            }\n          }\n\n          // Clear the current batch buffer since we're now up-to-date\n          currentBatchMessages.setState(() => [])\n\n          if (hasUpToDate || (hasSnapshotEnd && syncMode === `on-demand`)) {\n            // Mark the collection as ready now that sync is up to date\n            wrappedMarkReady(isBufferingInitialSync())\n          }\n\n          // Track that we've received the first up-to-date for progressive mode\n          if (hasUpToDate) {\n            hasReceivedUpToDate = true\n          }\n\n          // Always commit txids when we receive up-to-date, regardless of transaction state\n          seenTxids.setState((currentTxids) => {\n            const clonedSeen = new Set<Txid>(currentTxids)\n            if (newTxids.size > 0) {\n              debug(\n                `${collectionId ? `[${collectionId}] ` : ``}new txids synced from pg %O`,\n                Array.from(newTxids)\n              )\n            }\n            newTxids.forEach((txid) => clonedSeen.add(txid))\n            newTxids.clear()\n            return clonedSeen\n          })\n\n          // Always commit snapshots when we receive up-to-date, regardless of transaction state\n          seenSnapshots.setState((currentSnapshots) => {\n            const seen = [...currentSnapshots, ...newSnapshots]\n            newSnapshots.forEach((snapshot) =>\n              debug(\n                `${collectionId ? `[${collectionId}] ` : ``}new snapshot synced from pg %o`,\n                snapshot\n              )\n            )\n            newSnapshots.length = 0\n            return seen\n          })\n\n          // Resolve all matched pending matches on up-to-date\n          resolveMatchedPendingMatches()\n        }\n      })\n\n      // Return the deduplicated loadSubset if available (on-demand or progressive mode)\n      // The loadSubset method is auto-bound, so it can be safely returned directly\n      return {\n        loadSubset: loadSubsetDedupe?.loadSubset,\n        cleanup: () => {\n          // Unsubscribe from the stream\n          unsubscribeStream()\n          // Abort the abort controller to stop the stream\n          abortController.abort()\n          // Reset deduplication tracking so collection can load fresh data if restarted\n          loadSubsetDedupe?.reset()\n        },\n      }\n    },\n    // Expose the getSyncMetadata function\n    getSyncMetadata,\n  }\n}\n"],
  "mappings": ";;;;;;;;;;;;AAqBA,eAAsB,SAAS,QAAoC,SAAkC;AACjG,QAAM,SAAS,OAAO,UAAS;AAC/B,MAAI;AACJ,SAAO,EAAE,SAAS,MAAM,OAAO,KAAI,GAAI,MAAM;AACzC,YAAQ,OAAO,KAAK;;AAE5B;AAeM,SAAU,SAAS,QAAuD;AAC5E,MAAI;AACJ,MAAI;AACJ,MAAI;AACJ,MAAI,yBAAyB;AAG7B,SAAO,SAAS,QAAQ,KAAe;AACnC,QAAI,WAAW,QAAW;AACtB,eAAS;AACT,iBAAW;AACX,oBAAc;WACX;AAEH,eAAS,OAAO,QAAQ,GAAG;;AAG/B,UAAM,YAAY,OAAO;AACzB,QAAI,YAAY;AAChB,WAAO,WAAW,WAAW;AACzB,UAAI,wBAAwB;AACxB,YAAI,OAAO,QAAQ,MAAC,IAA2B;AAC3C,sBAAY,EAAE;;AAGlB,iCAAyB;;AAI7B,UAAI,UAAU;AACd,aAAO,WAAW,aAAa,YAAY,IAAI,EAAE,UAAU;AACvD,gBAAQ,OAAO,QAAQ,GAAG;UACtB,KAAA;AACI,gBAAI,gBAAgB,IAAI;AACpB,4BAAc,WAAW;;AAE7B;UAEJ,KAAA;AACI,qCAAyB;UAC7B,KAAA;AACI,sBAAU;AACV;;;AAIZ,UAAI,YAAY,IAAI;AAGhB;;AAIJ,aAAO,OAAO,SAAS,WAAW,OAAO,GAAG,WAAW;AACvD,kBAAY;AACZ,oBAAc;;AAGlB,QAAI,cAAc,WAAW;AACzB,eAAS;eACF,cAAc,GAAG;AAGxB,eAAS,OAAO,SAAS,SAAS;AAClC,kBAAY;;EAEpB;AACJ;AASM,SAAU,YACZ,MACA,SACA,WAA6C;AAE7C,MAAI,UAAU,WAAU;AACxB,QAAM,UAAU,IAAI,YAAW;AAG/B,SAAO,SAAS,OAAO,MAAkB,aAAmB;AACxD,QAAI,KAAK,WAAW,GAAG;AAEnB,oBAAS,QAAT,cAAS,SAAA,SAAT,UAAY,OAAO;AACnB,gBAAU,WAAU;eACb,cAAc,GAAG;AAGxB,YAAM,QAAQ,QAAQ,OAAO,KAAK,SAAS,GAAG,WAAW,CAAC;AAC1D,YAAM,cAAc,eAAe,KAAK,cAAc,CAAC,MAAC,KAA0B,IAAI;AACtF,YAAM,QAAQ,QAAQ,OAAO,KAAK,SAAS,WAAW,CAAC;AAEvD,cAAQ,OAAO;QACX,KAAK;AAGD,kBAAQ,OAAO,QAAQ,OACjB,QAAQ,OAAO,OAAO,QACtB;AACN;QACJ,KAAK;AACD,kBAAQ,QAAQ;AAChB;QACJ,KAAK;AACD,eAAK,QAAQ,KAAK,KAAK;AACvB;QACJ,KAAK;AACD,gBAAM,QAAQ,SAAS,OAAO,EAAE;AAChC,cAAI,CAAC,MAAM,KAAK,GAAG;AACf,oBAAQ,QAAQ,QAAQ,KAAK;;AAEjC;;;EAGhB;AACJ;AAEA,SAAS,OAAO,GAAe,GAAa;AACxC,QAAM,MAAM,IAAI,WAAW,EAAE,SAAS,EAAE,MAAM;AAC9C,MAAI,IAAI,CAAC;AACT,MAAI,IAAI,GAAG,EAAE,MAAM;AACnB,SAAO;AACX;AAEA,SAAS,aAAU;AAKf,SAAO;IACH,MAAM;IACN,OAAO;IACP,IAAI;IACJ,OAAO;;AAEf;;;;;;;;;;;;;;ACpLO,IAAM,yBAAyB;AAEtC,IAAM,uBAAuB;AAC7B,IAAM,cAAc;AAkDd,SAAU,iBAAiB,OAAoB,IAU9B;MAV8B,EACjD,QAAQ,aACR,SAAS,cACT,QAAQ,aACR,WACA,SACA,SACA,gBACA,OAAO,WAAU,IAAA,IACd,OAAI,OAAA,IAT0C,CAAA,UAAA,WAAA,UAAA,aAAA,WAAA,WAAA,kBAAA,OAAA,CAUpD;AACG,SAAO,IAAI,QAAc,CAAC,SAAS,WAAU;AAEzC,UAAM,UAAO,OAAA,OAAA,CAAA,GAAQ,YAAY;AACjC,QAAI,CAAC,QAAQ,QAAQ;AACjB,cAAQ,SAAS;;AAGrB,QAAI;AACJ,aAAS,qBAAkB;AACvB,2BAAqB,MAAK;AAC1B,UAAI,CAAC,SAAS,QAAQ;AAClB,eAAM;;IAEd;AAEA,QAAI,CAAC,gBAAgB;AACjB,eAAS,iBAAiB,oBAAoB,kBAAkB;;AAGpE,QAAI,gBAAgB;AACpB,QAAI,aAAa;AACjB,aAAS,UAAO;AACZ,eAAS,oBAAoB,oBAAoB,kBAAkB;AACnE,aAAO,aAAa,UAAU;AAC9B,2BAAqB,MAAK;IAC9B;AAGA,oBAAW,QAAX,gBAAW,SAAA,SAAX,YAAa,iBAAiB,SAAS,MAAK;AACxC,cAAO;AACP,cAAO;IACX,CAAC;AAED,UAAMA,SAAQ,eAAU,QAAV,eAAU,SAAV,aAAc,OAAO;AACnC,UAAM,SAAS,gBAAW,QAAX,gBAAW,SAAX,cAAe;AAC9B,mBAAe,SAAM;;AACjB,6BAAuB,IAAI,gBAAe;AAC1C,UAAI;AACA,cAAM,WAAW,MAAMA,OAAM,OAAK,OAAA,OAAA,OAAA,OAAA,CAAA,GAC3B,IAAI,GAAA,EACP,SACA,QAAQ,qBAAqB,OAAM,CAAA,CAAA;AAGvC,cAAM,OAAO,QAAQ;AAErB,cAAM,SAAS,SAAS,MAAM,SAAS,YAAY,QAAK;AACpD,cAAI,IAAI;AAEJ,oBAAQ,WAAW,IAAI;iBACpB;AAEH,mBAAO,QAAQ,WAAW;;QAElC,GAAG,WAAQ;AACP,0BAAgB;QACpB,GAAG,SAAS,CAAC,CAAC;AAEd,oBAAO,QAAP,YAAO,SAAA,SAAP,QAAO;AACP,gBAAO;AACP,gBAAO;eACF,KAAK;AACV,YAAI,CAAC,qBAAqB,OAAO,SAAS;AAEtC,cAAI;AAEA,kBAAM,YAAgBC,MAAA,YAAO,QAAP,YAAO,SAAA,SAAP,QAAU,GAAG,OAAC,QAAAA,QAAA,SAAAA,MAAI;AACxC,mBAAO,aAAa,UAAU;AAC9B,yBAAa,OAAO,WAAW,QAAQ,QAAQ;mBAC1C,UAAU;AAEf,oBAAO;AACP,mBAAO,QAAQ;;;;IAI/B;AAEA,WAAM;EACV,CAAC;AACL;AAEA,SAAS,cAAc,UAAkB;AACrC,QAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AACvD,MAAI,EAAC,gBAAW,QAAX,gBAAW,SAAA,SAAX,YAAa,WAAW,sBAAsB,IAAG;AAClD,UAAM,IAAI,MAAM,+BAA+B,sBAAsB,aAAa,WAAW,EAAE;;AAEvG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzJO,IAAM,aAAN,MAAM,oBAAmB,MAAM;EAMpC,YACE,QACA,MACA,MACA,SACO,KACP,SACA;AACA;MACE,WACE,cAAc,MAAM,OAAO,GAAG,KAAK,QAAA,OAAA,OAAQ,KAAK,UAAU,IAAI,CAAC;IACnE;AANO,SAAA,MAAA;AAOP,SAAK,OAAO;AACZ,SAAK,SAAS;AACd,SAAK,OAAO;AACZ,SAAK,OAAO;AACZ,SAAK,UAAU;EACjB;EAEA,OAAa,aACX,UACA,KACqB;AAAA,WAAA,QAAA,MAAA,MAAA,aAAA;AACrB,YAAM,SAAS,SAAS;AACxB,YAAM,UAAU,OAAO,YAAY,CAAC,GAAG,SAAS,QAAQ,QAAQ,CAAC,CAAC;AAClE,UAAI,OAA2B;AAC/B,UAAI,OAA2B;AAE/B,YAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AACvD,UAAI,CAAC,SAAS,UAAU;AACtB,YAAI,eAAe,YAAY,SAAS,kBAAkB,GAAG;AAC3D,iBAAQ,MAAM,SAAS,KAAK;QAC9B,OAAO;AACL,iBAAO,MAAM,SAAS,KAAK;QAC7B;MACF;AAEA,aAAO,IAAI,YAAW,QAAQ,MAAM,MAAM,SAAS,GAAG;IACxD,CAAA;EAAA;AACF;AAEO,IAAM,yBAAN,cAAqC,MAAM;EAChD,cAAc;AACZ,UAAM,4BAA4B;AAClC,SAAK,OAAO;EACd;AACF;AASO,IAAM,uBAAN,cAAmC,MAAM;EAC9C,cAAc;AACZ,UAAM,uDAAuD;AAC7D,SAAK,OAAO;EACd;AACF;AAEO,IAAM,qBAAN,cAAiC,MAAM;EAC5C,cAAc;AACZ,UAAM,+DAA+D;AACrE,SAAK,OAAO;EACd;AACF;AAEO,IAAM,0BAAN,cAAsC,MAAM;EACjD,cAAc;AACZ;MACE;IACF;AACA,SAAK,OAAO;EACd;AACF;AAEO,IAAM,qBAAN,cAAiC,MAAM;EAC5C,YAAY,gBAA0B;AACpC;MACE,kEAAkE,eAAe,KAAK,IAAI,CAAC;IAC7F;AACA,SAAK,OAAO;EACd;AACF;AAEO,IAAM,uBAAN,cAAmC,MAAM;EAC9C,YAAY,YAAoB;AAC9B,UAAM,WAAW,cAAA,OAAA,aAAc,SAAS,8BAA8B;AACtE,SAAK,OAAO;EACd;AACF;AASO,IAAM,sBAAN,cAAkC,MAAM;EAC7C,YAAY,KAAa,gBAA+B;AACtD,QAAI,MAAM,yCAAyC,GAAG;;AACtD,mBAAe,QAAQ,CAAC,MAAM;AAC5B,aAAO,KAAK,CAAC;;IACf,CAAC;AACD,WAAO;;AACP,WAAO;;AACP,UAAM,GAAG;EACX;AACF;AC5FA,IAAM,cAAc,CAAC,UAAkB,OAAO,KAAK;AACnD,IAAM,YAAY,CAAC,UAAkB,UAAU,UAAU,UAAU;AACnE,IAAM,cAAc,CAAC,UAAkB,OAAO,KAAK;AACnD,IAAM,YAAY,CAAC,UAAkB,KAAK,MAAM,KAAK;AACrD,IAAM,iBAAgC,CAAC,MAAc;AAE9C,IAAM,gBAAwB;EACnC,MAAM;EACN,MAAM;EACN,MAAM;EACN,MAAM;EACN,QAAQ;EACR,QAAQ;EACR,MAAM;EACN,OAAO;AACT;AAGO,SAAS,cACd,OACA,QACmB;AACnB,MAAI,IAAI;AACR,MAAI,OAAO;AACX,MAAI,MAAM;AACV,MAAI,SAAS;AACb,MAAI,OAAO;AACX,MAAI,IAAwB;AAE5B,WAAS,aAAa,GAAU,OAAe,KAAa;AAC1D,QAAI,MAAoB,EAAE,MAAM,OAAO,GAAG;AAC1C,UAAM,QAAQ,SAAS,OAAO;AAC9B,WAAO,SAAS,OAAO,GAAG,IAAI;EAChC;AAEA,WAAS,KAAK,GAAqC;AACjD,UAAM,KAAK,CAAC;AACZ,WAAO,IAAI,EAAE,QAAQ,KAAK;AACxB,aAAO,EAAE,CAAC;AACV,UAAI,QAAQ;AACV,YAAI,SAAS,MAAM;AACjB,iBAAO,EAAE,EAAE,CAAC;QACd,WAAW,SAAS,KAAK;AACvB,aAAG,KAAK,SAAS,OAAO,GAAG,IAAI,GAAG;AAClC,gBAAM;AACN,mBAAS,EAAE,IAAI,CAAC,MAAM;AACtB,iBAAO,IAAI;QACb,OAAO;AACL,iBAAO;QACT;MACF,WAAW,SAAS,KAAK;AACvB,iBAAS;MACX,WAAW,SAAS,KAAK;AACvB,eAAO,EAAE;AACT,WAAG,KAAK,KAAK,CAAC,CAAC;MACjB,WAAW,SAAS,KAAK;AACvB,iBAAS;AACT,eAAO,KAAK,GAAG,KAAK,aAAa,GAAG,MAAM,CAAC,CAAC;AAC5C,eAAO,IAAI;AACX;MACF,WAAW,SAAS,OAAO,MAAM,OAAO,MAAM,KAAK;AACjD,WAAG,KAAK,aAAa,GAAG,MAAM,CAAC,CAAC;AAChC,eAAO,IAAI;MACb;AACA,UAAI;IACN;AACA,WAAO,KAAK,GAAG,KAAK,GAAG,KAAK,aAAa,GAAG,MAAM,IAAI,CAAC,CAAC,CAAC;AACzD,WAAO;EACT;AAEA,SAAO,KAAK,KAAK,EAAE,CAAC;AACtB;AAEO,IAAM,gBAAN,MAA4C;EAGjD,YACE,QACA,aACA;AAIA,SAAK,SAAS,eAAA,eAAA,CAAA,GAAK,aAAA,GAAkB,MAAA;AACrC,SAAK,cAAc;EACrB;EAEA,MAAc,UAAkB,QAAwB;AACtD,WAAO,KAAK,MAAM,UAAU,CAAC,KAAK,UAAU;AAM1C,WACG,QAAQ,WAAW,QAAQ,gBAC5B,OAAO,UAAU,YACjB,UAAU,MACV;AACA,eAAO,KAAK,sBAAsB,OAAO,MAAM;MACjD;AACA,aAAO;IACT,CAAC;EACH;;;;;EAMA,kBACE,UACA,QACe;AACf,WAAO,SAAS,IAAI,CAAC,YAAY;AAC/B,YAAM,MAAM;AAGZ,UAAI,IAAI,SAAS,OAAO,IAAI,UAAU,YAAY,IAAI,UAAU,MAAM;AACpE,YAAI,QAAQ,KAAK,sBAAsB,IAAI,OAAO,MAAM;MAC1D;AAGA,UACE,IAAI,aACJ,OAAO,IAAI,cAAc,YACzB,IAAI,cAAc,MAClB;AACA,YAAI,YAAY,KAAK,sBAAsB,IAAI,WAAW,MAAM;MAClE;AAEA,aAAO;IACT,CAAC;EACH;;;;EAKQ,sBACN,OACA,QACuB;AACvB,UAAM,MAAM;AACZ,WAAO,KAAK,GAAG,EAAE,QAAQ,CAAC,QAAQ;AAChC,UAAI,GAAG,IAAI,KAAK,SAAS,KAAK,IAAI,GAAG,GAAoB,MAAM;IACjE,CAAC;AAED,WAAO,KAAK,cAAc,KAAK,YAAY,GAAG,IAAI;EACpD;;EAGQ,SACN,KACA,OACA,QACyB;AAnL7B,QAAA;AAoLI,UAAM,aAAa,OAAO,GAAG;AAC7B,QAAI,CAAC,YAAY;AAGf,aAAO;IACT;AAGA,UAA2D,KAAA,YAAnD,EAAA,MAAM,KAAK,MAAM,WA5L7B,IA4L+D,IAAnB,iBAAA,UAAmB,IAAnB,CAAhC,QAAW,MAAA,CAAA;AAKnB,UAAM,cAAa,KAAA,KAAK,OAAO,GAAG,MAAf,OAAA,KAAoB;AACvC,UAAM,SAAS,mBAAmB,YAAY,YAAY,GAAG;AAE7D,QAAI,cAAc,aAAa,GAAG;AAEhC,YAAM,wBAAwB;QAC5B,CAACC,QAAO,MAAM,cAAcA,QAAO,MAAM;QACzC;QACA;MACF;AACA,aAAO,sBAAsB,KAAK;IACpC;AAEA,WAAO,OAAO,OAAO,cAAc;EACrC;AACF;AAEA,SAAS,mBACP,QACA,YACA,YACmC;AAtNrC,MAAA;AAuNE,QAAM,aAAa,GAAE,KAAA,WAAW,aAAX,OAAA,KAAuB;AAI5C,SAAO,CAAC,UAAyB;AAC/B,QAAI,UAAU,MAAM;AAClB,UAAI,CAAC,YAAY;AACf,cAAM,IAAI,qBAAqB,cAAA,OAAA,aAAc,SAAS;MACxD;AACA,aAAO;IACT;AACA,WAAO,OAAO,OAAO,UAAU;EACjC;AACF;AChEO,SAAS,kBACd,aACA,QACQ;AACR,MAAI,CAAC,eAAe,CAAC,OAAQ,QAAO,eAAA,OAAA,cAAe;AAGnD,QAAM,cAAc,oBAAI,IAAI;IAC1B;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF,CAAC;AAGD,QAAM,eAAsD,CAAC;AAG7D,MAAI,MAAM;AACV,SAAO,MAAM,YAAY,QAAQ;AAC/B,UAAM,KAAK,YAAY,GAAG;AAC1B,QAAI,OAAO,OAAO,OAAO,KAAK;AAC5B,YAAM,QAAQ;AACd,YAAM,YAAY;AAClB;AAEA,aAAO,MAAM,YAAY,QAAQ;AAC/B,YAAI,YAAY,GAAG,MAAM,WAAW;AAClC,cAAI,YAAY,MAAM,CAAC,MAAM,WAAW;AACtC,mBAAO;UACT,OAAO;AACL;AACA;UACF;QACF,OAAO;AACL;QACF;MACF;AACA,mBAAa,KAAK,EAAE,OAAO,KAAK,IAAI,CAAC;IACvC,OAAO;AACL;IACF;EACF;AAGA,QAAM,mBAAmB,CAACC,SAAyB;AACjD,WAAO,aAAa,KAAK,CAAC,UAAUA,QAAO,MAAM,SAASA,OAAM,MAAM,GAAG;EAC3E;AAUA,QAAM,oBACJ,IAAA,OAAC,6DAA0D,GAAC;AAE9D,SAAO,YAAY,QAAQ,mBAAmB,CAAC,OAAO,KAAK,WAAW;AAEpE,QAAI,iBAAiB,MAAM,GAAG;AAC5B,aAAO;IACT;AAGA,QAAI,YAAY,IAAI,MAAM,YAAY,CAAC,GAAG;AACxC,aAAO;IACT;AAIA,QAAI,MAAM,WAAW,GAAG,GAAG;AACzB,aAAO;IACT;AAGA,UAAM,UAAU,OAAO,KAAK;AAC5B,WAAO;EACT,CAAC;AACH;AClQO,SAAS,gBACd,SAC6B;AAC7B,SAAO,SAAS;AAClB;AAmBO,SAAS,iBACd,SAC2B;AAC3B,SAAO,CAAC,gBAAgB,OAAO;AACjC;AAEO,SAAS,kBACd,SACkD;AAClD,SAAO,iBAAiB,OAAO,KAAK,QAAQ,QAAQ,YAAY;AAClE;AAOO,SAAS,UAAU,SAA6C;AACrE,QAAM,MAAM,QAAQ,QAAQ;AAC5B,MAAI,CAAC,KAAK;AACR;EACF;AACA,SAAO,GAAG,GAAG;AACf;AASO,SAAS,oBACd,MACA,UACS;AACT,QAAM,MAAM,OAAO,IAAI;AACvB,QAAM,OAAO,OAAO,SAAS,IAAI;AACjC,QAAM,OAAO,OAAO,SAAS,IAAI;AACjC,QAAM,MAAM,SAAS,SAAS,IAAI,MAAM;AAQxC,SAAO,MAAM,QAAS,MAAM,QAAQ,CAAC,IAAI,SAAS,GAAG;AACvD;AClGO,IAAM,2BAA2B;AACjC,IAAM,sBAAsB;AAC5B,IAAM,2BAA2B;AACjC,IAAM,sBAAsB;AAC5B,IAAM,0BAA0B;AAChC,IAAM,sBAAsB;AAC5B,IAAM,gCAAgC;AACtC,IAAM,6BAA6B;AACnC,IAAM,2BAA2B;AACjC,IAAM,mBAAmB;AACzB,IAAM,qBAAqB;AAC3B,IAAM,oBAAoB;AAC1B,IAAM,oBAAoB;AAC1B,IAAM,gBAAgB;AACtB,IAAM,qBAAqB;AAI3B,IAAM,oCAAoC;AAC1C,IAAM,uBAAuB;AAC7B,IAAM,+BAA+B;AACrC,IAAM,eAAe;AACrB,IAAM,uBAAuB;AAC7B,IAAM,qBAAqB;AAC3B,IAAM,qBAAqB;AAC3B,IAAM,sBAAsB;AAC5B,IAAM,wBAAwB;AAC9B,IAAM,4BAA4B;AAGlC,IAAM,iCAAgD;EAC3D;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;AACF;ACtBA,IAAM,0BAA0B,CAAC,GAAG;AAuB7B,IAAM,kBAAkB;EAC7B,cAAc;EACd,UAAU;;EACV,YAAY;EACZ,YAAY;;AACd;AAOO,SAAS,sBAAsB,YAAwC;AAC5E,MAAI,CAAC,WAAY,QAAO;AAGxB,QAAM,gBAAgB,OAAO,UAAU;AACvC,MAAI,OAAO,SAAS,aAAa,KAAK,gBAAgB,GAAG;AACvD,WAAO,gBAAgB;EACzB;AAGA,QAAM,YAAY,KAAK,MAAM,UAAU;AACvC,MAAI,CAAC,MAAM,SAAS,GAAG;AAErB,UAAM,UAAU,YAAY,KAAK,IAAI;AACrC,WAAO,KAAK,IAAI,GAAG,KAAK,IAAI,SAAS,IAAQ,CAAC;EAChD;AAEA,SAAO;AACT;AAEO,SAAS,uBACd,aACA,iBAAiC,iBACnB;AACd,QAAM;IACJ;IACA;IACA;IACA,OAAAC,SAAQ;IACR;IACA,aAAa;EACf,IAAI;AACJ,SAAO,IAAU,SAAsD,QAAA,MAAA,MAAA,aAAA;AAxFzE,QAAA;AAyFI,UAAM,MAAM,KAAK,CAAC;AAClB,UAAM,UAAU,KAAK,CAAC;AAEtB,QAAI,QAAQ;AACZ,QAAI,UAAU;AAEd,WAAO,MAAM;AACX,UAAI;AACF,cAAM,SAAS,MAAM,YAAY,GAAG,IAAI;AACxC,YAAI,OAAO,IAAI;AACb,iBAAO;QACT;AAEA,cAAM,MAAM,MAAM,WAAW,aAAa,QAAQ,IAAI,SAAS,CAAC;AAEhE,cAAM;MACR,SAAS,GAAG;AACV,2BAAA,OAAA,SAAA,gBAAA;AACA,aAAI,KAAA,WAAA,OAAA,SAAA,QAAS,WAAT,OAAA,SAAA,GAAiB,SAAS;AAC5B,gBAAM,IAAI,uBAAuB;QACnC,WACE,aAAa,cACb,CAAC,wBAAwB,SAAS,EAAE,MAAM,KAC1C,EAAE,UAAU,OACZ,EAAE,SAAS,KACX;AAEA,gBAAM;QACR,OAAO;AAEL;AACA,cAAI,UAAU,YAAY;AACxB,gBAAIA,QAAO;AACT,sBAAQ;gBACN,wBAAwB,OAAO,IAAI,UAAU;cAC/C;YACF;AACA,kBAAM;UACR;AAMA,gBAAM,kBACJ,aAAa,cAAc,EAAE,UACzB,sBAAsB,EAAE,QAAQ,aAAa,CAAC,IAC9C;AAKN,gBAAM,SAAS,KAAK,OAAO,IAAI;AAC/B,gBAAM,kBAAkB,KAAK,IAAI,QAAQ,QAAQ;AAGjD,gBAAM,SAAS,KAAK,IAAI,iBAAiB,eAAe;AAExD,cAAIA,QAAO;AACT,kBAAM,SAAS,kBAAkB,IAAI,kBAAkB;AACvD,oBAAQ;cACN,kBAAkB,OAAO,UAAU,MAAM,OAAO,MAAM,eAAe,eAAe,qBAAqB,eAAe;YAC1H;UACF;AAGA,gBAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,MAAM,CAAC;AAG1D,kBAAQ,KAAK,IAAI,QAAQ,YAAY,QAAQ;QAC/C;MACF;IACF;EACF,CAAA;AACF;AAEA,IAAM,uBAAuB,CAAC,KAAK,KAAK,GAAG;AAGpC,SAAS,gCAAgC,aAA2B;AACzE,SAAO,IAAU,SAAsD,QAAA,MAAA,MAAA,aAAA;AAzKzE,QAAA,IAAA;AA0KI,UAAM,MAAM,KAAK,CAAC;AAClB,UAAM,MAAM,MAAM,YAAY,GAAG,IAAI;AACrC,QAAI;AACF,UAAI,IAAI,SAAS,OAAO,qBAAqB,SAAS,IAAI,MAAM,GAAG;AACjE,eAAO;MACT;AAEA,YAAM,OAAO,MAAM,IAAI,KAAK;AAC5B,aAAO,IAAI,SAAS,MAAM,GAAG;IAC/B,SAAS,KAAK;AACZ,WAAI,MAAA,KAAA,KAAK,CAAC,MAAN,OAAA,SAAA,GAAS,WAAT,OAAA,SAAA,GAAiB,SAAS;AAC5B,cAAM,IAAI,uBAAuB;MACnC;AAEA,YAAM,IAAI;QACR,IAAI;QACJ;QACA;QACA,OAAO,YAAY,CAAC,GAAG,IAAI,QAAQ,QAAQ,CAAC,CAAC;QAC7C,IAAI,SAAS;QACb,eAAe,QACX,IAAI,UACJ,OAAO,QAAQ,WACb,MACA;MACR;IACF;EACF,CAAA;AACF;AAMA,IAAM,wBAAwB;EAC5B,qBAAqB;AACvB;AAWO,SAAS,2BACd,aACA,kBAAwC,uBAC1B;AACd,QAAM,EAAE,oBAAoB,IAAI;AAEhC,MAAI;AAEJ,QAAM,iBAAiB,IAAU,SAAyC,QAAA,MAAA,MAAA,aAAA;AACxE,UAAM,MAAM,KAAK,CAAC,EAAE,SAAS;AAI7B,UAAM,oBAAoB,iBAAA,OAAA,SAAA,cAAe,QAAQ,GAAG,IAAA;AACpD,QAAI,mBAAmB;AACrB,aAAO;IACT;AAEA,qBAAA,OAAA,SAAA,cAAe,MAAA;AAGf,UAAM,WAAW,MAAM,YAAY,GAAG,IAAI;AAC1C,UAAM,UAAU,gBAAgB,KAAK,QAAQ;AAC7C,QAAI,SAAS;AACX,sBAAgB,IAAI,cAAc;QAChC;QACA,uBAAuB;QACvB,KAAK;QACL,aAAa,KAAK,CAAC;MACrB,CAAC;IACH;AAEA,WAAO;EACT,CAAA;AAEA,SAAO;AACT;AAEO,IAAM,kCAAkC;EAC7C;EACA;AACF;AAEO,IAAM,8BAA8B,CAAC,iBAAiB;AAEtD,IAAM,iCAAiC,CAAC,iBAAiB;AAEzD,SAAS,oCACd,aACc;AACd,SAAO,IAAU,SAAyC,QAAA,MAAA,MAAA,aAAA;AACxD,UAAM,WAAW,MAAM,YAAY,GAAG,IAAI;AAE1C,QAAI,SAAS,IAAI;AAEf,YAAM,UAAU,SAAS;AACzB,YAAM,iBAAgC,CAAC;AAEvC,YAAM,oBAAoB,CAAC,oBACzB,eAAe,KAAK,GAAG,gBAAgB,OAAO,CAAC,MAAM,CAAC,QAAQ,IAAI,CAAC,CAAC,CAAC;AAEvE,YAAM,QAAQ,KAAK,CAAC;AACpB,YAAM,YAAY,MAAM,SAAS;AACjC,YAAM,MAAM,IAAI,IAAI,SAAS;AAG7B,YAAM,oBAAoB;QACxB;QACA;QACA;QACA;QACA;MACF,EAAE,KAAK,CAAC,MAAM,IAAI,aAAa,IAAI,CAAC,CAAC;AACrC,UAAI,mBAAmB;AACrB,eAAO;MACT;AAEA,wBAAkB,+BAA+B;AACjD,UAAI,IAAI,aAAa,IAAI,gBAAgB,MAAM,QAAQ;AACrD,0BAAkB,2BAA2B;MAC/C;AAEA,UACE,CAAC,IAAI,aAAa,IAAI,gBAAgB,KACtC,IAAI,aAAa,IAAI,gBAAgB,MAAM,SAC3C;AACA,0BAAkB,8BAA8B;MAClD;AAEA,UAAI,eAAe,SAAS,GAAG;AAC7B,cAAM,IAAI,oBAAoB,WAAW,cAAc;MACzD;IACF;AAEA,WAAO;EACT,CAAA;AACF;AAzTA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AA2TA,IAAM,gBAAN,MAAoB;EAUlB,YAAY,SAKT;AAfL,iBAAA,MAAA,wBAAA;AACE,iBAAA,MAAS,YAAA;AACT,iBAAA,MAAS,sBAAA;AACT,iBAAA,MAAS,gBAAiB,oBAAI,IAG5B,CAAA;AACF,iBAAA,MAAA,aAAA;AACA,iBAAA,MAAA,aAAA;AAnUF,QAAA;AA2UI,iBAAA,MAAK,eACH,KAAA,QAAQ,gBAAR,OAAA,KACC,IAAI,SAAmC,MAAM,GAAG,IAAI,CAAA;AACvD,iBAAA,MAAK,wBAAyB,QAAQ,qBAAA;AACtC,iBAAA,MAAK,eAAgB,QAAQ,IAAI,SAAS,CAAA;AAC1C,iBAAA,MAAK,eAAgB,aAAA,MAAK,aAAA,CAAA;AAC1B,oBAAA,MAAK,0BAAA,WAAA,EAAL,KAAA,MAAe,QAAQ,KAAK,QAAQ,WAAA;EACtC;EAEA,QAAc;AACZ,iBAAA,MAAK,cAAA,EAAe,QAAQ,CAAC,CAAC,GAAG,OAAO,MAAM,QAAQ,MAAM,CAAC;EAC/D;EAEA,WAAW,MAA0D;AAxVvE,QAAA;AAyVI,UAAM,MAAM,KAAK,CAAC,EAAE,SAAS;AAE7B,UAAM,WAAU,KAAA,aAAA,MAAK,cAAA,EAAe,IAAI,GAAG,MAA3B,OAAA,SAAA,GAA+B,CAAA;AAI/C,QAAI,CAAC,WAAW,QAAQ,aAAA,MAAK,aAAA,EAAe;AAC5C,iBAAA,MAAK,cAAA,EAAe,OAAO,GAAG;AAG9B,YACG,KAAK,CAAC,aAAa;AAClB,YAAM,UAAU,gBAAgB,KAAK,QAAQ;AAC7C,mBAAA,MAAK,eAAgB,OAAA;AACrB,UACE,aAAA,MAAK,aAAA,KACL,CAAC,aAAA,MAAK,cAAA,EAAe,IAAI,aAAA,MAAK,aAAA,CAAa,GAC3C;AACA,wBAAA,MAAK,0BAAA,WAAA,EAAL,KAAA,MAAe,aAAA,MAAK,aAAA,GAAe,KAAK,CAAC,CAAA;MAC3C;IACF,CAAC,EACA,MAAM,MAAM;IAAC,CAAC;AAEjB,WAAO;EACT;AAsCF;AA3FW,eAAA,oBAAA,QAAA;AACA,yBAAA,oBAAA,QAAA;AACA,iBAAA,oBAAA,QAAA;AAIT,gBAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AARF,2BAAA,oBAAA,QAAA;AAwDE,cAAS,YAAI,MAAsC;AAnXrD,MAAA,IAAA;AAoXI,QAAM,MAAM,KAAK,CAAC,EAAE,SAAS;AAG7B,MAAI,aAAA,MAAK,cAAA,EAAe,QAAQ,aAAA,MAAK,sBAAA,EAAwB;AAI7D,QAAM,UAAU,IAAI,gBAAgB;AAEpC,MAAI;AACF,UAAM,EAAE,QAAQ,QAAQ,IAAI,aAAa,UAAS,KAAA,KAAK,CAAC,MAAN,OAAA,SAAA,GAAS,MAAM;AACjE,UAAM,UAAU,aAAA,MAAK,YAAA,EAAL,KAAA,MAAkB,KAAK,cAAA,eAAA,CAAA,IAAM,KAAA,KAAK,CAAC,MAAN,OAAA,KAAW,CAAC,CAAA,GAAlB,EAAsB,OAAO,CAAA,CAAA;AACpE,iBAAA,MAAK,cAAA,EAAe,IAAI,KAAK,CAAC,SAAS,OAAO,CAAC;AAC/C,YACG,KAAK,CAAC,aAAa;AAElB,UAAI,CAAC,SAAS,MAAM,QAAQ,OAAO,QAAS;AAE5C,YAAM,UAAU,gBAAgB,KAAK,QAAQ;AAG7C,UAAI,CAAC,WAAW,YAAY,KAAK;AAC/B,qBAAA,MAAK,eAAgB,MAAA;AACrB;MACF;AAEA,mBAAA,MAAK,eAAgB,OAAA;AACrB,aAAO,gBAAA,MAAK,0BAAA,WAAA,EAAL,KAAA,MAAe,SAAS,KAAK,CAAC,CAAA;IACvC,CAAC,EACA,MAAM,MAAM;IAAC,CAAC,EACd,QAAQ,OAAO;EACpB,SAAS,GAAG;EAEZ;AACF;AAMF,SAAS,gBAAgB,KAAa,KAA8B;AAClE,QAAM,cAAc,IAAI,QAAQ,IAAI,mBAAmB;AACvD,QAAM,aAAa,IAAI,QAAQ,IAAI,wBAAwB;AAC3D,QAAM,aAAa,IAAI,QAAQ,IAAI,uBAAuB;AAI1D,MAAI,CAAC,eAAe,CAAC,cAAc,WAAY;AAE/C,QAAM,UAAU,IAAI,IAAI,GAAG;AAI3B,MAAI,QAAQ,aAAa,IAAI,gBAAgB,EAAG;AAEhD,UAAQ,aAAa,IAAI,0BAA0B,WAAW;AAC9D,UAAQ,aAAa,IAAI,oBAAoB,UAAU;AACvD,UAAQ,aAAa,KAAK;AAC1B,SAAO,QAAQ,SAAS;AAC1B;AAOA,SAAS,aACP,SACA,cAIA;AACA,MAAI,UAAU;AACd,MAAI,CAAC,cAAc;EAEnB,WAAW,aAAa,SAAS;AAE/B,YAAQ,MAAM;EAChB,OAAO;AAGL,UAAM,cAAc,MAAM,QAAQ,MAAM;AACxC,iBAAa,iBAAiB,SAAS,aAAa;MAClD,MAAM;MACN,QAAQ,QAAQ;IAClB,CAAC;AACD,cAAU,MAAM,aAAa,oBAAoB,SAAS,WAAW;EACvE;AAEA,SAAO;IACL,QAAQ,QAAQ;IAChB;EACF;AACF;AAEA,SAAS,OAAO;AAAC;AE5cV,IAAM,qBAAN,MAAyB;EAoD9B,cAAc;AAnDd,SAAQ,OAA+C,CAAC;AACxD,SAAQ,MAAc;AACtB,SAAiB,aAAa;AAkD5B,SAAK,KAAK;EACZ;EAjDA,iBAAiB,UAAiC;AAChD,UAAM,QAAQ,KAAK,KAAK,QAAQ;AAChC,QAAI,OAAO;AAET,YAAM,WAAW,KAAK,IAAI;AAC1B,WAAK,KAAK;AACV,aAAO,MAAM;IACf;AACA,WAAO;EACT;EAEA,YAAY,UAAkB,QAAsB;AAClD,SAAK,KAAK,QAAQ,IAAI,EAAE,eAAe,QAAQ,UAAU,KAAK,IAAI,EAAE;AAEpE,UAAM,OAAO,OAAO,KAAK,KAAK,IAAI;AAClC,QAAI,KAAK,SAAS,KAAK,KAAK;AAC1B,YAAM,SAAS,KAAK;QAAO,CAAC,KAAK,MAC/B,KAAK,KAAK,CAAC,EAAE,WAAW,KAAK,KAAK,GAAG,EAAE,WAAW,IAAI;MACxD;AACA,aAAO,KAAK,KAAK,MAAM;IACzB;AAEA,SAAK,KAAK;EACZ;EAEQ,OAAa;AACnB,QAAI,OAAO,iBAAiB,YAAa;AACzC,QAAI;AACF,mBAAa,QAAQ,KAAK,YAAY,KAAK,UAAU,KAAK,IAAI,CAAC;IACjE,SAAQ,GAAA;IAER;EACF;EAEQ,OAAa;AACnB,QAAI,OAAO,iBAAiB,YAAa;AACzC,QAAI;AACF,YAAM,SAAS,aAAa,QAAQ,KAAK,UAAU;AACnD,UAAI,QAAQ;AACV,aAAK,OAAO,KAAK,MAAM,MAAM;MAC/B;IACF,SAAQ,GAAA;AAEN,WAAK,OAAO,CAAC;IACf;EACF;EAMA,QAAc;AACZ,SAAK,OAAO,CAAC;AACb,SAAK,KAAK;EACZ;AACF;AAGO,IAAM,qBAAqB,IAAI,mBAAmB;ACvDlD,IAAM,kBAAN,MAAsB;EAS3B,cAAc;AARd,SAAQ,OAAsC,CAAC;AAC/C,SAAiB,aAAa;AAC9B,SAAiB,WAAW;AAC5B,SAAiB,aAAa;AAC9B,SAAiB,kBAAkB;AACnC,SAAQ,gBAAgB;AAItB,SAAK,KAAK;AACV,SAAK,QAAQ;EACf;;;;;;EAOA,eAAe,UAAkB,QAAsB;AACrD,SAAK,KAAK,QAAQ,IAAI;MACpB,WAAW,KAAK,IAAI;MACpB;IACF;AAGA,UAAM,OAAO,OAAO,KAAK,KAAK,IAAI;AAClC,QAAI,KAAK,SAAS,KAAK,YAAY;AACjC,YAAM,SAAS,KAAK;QAAO,CAAC,KAAK,MAC/B,KAAK,KAAK,CAAC,EAAE,YAAY,KAAK,KAAK,GAAG,EAAE,YAAY,IAAI;MAC1D;AACA,aAAO,KAAK,KAAK,MAAM;IACzB;AAEA,SAAK,aAAa;EACpB;;;;;EAMQ,eAAqB;AAC3B,UAAM,MAAM,KAAK,IAAI;AACrB,UAAM,qBAAqB,MAAM,KAAK;AAEtC,QAAI,sBAAsB,KAAK,iBAAiB;AAE9C,WAAK,gBAAgB;AACrB,WAAK,KAAK;IACZ,WAAW,CAAC,KAAK,kBAAkB;AAEjC,YAAM,QAAQ,KAAK,kBAAkB;AACrC,WAAK,mBAAmB,WAAW,MAAM;AACvC,aAAK,gBAAgB,KAAK,IAAI;AAC9B,aAAK,mBAAmB;AACxB,aAAK,KAAK;MACZ,GAAG,KAAK;IACV;EAEF;;;;;;;EAQA,sBAAsB,UAAiC;AACrD,UAAM,QAAQ,KAAK,KAAK,QAAQ;AAChC,QAAI,CAAC,OAAO;AACV,aAAO;IACT;AAEA,UAAM,MAAM,KAAK,IAAI,IAAI,MAAM;AAC/B,QAAI,OAAO,KAAK,UAAU;AACxB,aAAO;IACT;AAEA,WAAO,MAAM;EACf;;;;;EAMQ,UAAgB;AACtB,UAAM,MAAM,KAAK,IAAI;AACrB,UAAM,OAAO,OAAO,KAAK,KAAK,IAAI;AAClC,QAAI,WAAW;AAEf,eAAW,OAAO,MAAM;AACtB,YAAM,MAAM,MAAM,KAAK,KAAK,GAAG,EAAE;AACjC,UAAI,MAAM,KAAK,UAAU;AACvB,eAAO,KAAK,KAAK,GAAG;AACpB,mBAAW;MACb;IACF;AAEA,QAAI,UAAU;AACZ,WAAK,KAAK;IACZ;EACF;EAEQ,OAAa;AACnB,QAAI,OAAO,iBAAiB,YAAa;AACzC,QAAI;AACF,mBAAa,QAAQ,KAAK,YAAY,KAAK,UAAU,KAAK,IAAI,CAAC;IACjE,SAAQ,GAAA;IAER;EACF;EAEQ,OAAa;AACnB,QAAI,OAAO,iBAAiB,YAAa;AACzC,QAAI;AACF,YAAM,SAAS,aAAa,QAAQ,KAAK,UAAU;AACnD,UAAI,QAAQ;AACV,aAAK,OAAO,KAAK,MAAM,MAAM;MAC/B;IACF,SAAQ,GAAA;AAEN,WAAK,OAAO,CAAC;IACf;EACF;;;;;EAMA,QAAc;AACZ,SAAK,OAAO,CAAC;AACb,QAAI,KAAK,kBAAkB;AACzB,mBAAa,KAAK,gBAAgB;AAClC,WAAK,mBAAmB;IAC1B;AACA,SAAK,KAAK;EACZ;AACF;AAGO,IAAM,kBAAkB,IAAI,gBAAgB;AC7I5C,IAAM,kBAAN,MAAsB;EAAtB,cAAA;AACL,SAAQ,kBAGJ,oBAAI,IAAI;AACZ,SAAQ,gBAA0C,oBAAI,IAAI;AAC1D,SAAQ,yBAAmD,oBAAI,IAAI;EAAA;;;;EAKnE,YAAY,UAA4B,MAAyB;AA1BnE,QAAA,IAAA,IAAA,IAAA;AA2BI,SAAK,gBAAgB,IAAI,SAAS,eAAe;MAC/C,MAAM,OAAO,SAAS,IAAI;MAC1B,MAAM,OAAO,SAAS,IAAI;MAC1B,UAAU,SAAS,SAAS,IAAI,MAAM;MACtC;IACF,CAAC;AACD,UAAM,WACJ,MAAA,KAAA,KAAK,cACF,IAAI,OAAO,SAAS,IAAI,CAAC,MAD5B,OAAA,SAAA,GAEI,IAAI,SAAS,aAAA,MAFjB,OAAA,KAEmC,oBAAI,IAAI,CAAC,SAAS,aAAa,CAAC;AACrE,SAAK,cAAc,IAAI,OAAO,SAAS,IAAI,GAAG,OAAO;AACrD,UAAM,kBACJ,MAAA,KAAA,KAAK,uBACF,IAAI,OAAO,SAAS,YAAY,CAAC,MADpC,OAAA,SAAA,GAEI,IAAI,SAAS,aAAA,MAFjB,OAAA,KAEmC,oBAAI,IAAI,CAAC,SAAS,aAAa,CAAC;AACrE,SAAK,uBAAuB;MAC1B,OAAO,SAAS,YAAY;MAC5B;IACF;EACF;;;;EAKA,eAAe,cAA4B;AACzC,SAAK,gBAAgB,OAAO,YAAY;EAC1C;;;;;EAMA,oBAAoB,SAA+C;AACjE,UAAM,QAAQ,QAAQ,QAAQ,SAAS,CAAC;AACxC,QAAI,MAAM,WAAW,EAAG,QAAO;AAE/B,UAAM,MAAM,KAAK,IAAI,GAAG,KAAK;AAE7B,eAAW,CAAC,MAAM,SAAS,KAAK,KAAK,cAAc,QAAQ,GAAG;AAC5D,UAAI,OAAO,MAAM;AACf,mBAAW,YAAY,WAAW;AAChC,eAAK,eAAe,QAAQ;QAC9B;MACF;IACF;AAEA,WAAO,CAAC,GAAG,KAAK,gBAAgB,OAAO,CAAC,EAAE;MACxC,CAAC,MAAM,EAAE,KAAK,IAAI,QAAQ,GAAG,KAAK,oBAAoB,KAAK,CAAC;IAC9D;EACF;EAEA,eAAe,gBAA8B;AAC3C,eAAW,CAAC,OAAO,SAAS,KAAK,KAAK,uBAAuB,QAAQ,GAAG;AACtE,UAAI,SAAS,gBAAgB;AAC3B,mBAAW,YAAY,WAAW;AAChC,eAAK,eAAe,QAAQ;QAC9B;MACF;IACF;EACF;AACF;AHtBA,IAAM,kBAA0C,oBAAI,IAAI;EACtD;EACA;EACA;EACA;AACF,CAAC;AAgGD,SAAsB,aACpB,OACY;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AACZ,QAAI,OAAO,UAAU,YAAY;AAC/B,aAAQ,MAA+B;IACzC;AACA,WAAO;EACT,CAAA;AAAA;AAKA,SAAe,iBACb,QAC+B;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAC/B,UAAM,UAAU,OAAO,QAAQ,MAAM;AACrC,UAAM,kBAAkB,MAAM,QAAQ;MACpC,QAAQ,IAAI,CAAO,OAAiB,QAAA,MAAA,CAAjB,EAAA,GAAiB,WAAjB,CAAC,KAAK,KAAK,GAAM;AAClC,YAAI,UAAU,OAAW,QAAO,CAAC,KAAK,MAAS;AAC/C,cAAM,gBAAgB,MAAM,aAAa,KAAK;AAC9C,eAAO;UACL;UACA,MAAM,QAAQ,aAAa,IAAI,cAAc,KAAK,GAAG,IAAI;QAC3D;MACF,CAAA,CAAC;IACH;AAEA,WAAO,OAAO;MACZ,gBAAgB,OAAO,CAAC,CAAC,GAAG,KAAK,MAAM,UAAU,MAAS;IAC5D;EACF,CAAA;AAAA;AAKA,SAAe,eACb,SACiC;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AACjC,QAAI,CAAC,QAAS,QAAO,CAAC;AAEtB,UAAM,UAAU,OAAO,QAAQ,OAAO;AACtC,UAAM,kBAAkB,MAAM,QAAQ;MACpC,QAAQ,IAAI,CAAO,OAAc,QAAA,MAAA,CAAd,EAAA,GAAc,WAAd,CAAC,KAAK,KAAK,GAAG;AAAG,eAAA,CAAC,KAAK,MAAM,aAAa,KAAK,CAAC;MAAA,CAAA,CAAC;IACtE;AAEA,WAAO,OAAO,YAAY,eAAe;EAC3C,CAAA;AAAA;AA8PA,SAAS,kBAAkB,KAAkB;AAC3C,QAAM,WAAW,IAAI,IAAI,IAAI,SAAS,IAAI,QAAQ;AAGlD,aAAW,CAAC,KAAK,KAAK,KAAK,IAAI,cAAc;AAC3C,QAAI,CAAC,+BAA+B,SAAS,GAAG,GAAG;AACjD,eAAS,aAAa,IAAI,KAAK,KAAK;IACtC;EACF;AAEA,WAAS,aAAa,KAAK;AAC3B,SAAO,SAAS,SAAS;AAC3B;AA9dA,IAAA;AAAA,IAAAC;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAwgBO,IAAM,cAAN,MAEP;EA2DE,YAAY,SAA+C;AA7DtD,iBAAA,MAAA,sBAAA;AASL,iBAAA,MAAA,QAAkB,IAAA;AAElB,iBAAA,MAASA,aAAAA;AACT,iBAAA,MAAS,eAAA;AACT,iBAAA,MAAS,cAAA;AAET,iBAAA,MAAS,cAAe,oBAAI,IAM1B,CAAA;AAEF,iBAAA,MAAA,UAAW,KAAA;AACX,iBAAA,MAAA,QAAS,QAAA;AACT,iBAAA,MAAA,WAAA;AACA,iBAAA,MAAA,gBAAA;AACA,iBAAA,MAAA,aAAA;AACA,iBAAA,MAAA,aAAuB,KAAA;AACvB,iBAAA,MAAA,cAAwB,IAAA;AACxB,iBAAA,MAAA,YAAsB,KAAA;AACtB,iBAAA,MAAA,YAAA;AACA,iBAAA,MAAA,KAAA;AACA,iBAAA,MAAA,OAAA;AACA,iBAAA,MAAA,QAAA;AACA,iBAAA,MAAA,uBAAA;AACA,iBAAA,MAAA,eAAgB,KAAA;AAChB,iBAAA,MAAA,YAAA;AACA,iBAAA,MAAA,oBAAA;AACA,iBAAA,MAAA,oBAAA;AACA,iBAAA,MAAA,eAAgB,QAAQ,QAAgB,CAAC,CAAC,CAAA;AAC1C,iBAAA,MAAA,kBAAmB,IAAI,gBAAgB,CAAA;AACvC,iBAAA,MAAA,yBAA0B,CAAA;AAC1B,iBAAA,MAAA,iBAAA;AACA,iBAAA,MAAA,yBAAA;AACA,iBAAA,MAAA,eAAA;AACA,iBAAA,MAAA,gBAAA;AACA,iBAAA,MAAA,2BAAA;AACA,iBAAA,MAAA,2BAA4B,GAAA;AAC5B,iBAAA,MAAA,iCAAkC,CAAA;AAClC,iBAAA,MAAA,yBAA0B,CAAA;AAC1B,iBAAA,MAAA,2BAA4B,KAAA;AAC5B,iBAAA,MAAA,sBAAuB,GAAA;AACvB,iBAAA,MAAA,qBAAsB,GAAA;AACtB,iBAAA,MAAA,iCAAA;AA9jBF,QAAA,IAAA,IAAA,IAAA;AAskBI,SAAK,UAAU,eAAA,EAAE,WAAW,KAAA,GAAS,OAAA;AACrC,oBAAgB,KAAK,OAAO;AAC5B,iBAAA,MAAK,cAAc,KAAA,KAAK,QAAQ,WAAb,OAAA,KAAuB,IAAA;AAC1C,iBAAA,MAAK,kBAAmB,EAAA;AACxB,iBAAA,MAAK,cAAe,KAAK,QAAQ,MAAA;AAIjC,QAAI;AAEJ,QAAI,QAAQ,cAAc;AACxB,YAAM,oBAAoB,CACxB,QAC0B;AAC1B,cAAM,SAAkC,CAAC;AACzC,mBAAW,CAAC,OAAO,KAAK,KAAK,OAAO,QAAQ,GAAG,GAAG;AAChD,gBAAM,SAAS,QAAQ,aAAc,OAAO,KAAK;AACjD,iBAAO,MAAM,IAAI;QACnB;AACA,eAAO;MACT;AAEA,oBAAc,QAAQ,cAClB,CAAC,QACC,QAAQ,YAAa,kBAAkB,GAAG,CAAC,IAC7C;IACN,OAAO;AACL,oBAAc,QAAQ;IACxB;AAEA,iBAAA,MAAK,gBAAiB,IAAI,cAAiB,QAAQ,QAAQ,WAAW,CAAA;AAEtE,iBAAA,MAAK,UAAW,KAAK,QAAQ,OAAA;AAC7B,iBAAA,MAAK,QAAQ,KAAA,KAAK,QAAQ,QAAb,OAAA,KAAoB,MAAA;AAEjC,UAAM,mBACJ,KAAA,QAAQ,gBAAR,OAAA,KACC,IAAI,SAAmC,MAAM,GAAG,IAAI;AAEvD,UAAM,cAAc,cAAA,eAAA,CAAA,IACd,KAAA,QAAQ,mBAAR,OAAA,KAA0B,eAAA,GADZ;MAElB,iBAAiB,MAAM;AA/mB7B,YAAAC,KAAAC;AAgnBQ,qBAAA,MAAK,YAAa,KAAA;AAClB,SAAAA,OAAAD,MAAA,QAAQ,mBAAR,OAAA,SAAAA,IAAwB,oBAAxB,OAAA,SAAAC,IAAA,KAAAD,GAAAA;MACF;IACF,CAAA;AACA,UAAM,yBAAyB;MAC7B;MACA;IACF;AAEA,iBAAA,MAAK,iBAAkB;MACrB,2BAA2B,sBAAsB;IACnD,CAAA;AAEA,iBAAA,MAAKD,eAAe,gCAAgC,aAAA,MAAK,eAAA,CAAe,CAAA;AAExE,oBAAA,MAAK,wBAAA,+BAAA,EAAL,KAAA,IAAA;EACF;EAEA,IAAI,cAAc;AAChB,WAAO,aAAA,MAAK,YAAA;EACd;EAEA,IAAI,QAAQ;AACV,WAAO,aAAA,MAAK,MAAA;EACd;EAEA,IAAI,aAAa;AACf,WAAO,aAAA,MAAK,WAAA;EACd;EAEA,IAAI,aAAa;AACf,WAAO,aAAA,MAAK,WAAA;EACd;EAEA,IAAI,OAAO;AACT,WAAO,aAAA,MAAK,KAAA;EACd;EAqkBA,UACE,UACA,UAAkC,MAAM;EAAC,GACzC;AACA,UAAM,iBAAiB,KAAK,OAAO;AAEnC,iBAAA,MAAK,YAAA,EAAa,IAAI,gBAAgB,CAAC,UAAU,OAAO,CAAC;AACzD,QAAI,CAAC,aAAA,MAAK,QAAA,EAAU,iBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;AAEpB,WAAO,MAAM;AACX,mBAAA,MAAK,YAAA,EAAa,OAAO,cAAc;IACzC;EACF;EAEA,iBAAuB;AAvuCzB,QAAA;AAwuCI,iBAAA,MAAK,YAAA,EAAa,MAAM;AACxB,KAAA,KAAA,aAAA,MAAK,iCAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;EACF;;EAGA,eAAmC;AACjC,WAAO,aAAA,MAAK,aAAA;EACd;;EAGA,aAAqB;AACnB,QAAI,aAAA,MAAK,aAAA,MAAkB,OAAW,QAAO;AAC7C,WAAO,KAAK,IAAI,IAAI,aAAA,MAAK,aAAA;EAC3B;;EAGA,cAAuB;AACrB,WAAO,aAAA,MAAK,UAAA;EACd;;EAGA,YAAqB;AACnB,WAAO,CAAC,aAAA,MAAK,WAAA;EACf;EAEA,aAAsB;AACpB,WAAO,aAAA,MAAK,QAAA;EACd;EAEA,WAAoB;AAClB,WAAO,aAAA,MAAK,MAAA,MAAW;EACzB;;;;;;;EA2CM,4BAA2C;AAAA,WAAA,QAAA,MAAA,MAAA,aAAA;AAlzCnD,UAAA,IAAA;AAmzCI,mBAAA,MAAK,eAAgB,IAAA;AACrB,UAAI,aAAA,MAAK,WAAA,KAAe,GAAC,KAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAA,GAA8B,OAAO,UAAS;AAGrE,SAAA,KAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAA,GAA8B,MAAM,4BAAA;MACtC;AACA,YAAM,gBAAA,MAAK,wBAAA,WAAA,EAAL,KAAA,IAAA;AACN,mBAAA,MAAK,eAAgB,KAAA;IACvB,CAAA;EAAA;;;;;;;;;;;;;;;EAqFM,gBAAgB,MAGnB;AAAA,WAAA,QAAA,MAAA,MAAA,aAAA;AACD,UAAI,aAAA,MAAK,KAAA,MAAU,QAAQ;AACzB,cAAM,IAAI;UACR,0CAA0C,aAAA,MAAK,KAAA,CAAK;QACtD;MACF;AAEA,UAAI,CAAC,aAAA,MAAK,QAAA,EAAU,OAAM,gBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;AAI1B,YAAM,gBAAA,MAAK,wBAAA,mBAAA,EAAL,KAAA,IAAA;AAGN,uBAAA,MAAK,uBAAA,EAAL;AAEA,UAAI;AACF,YAAI,aAAA,MAAK,uBAAA,MAA4B,GAAG;AAEtC,0BAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;QACF;AAEA,cAAM,EAAE,UAAU,KAAK,IAAI,MAAM,KAAK,cAAc,IAAI;AAExD,cAAM,sBAAuB,KAA2B,OAAO;UAC7D,EAAE,SAAS,eAAA,EAAE,SAAS,eAAA,GAAmB,QAAA,EAAW;QACtD,CAAC;AAED,qBAAA,MAAK,gBAAA,EAAiB;UACpB;UACA,IAAI,IAAI,KAAK,IAAI,CAAC,YAAY,QAAQ,GAAG,CAAC;QAC5C;AACA,wBAAA,MAAK,wBAAA,aAAA,EAAL,KAAA,MAAiB,qBAAqB,KAAA;AAEtC,eAAO;UACL;UACA;QACF;MACF,UAAA;AAEE,yBAAA,MAAK,uBAAA,EAAL;AACA,YAAI,aAAA,MAAK,uBAAA,MAA4B,GAAG;AACtC,0BAAA,MAAK,wBAAA,SAAA,EAAL,KAAA,IAAA;QACF;MACF;IACF,CAAA;EAAA;;;;;;;;EASM,cAAc,MAGjB;AAAA,WAAA,QAAA,MAAA,MAAA,aAAA;AA58CL,UAAA;AA68CI,YAAM,EAAE,UAAU,eAAe,IAAI,MAAM,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,MACzC,KAAK,QAAQ,KACb,MACA,IAAA;AAGF,YAAM,WAAW,MAAM,aAAA,MAAKA,aAAAA,EAAL,KAAA,MAAkB,SAAS,SAAS,GAAG;QAC5D,SAAS;MACX,CAAA;AAEA,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,IAAI;UACR,SAAS;UACT;UACA;UACA,OAAO,YAAY,CAAC,GAAG,SAAS,QAAQ,QAAQ,CAAC,CAAC;UAClD,SAAS,SAAS;QACpB;MACF;AAGA,YAAM,UACJ,KAAA,aAAA,MAAK,OAAA,MAAL,OAAA,KACA,qBAAqB,SAAS,SAAS;QACrC,UAAU;QACV,KAAK,SAAS,SAAS;MACzB,CAAC;AAEH,YAAM,EAAE,UAAU,MAAM,QAAQ,IAAI,MAAM,SAAS,KAAK;AACxD,YAAM,OAAO,aAAA,MAAK,cAAA,EAAe;QAC/B;QACA;MACF;AAEA,aAAO;QACL;QACA;MACF;IACF,CAAA;EAAA;AACF;AAn+BE,SAAA,oBAAA,QAAA;AAESA,gBAAA,oBAAA,QAAA;AACA,kBAAA,oBAAA,QAAA;AACA,iBAAA,oBAAA,QAAA;AAEA,eAAA,oBAAA,QAAA;AAQT,WAAA,oBAAA,QAAA;AACA,SAAA,oBAAA,QAAA;AACA,cAAA,oBAAA,QAAA;AACA,mBAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AACA,cAAA,oBAAA,QAAA;AACA,eAAA,oBAAA,QAAA;AACA,aAAA,oBAAA,QAAA;AACA,eAAA,oBAAA,QAAA;AACA,QAAA,oBAAA,QAAA;AACA,UAAA,oBAAA,QAAA;AACA,WAAA,oBAAA,QAAA;AACA,0BAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AACA,eAAA,oBAAA,QAAA;AACA,uBAAA,oBAAA,QAAA;AACA,uBAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AACA,mBAAA,oBAAA,QAAA;AACA,0BAAA,oBAAA,QAAA;AACA,oBAAA,oBAAA,QAAA;AACA,4BAAA,oBAAA,QAAA;AACA,kBAAA,oBAAA,QAAA;AACA,mBAAA,oBAAA,QAAA;AACA,8BAAA,oBAAA,QAAA;AACA,4BAAA,oBAAA,QAAA;AACA,kCAAA,oBAAA,QAAA;AACA,0BAAA,oBAAA,QAAA;AACA,4BAAA,oBAAA,QAAA;AACA,uBAAA,oBAAA,QAAA;AACA,sBAAA,oBAAA,QAAA;AACA,oCAAA,oBAAA,QAAA;AAtDK,yBAAA,oBAAA,QAAA;AAyDD,iBAAW,WAAY;AACzB,SAAO,aAAA,MAAK,eAAA,MAAoB;AAClC;AAmFM,WAAM,WAAkB;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAtpBhC,QAAA,IAAA,IAAA,IAAA,IAAA;AAupBI,iBAAA,MAAK,UAAW,IAAA;AAEhB,QAAI;AACF,YAAM,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,IAAA;IACR,SAAS,KAAK;AACZ,mBAAA,MAAK,QAAS,GAAA;AAGd,UAAI,aAAA,MAAK,QAAA,GAAU;AACjB,cAAM,YAAY,MAAM,aAAA,MAAK,QAAA,EAAL,KAAA,MAAc,GAAA;AAEtC,YAAI,aAAa,OAAO,cAAc,UAAU;AAG9C,cAAI,UAAU,QAAQ;AAEpB,iBAAK,QAAQ,SAAS,eAAA,eAAA,CAAA,IAChB,KAAA,KAAK,QAAQ,WAAb,OAAA,KAAuB,CAAC,CAAA,GACzB,UAAU,MAAA;UAEjB;AAEA,cAAI,UAAU,SAAS;AAErB,iBAAK,QAAQ,UAAU,eAAA,eAAA,CAAA,IACjB,KAAA,KAAK,QAAQ,YAAb,OAAA,KAAwB,CAAC,CAAA,GAC1B,UAAU,OAAA;UAEjB;AAGA,uBAAA,MAAK,QAAS,IAAA;AAGd,uBAAA,MAAK,UAAW,KAAA;AAChB,gBAAM,gBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;AACN;QACF;AAGA,YAAI,eAAe,OAAO;AACxB,0BAAA,MAAK,wBAAA,yBAAA,EAAL,KAAA,MAA6B,GAAA;QAC/B;AACA,qBAAA,MAAK,YAAa,KAAA;AAClB,SAAA,KAAA,aAAA,MAAK,oBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AACA;MACF;AAIA,UAAI,eAAe,OAAO;AACxB,wBAAA,MAAK,wBAAA,yBAAA,EAAL,KAAA,MAA6B,GAAA;MAC/B;AACA,mBAAA,MAAK,YAAa,KAAA;AAClB,OAAA,KAAA,aAAA,MAAK,oBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AACA,YAAM;IACR;AAGA,iBAAA,MAAK,YAAa,KAAA;AAClB,KAAA,KAAA,aAAA,MAAK,oBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;EACF,CAAA;AAAA;AAEM,kBAAa,WAAkB;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAttBvC,QAAA,IAAA;AAutBI,QAAI,aAAA,MAAK,MAAA,MAAW,mBAAmB;AACrC,mBAAA,MAAK,QAAS,QAAA;AAEd;IACF;AAEA,QACE,CAAC,KAAK,QAAQ,gBACb,KAAA,KAAK,QAAQ,WAAb,OAAA,SAAA,GAAqB,YAAW,aAAA,MAAK,WAAA,IACtC;AACA;IACF;AAEA,UAAM,oBAAoB,aAAA,MAAK,MAAA,MAAW;AAC1C,iBAAA,MAAK,QAAS,QAAA;AAEd,UAAM,EAAE,KAAK,OAAO,IAAI,KAAK;AAC7B,UAAM,EAAE,UAAU,eAAe,IAAI,MAAM,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,MACzC,KACA,iBAAA;AAEF,UAAM,gBAAgB,MAAM,gBAAA,MAAK,wBAAA,sBAAA,EAAL,KAAA,MAA0B,MAAA;AACtD,UAAM,yBAAyB,aAAA,MAAK,uBAAA;AAEpC,QAAI;AACF,YAAM,gBAAA,MAAK,wBAAA,aAAA,EAAL,KAAA,MAAiB;QACrB;QACA;QACA,SAAS;QACT;MACF,CAAA;IACF,SAAS,GAAG;AAEV,WACG,aAAa,cAAc,aAAa,2BACzC,uBAAuB,OAAO,WAC9B,uBAAuB,OAAO,WAAW,8BACzC;AAEA,eAAO,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,IAAA;MACT;AAEA,UAAI,aAAa,wBAAwB;AAIvC,cAAM,eAAe,aAAA,MAAK,MAAA;AAI1B,YACE,uBAAuB,OAAO,WAC9B,uBAAuB,OAAO,WAAW,gBACzC,iBAAiB,mBACjB;AACA,uBAAA,MAAK,QAAS,QAAA;QAChB;AACA;MACF;AACA,UAAI,EAAE,aAAa,YAAa,OAAM;AAEtC,UAAI,EAAE,UAAU,KAAK;AAOnB,YAAI,aAAA,MAAK,YAAA,GAAc;AACrB,gBAAM,WAAW,kBAAkB,QAAQ;AAC3C,6BAAmB,YAAY,UAAU,aAAA,MAAK,YAAA,CAAY;QAC5D;AAEA,cAAM,iBACJ,EAAE,QAAQ,mBAAmB,KAAK,GAAG,aAAA,MAAK,YAAA,CAAa;AACzD,wBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,MAAY,cAAA;AAKZ,cAAM,gBAAA,MAAK,wBAAA,UAAA,EAAL,KAAA,MACH,MAAM,QAAQ,EAAE,IAAI,IAAI,EAAE,OAAO,CAAC,EAAE,IAAI,CAAA;AAE3C,eAAO,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,IAAA;MACT,OAAO;AAKL,cAAM;MACR;IACF,UAAA;AACE,UAAI,iBAAiB,QAAQ;AAC3B,eAAO,oBAAoB,SAAS,aAAa;MACnD;AACA,mBAAA,MAAK,yBAA0B,MAAA;IACjC;AAEA,KAAA,KAAA,aAAA,MAAK,oBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AACA,WAAO,gBAAA,MAAK,wBAAA,eAAA,EAAL,KAAA,IAAA;EACT,CAAA;AAAA;AAEM,kBAAa,SACjB,KACA,mBACA,cACA;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAj0BJ,QAAA,IAAA,IAAA;AAm0BI,UAAM,CAAC,gBAAgB,MAAM,IAAI,MAAM,QAAQ,IAAI;MACjD,eAAe,KAAK,QAAQ,OAAO;MACnC,KAAK,QAAQ,SACT,iBAAiB,wBAAwB,KAAK,QAAQ,MAAM,CAAC,IAC7D;IACN,CAAC;AAGD,QAAI,OAAQ,gBAAe,MAAM;AAEjC,UAAM,WAAW,IAAI,IAAI,GAAG;AAG5B,QAAI,QAAQ;AACV,UAAI,OAAO,MAAO,eAAc,UAAU,mBAAmB,OAAO,KAAK;AACzE,UAAI,OAAO,SAAS,OAAO,OAAO,UAAU,UAAU;AACpD,cAAM,eAAe;UACnB,OAAO;WACP,KAAA,KAAK,QAAQ,iBAAb,OAAA,SAAA,GAA2B;QAC7B;AACA,sBAAc,UAAU,mBAAmB,YAAY;MACzD;AACA,UAAI,OAAO;AACT,sBAAc,UAAU,qBAAqB,OAAO,OAAO;AAC7D,UAAI,OAAO,QAAS,eAAc,UAAU,eAAe,OAAO,OAAO;AACzE,UAAI,OAAO;AACT,sBAAc,UAAU,oBAAoB,OAAO,MAAM;AAG3D,YAAM,eAAe,eAAA,CAAA,GAAK,MAAA;AAC1B,aAAO,aAAa;AACpB,aAAO,aAAa;AACpB,aAAO,aAAa;AACpB,aAAO,aAAa;AACpB,aAAO,aAAa;AAEpB,iBAAW,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,YAAY,GAAG;AACvD,sBAAc,UAAU,KAAK,KAAK;MACpC;IACF;AAEA,QAAI,cAAc;AAChB,UAAI,aAAa,SAAS,OAAO,aAAa,UAAU,UAAU;AAChE,cAAM,eAAe;UACnB,aAAa;WACb,KAAA,KAAK,QAAQ,iBAAb,OAAA,SAAA,GAA2B;QAC7B;AACA,sBAAc,UAAU,oBAAoB,YAAY;MAC1D;AACA,UAAI,aAAa;AAEf,iBAAS,aAAa;UACpB;UACA,KAAK,UAAU,aAAa,MAAM;QACpC;AACF,UAAI,aAAa;AACf,sBAAc,UAAU,oBAAoB,aAAa,KAAK;AAChE,UAAI,aAAa;AACf,sBAAc,UAAU,qBAAqB,aAAa,MAAM;AAClE,UAAI,aAAa,WAAW,OAAO,aAAa,YAAY,UAAU;AACpE,cAAM,iBAAiB;UACrB,aAAa;WACb,KAAA,KAAK,QAAQ,iBAAb,OAAA,SAAA,GAA2B;QAC7B;AACA,sBAAc,UAAU,uBAAuB,cAAc;MAC/D;IACF;AAGA,aAAS,aAAa,IAAI,oBAAoB,aAAA,MAAK,WAAA,CAAW;AAC9D,aAAS,aAAa,IAAI,sBAAsB,aAAA,MAAK,KAAA,CAAK;AAG1D,UAAM,oBAAoB,iBAAiB;AAE3C,QAAI,aAAA,MAAK,WAAA,KAAe,CAAC,mBAAmB;AAI1C,UAAI,CAAC,aAAA,MAAK,aAAA,KAAiB,CAAC,mBAAmB;AAC7C,iBAAS,aAAa,IAAI,kBAAkB,MAAM;MACpD;AACA,eAAS,aAAa;QACpB;QACA,aAAA,MAAK,gBAAA;MACP;IACF;AAEA,QAAI,aAAA,MAAK,YAAA,GAAc;AAErB,eAAS,aAAa,IAAI,0BAA0B,aAAA,MAAK,YAAA,CAAa;IACxE;AAGA,UAAM,WAAW,kBAAkB,QAAQ;AAC3C,UAAM,gBAAgB,mBAAmB,iBAAiB,QAAQ;AAClE,QAAI,eAAe;AACjB,eAAS,aAAa,IAAI,4BAA4B,aAAa;IACrE;AAGA,aAAS,aAAa,KAAK;AAE3B,WAAO;MACL;MACA;IACF;EACF,CAAA;AAAA;AAEM,yBAAoB,SAAC,QAAsB;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAh7BnD,QAAA;AAk7BI,iBAAA,MAAK,yBAA0B,IAAI,gBAAgB,CAAA;AAGnD,QAAI,QAAQ;AACV,YAAM,gBAAgB,MAAM;AAt7BlC,YAAAC;AAu7BQ,SAAAA,MAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAAA,IAA8B,MAAM,OAAO,MAAA;MAC7C;AAEA,aAAO,iBAAiB,SAAS,eAAe,EAAE,MAAM,KAAK,CAAC;AAE9D,UAAI,OAAO,SAAS;AAElB,SAAA,KAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAA,GAA8B,MAAM,OAAO,MAAA;MAC7C;AAEA,aAAO;IACT;EACF,CAAA;AAAA;AAEM,uBAAkB,SAAC,UAAoB;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAr8B/C,QAAA;AAs8BI,UAAM,EAAE,SAAS,OAAO,IAAI;AAC5B,UAAM,cAAc,QAAQ,IAAI,mBAAmB;AACnD,QAAI,aAAa;AACf,mBAAA,MAAK,cAAe,WAAA;IACtB;AAEA,UAAM,aAAa,QAAQ,IAAI,wBAAwB;AACvD,QAAI,YAAY;AACd,mBAAA,MAAK,aAAc,UAAA;IACrB;AAEA,UAAM,kBAAkB,QAAQ,IAAI,wBAAwB;AAC5D,QAAI,iBAAiB;AACnB,mBAAA,MAAK,kBAAmB,eAAA;IAC1B;AAEA,iBAAA,MAAK,UAAU,KAAA,aAAA,MAAK,OAAA,MAAL,OAAA,KAAgB,qBAAqB,OAAO,CAAA;AAK3D,QAAI,WAAW,KAAK;AAElB,mBAAA,MAAK,eAAgB,KAAK,IAAI,CAAA;IAChC;EACF,CAAA;AAAA;AAEM,gBAAW,SAACE,QAA0B,eAAe,OAAO;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAj+BpE,QAAA;AAm+BI,QAAIA,OAAM,SAAS,GAAG;AAEpB,mBAAA,MAAK,cAAe,IAAA;AAEpB,YAAM,cAAcA,OAAMA,OAAM,SAAS,CAAC;AAC1C,UAAI,kBAAkB,WAAW,GAAG;AAClC,YAAI,cAAc;AAIhB,gBAAM,SAAS,UAAU,WAAW;AACpC,cAAI,QAAQ;AACV,yBAAA,MAAK,aAAc,MAAA;UACrB;QACF;AACA,qBAAA,MAAK,eAAgB,KAAK,IAAI,CAAA;AAC9B,qBAAA,MAAK,aAAc,IAAA;AAEnB,qBAAA,MAAK,cAAe,KAAA;AAEpB,SAAA,KAAA,aAAA,MAAK,yBAAA,MAAL,OAAA,SAAA,GAAA,KAAA,IAAA;AAIA,YAAI,aAAA,MAAK,wBAAA,cAAA,KAAe,CAAC,cAAc;AAIrC,gBAAM,gBAAgB,aAAA,MAAK,gBAAA;AAE3B,cAAI,kBAAkB,aAAA,MAAK,eAAA,GAAiB;AAG1C;UACF;QACF;AAOA,qBAAA,MAAK,iBAAkB,MAAA;AAEvB,YAAI,aAAA,MAAK,gBAAA,GAAkB;AACzB,gBAAM,WAAW,kBAAkB,aAAA,MAAK,gBAAA,CAAgB;AACxD,0BAAgB,eAAe,UAAU,aAAA,MAAK,gBAAA,CAAgB;QAChE;MACF;AAGA,YAAM,oBAAoBA,OAAM,OAAO,CAAC,YAAY;AAClD,YAAI,gBAAgB,OAAO,GAAG;AAC5B,iBAAO,CAAC,aAAA,MAAK,gBAAA,EAAiB,oBAAoB,OAAO;QAC3D;AACA,eAAO;MACT,CAAC;AAED,YAAM,gBAAA,MAAK,wBAAA,UAAA,EAAL,KAAA,MAAc,iBAAA;IACtB;EACF,CAAA;AAAA;AASM,gBAAW,SAAC,MAKA;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AA7iCpB,QAAA;AA+iCI,iBAAA,MAAK,kBAAmB,KAAK,QAAA;AAK7B,QAAI,CAAC,aAAA,MAAK,WAAA,KAAe,CAAC,aAAA,MAAK,wBAAA,cAAA,GAAa;AAC1C,YAAM,WAAW,kBAAkB,KAAK,QAAQ;AAChD,YAAM,iBAAiB,gBAAgB,sBAAsB,QAAQ;AACrE,UAAI,gBAAgB;AAElB,qBAAA,MAAK,iBAAkB,cAAA;MACzB;IACF;AAEA,UAAM,UAAS,KAAA,KAAK,QAAQ,YAAb,OAAA,KAAwB,KAAK,QAAQ;AACpD,QACE,aAAA,MAAK,WAAA,KACL,UACA,CAAC,aAAA,MAAK,aAAA,KACN,CAAC,KAAK,qBACN,CAAC,aAAA,MAAK,yBAAA,GACN;AACA,WAAK,SAAS,aAAa,IAAI,mCAAmC,MAAM;AACxE,WAAK,SAAS,aAAa,IAAI,sBAAsB,MAAM;AAC3D,aAAO,gBAAA,MAAK,wBAAA,kBAAA,EAAL,KAAA,MAAsB,IAAA;IAC/B;AAEA,WAAO,gBAAA,MAAK,wBAAA,uBAAA,EAAL,KAAA,MAA2B,IAAA;EACpC,CAAA;AAAA;AAEM,0BAAqB,SAAC,MAIV;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAChB,UAAM,EAAE,UAAU,wBAAwB,QAAQ,IAAI;AACtD,UAAM,WAAW,MAAM,aAAA,MAAKH,aAAAA,EAAL,KAAA,MAAkB,SAAS,SAAS,GAAG;MAC5D,QAAQ,uBAAuB;MAC/B;IACF,CAAA;AAEA,iBAAA,MAAK,YAAa,IAAA;AAClB,UAAM,gBAAA,MAAK,wBAAA,oBAAA,EAAL,KAAA,MAAwB,QAAA;AAE9B,UAAM,SAAS,aAAA,MAAK,OAAA;AACpB,UAAM,MAAM,MAAM,SAAS,KAAK;AAChC,UAAM,WAAW,OAAO;AACxB,UAAMG,SAAQ,aAAA,MAAK,cAAA,EAAe,MAAyB,UAAU,MAAM;AAE3E,UAAM,gBAAA,MAAK,wBAAA,aAAA,EAAL,KAAA,MAAiBA,MAAA;EACzB,CAAA;AAAA;AAEM,qBAAgB,SAAC,MAIL;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAChB,UAAM,EAAE,UAAU,wBAAwB,QAAQ,IAAI;AACtD,UAAMC,SAAQ,aAAA,MAAK,eAAA;AAGnB,iBAAA,MAAK,6BAA8B,KAAK,IAAI,CAAA;AAE5C,QAAI;AACF,UAAI,SAA4B,CAAC;AACjC,YAAM,iBAAiB,SAAS,SAAS,GAAG;QAC1C;QACA,OAAAA;QACA,QAAQ,CAAO,aAAuB,QAAA,MAAA,MAAA,aAAA;AACpC,uBAAA,MAAK,YAAa,IAAA;AAClB,gBAAM,gBAAA,MAAK,wBAAA,oBAAA,EAAL,KAAA,MAAwB,QAAA;QAChC,CAAA;QACA,WAAW,CAAC,UAA8B;AACxC,cAAI,MAAM,MAAM;AAEd,kBAAM,SAAS,aAAA,MAAK,OAAA;AACpB,kBAAM,UAAU,aAAA,MAAK,cAAA,EAAe;cAClC,MAAM;cACN;YACF;AACA,mBAAO,KAAK,OAAO;AAEnB,gBAAI,kBAAkB,OAAO,GAAG;AAG9B,8BAAA,MAAK,wBAAA,aAAA,EAAL,KAAA,MAAiB,QAAQ,IAAA;AACzB,uBAAS,CAAC;YACZ;UACF;QACF;QACA,SAAS,CAAC,UAAiB;AAEzB,gBAAM;QACR;QACA,QAAQ,uBAAuB;MACjC,CAAC;IACH,SAAS,OAAO;AACd,UAAI,uBAAuB,OAAO,SAAS;AAQzC,cAAM,IAAI,uBAAuB;MACnC;AACA,YAAM;IACR,UAAA;AAIE,YAAM,qBAAqB,KAAK,IAAI,IAAI,aAAA,MAAK,2BAAA;AAC7C,YAAM,aAAa,uBAAuB,OAAO;AAEjD,UAAI,qBAAqB,aAAA,MAAK,yBAAA,KAA6B,CAAC,YAAY;AAEtE,yBAAA,MAAK,+BAAA,EAAL;AAEA,YACE,aAAA,MAAK,+BAAA,KAAmC,aAAA,MAAK,uBAAA,GAC7C;AAEA,uBAAA,MAAK,2BAA4B,IAAA;AACjC,kBAAQ;YACN;UAKF;QACF,OAAO;AAGL,gBAAM,WAAW,KAAK;YACpB,aAAA,MAAK,mBAAA;YACL,aAAA,MAAK,oBAAA,IACH,KAAK,IAAI,GAAG,aAAA,MAAK,+BAAA,CAA+B;UACpD;AACA,gBAAM,UAAU,KAAK,MAAM,KAAK,OAAO,IAAI,QAAQ;AACnD,gBAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,OAAO,CAAC;QAC7D;MACF,WAAW,sBAAsB,aAAA,MAAK,yBAAA,GAA2B;AAE/D,qBAAA,MAAK,iCAAkC,CAAA;MACzC;IACF;EACF,CAAA;AAAA;AAEA,WAAM,WAAG;AApsCX,MAAA;AAqsCI,MAAI,aAAA,MAAK,QAAA,KAAY,aAAA,MAAK,MAAA,MAAW,UAAU;AAC7C,iBAAA,MAAK,QAAS,iBAAA;AACd,KAAA,KAAA,aAAA,MAAK,uBAAA,MAAL,OAAA,SAAA,GAA8B,MAAM,YAAA;EACtC;AACF;AAEA,YAAO,WAAG;AACR,MACE,aAAA,MAAK,QAAA,MACJ,aAAA,MAAK,MAAA,MAAW,YAAY,aAAA,MAAK,MAAA,MAAW,oBAC7C;AAGA,QAAI,aAAA,MAAK,MAAA,MAAW,mBAAmB;AACrC,mBAAA,MAAK,QAAS,QAAA;IAChB;AACA,oBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;EACF;AACF;AAmDM,cAAS,WAAG;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAChB,QAAI,aAAA,MAAK,YAAA,GAAc;AACrB,aAAO,aAAA,MAAK,YAAA;IACd;AACA,iBAAA,MAAK,cAAe,IAAI,QAAQ,CAAC,SAAS,WAAW;AACnD,mBAAA,MAAK,sBAAuB,OAAA;AAC5B,mBAAA,MAAK,sBAAuB,MAAA;IAC9B,CAAC,CAAA;AACD,iBAAA,MAAK,YAAA,EAAa,QAAQ,MAAM;AAC9B,mBAAA,MAAK,cAAe,MAAA;AACpB,mBAAA,MAAK,sBAAuB,MAAA;AAC5B,mBAAA,MAAK,sBAAuB,MAAA;IAC9B,CAAC;AACD,WAAO,aAAA,MAAK,YAAA;EACd,CAAA;AAAA;AAGM,sBAAiB,WAAG;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AACxB,QAAI,CAAC,aAAA,MAAK,YAAA,GAAc;AACtB;IACF;AACA,QAAI,aAAA,MAAK,iBAAA,GAAmB;AAC1B,aAAO,aAAA,MAAK,iBAAA;IACd;AACA,iBAAA,MAAK,mBAAoB,IAAI,QAAQ,CAAC,YAAY;AAChD,mBAAA,MAAK,2BAA4B,OAAA;IACnC,CAAC,CAAA;AACD,iBAAA,MAAK,iBAAA,EAAkB,QAAQ,MAAM;AACnC,mBAAA,MAAK,mBAAoB,MAAA;AACzB,mBAAA,MAAK,2BAA4B,MAAA;IACnC,CAAC;AACD,WAAO,aAAA,MAAK,iBAAA;EACd,CAAA;AAAA;AAmBM,aAAQ,SAAC,UAAyC;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAKtD,iBAAA,MAAK,eAAgB,aAAA,MAAK,aAAA,EAAc;MAAK,MAC3C,QAAQ;QACN,MAAM,KAAK,aAAA,MAAK,YAAA,EAAa,OAAO,CAAC,EAAE,IAAI,CAAO,OAAmB,QAAA,MAAA,CAAnB,EAAA,GAAmB,WAAnB,CAAC,UAAU,EAAE,GAAM;AACnE,cAAI;AACF,kBAAM,SAAS,QAAQ;UACzB,SAAS,KAAK;AACZ,2BAAe,MAAM;AACnB,oBAAM;YACR,CAAC;UACH;QACF,CAAA,CAAC;MACH;IACF,CAAA;AAEA,WAAO,aAAA,MAAK,aAAA;EACd,CAAA;AAAA;AAEA,4BAAuB,SAAC,OAAc;AACpC,eAAA,MAAK,YAAA,EAAa,QAAQ,CAAC,CAAC,GAAG,OAAO,MAAM;AAC1C,eAAA,OAAA,SAAA,QAAU,KAAA;EACZ,CAAC;AACH;AAEA,kCAA6B,WAAG;AAC9B,MACE,OAAO,aAAa,YACpB,OAAO,SAAS,WAAW,aAC3B,OAAO,SAAS,qBAAqB,YACrC;AACA,UAAM,oBAAoB,MAAM;AAC9B,UAAI,SAAS,QAAQ;AACnB,wBAAA,MAAK,wBAAA,QAAA,EAAL,KAAA,IAAA;MACF,OAAO;AACL,wBAAA,MAAK,wBAAA,SAAA,EAAL,KAAA,IAAA;MACF;IACF;AAEA,aAAS,iBAAiB,oBAAoB,iBAAiB;AAG/D,iBAAA,MAAK,mCAAoC,MAAM;AAC7C,eAAS,oBAAoB,oBAAoB,iBAAiB;IACpE,CAAA;EACF;AACF;AAMA,WAAM,SAAC,QAAiB;AACtB,eAAA,MAAK,aAAc,IAAA;AACnB,eAAA,MAAK,kBAAmB,EAAA;AACxB,eAAA,MAAK,cAAe,MAAA;AACpB,eAAA,MAAK,aAAc,KAAA;AACnB,eAAA,MAAK,cAAe,IAAA;AACpB,eAAA,MAAK,YAAa,KAAA;AAClB,eAAA,MAAK,SAAU,MAAA;AACf,eAAA,MAAK,yBAA0B,CAAA;AAE/B,eAAA,MAAK,iCAAkC,CAAA;AACvC,eAAA,MAAK,2BAA4B,KAAA;AACnC;AAx3BW,YAGK,UAAU;EACxB,MAAM;EACN,SAAS;AACX;AAi/BF,SAAS,qBACP,SACA,SACQ;AACR,QAAM,eAAe,QAAQ,IAAI,mBAAmB;AACpD,MAAI,CAAC,cAAc;AACjB,SAAI,WAAA,OAAA,SAAA,QAAS,cAAY,WAAA,OAAA,SAAA,QAAS,MAAK;AACrC,YAAM,IAAI,oBAAoB,QAAQ,KAAK,CAAC,mBAAmB,CAAC;IAClE;AACA,WAAO,CAAC;EACV;AACA,SAAO,KAAK,MAAM,YAAY;AAChC;AAMA,SAAS,eAAe,QAAmD;AACzE,MAAI,CAAC,OAAQ;AAEb,QAAM,iBAAiB,OAAO,KAAK,MAAM,EAAE;IAAO,CAAC,QACjD,gBAAgB,IAAI,GAAwB;EAC9C;AACA,MAAI,eAAe,SAAS,GAAG;AAC7B,UAAM,IAAI,mBAAmB,cAAc;EAC7C;AACF;AAEA,SAAS,gBAAmB,SAA+C;AACzE,MAAI,CAAC,QAAQ,KAAK;AAChB,UAAM,IAAI,qBAAqB;EACjC;AACA,MAAI,QAAQ,UAAU,EAAE,QAAQ,kBAAkB,cAAc;AAC9D,UAAM,IAAI,mBAAmB;EAC/B;AAEA,MACE,QAAQ,WAAW,UACnB,QAAQ,WAAW,QACnB,QAAQ,WAAW,SACnB,CAAC,QAAQ,QACT;AACA,UAAM,IAAI,wBAAwB;EACpC;AAEA,iBAAe,QAAQ,MAAM;AAE7B;AACF;AAGA,SAAS,cACP,KACA,KACA,OACM;AACN,MAAI,UAAU,UAAa,SAAS,MAAM;AACxC;EACF,WAAW,OAAO,UAAU,UAAU;AACpC,QAAI,aAAa,IAAI,KAAK,KAAK;EACjC,WAAW,OAAO,UAAU,UAAU;AACpC,eAAW,CAAC,GAAG,CAAC,KAAK,OAAO,QAAQ,KAAK,GAAG;AAC1C,UAAI,aAAa,IAAI,GAAG,GAAG,IAAI,CAAC,KAAK,CAAC;IACxC;EACF,OAAO;AACL,QAAI,aAAa,IAAI,KAAK,MAAM,SAAS,CAAC;EAC5C;AACF;AAEA,SAAS,wBACP,aAC2B;AAC3B,MAAI,MAAM,QAAQ,YAAY,MAAM,GAAG;AACrC,WAAO,cAAA,eAAA,CAAA,GACF,WAAA,GADE;MAEL,QAAQ,OAAO,YAAY,YAAY,OAAO,IAAI,CAAC,GAAG,MAAM,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC;IACzE,CAAA;EACF;AACA,SAAO;AACT;AI/kDA,IAAA;AAAA,IAAAC;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAAC;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAoDW,QAAA,oBAAA,QAAA;AACAC,gBAAA,oBAAA,QAAA;AACA,gBAAA,oBAAA,QAAA;AACA,yBAAA,oBAAA,QAAA;AACT,6BAAA,oBAAA,QAAA;AACA,UAAA,oBAAA,QAAA;AACAC,UAAA,oBAAA,QAAA;AATK,mBAAA,oBAAA,QAAA;AAuHL,aAAQ,SAAC,UAA8B;AACrC,MAAI,eAAe;AAEnB,WAAS,QAAQ,CAAC,YAAY;AAC5B,QAAI,gBAAgB,OAAO,GAAG;AAC5B,qBAAe,gBAAA,MAAK,kBAAA,oBAAA,EAAL,KAAA,MAAwB,SAAA;AACvC,UAAI,KAAK,SAAS,QAAQ;AACxB,gBAAQ,QAAQ,QAAQ,WAAW;UACjC,KAAK;AACH,yBAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,KAAK,QAAQ,KAAK;AACzC;UACF,KAAK;AACH,yBAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,KAAK,eAAA,eAAA,CAAA,GACvB,aAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,GAAG,CAAA,GAC1B,QAAQ,KAAA,CACZ;AACD;UACF,KAAK;AACH,yBAAA,MAAK,KAAA,EAAM,OAAO,QAAQ,GAAG;AAC7B;QACJ;MACF,OAAO;AAEL,gBAAQ,QAAQ,QAAQ,WAAW;UACjC,KAAK;AACH,yBAAA,MAAK,aAAA,EAAc,IAAI,QAAQ,GAAG;AAClC,yBAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,KAAK,QAAQ,KAAK;AACzC;UACF,KAAK;AACH,gBAAI,aAAA,MAAK,aAAA,EAAc,IAAI,QAAQ,GAAG,GAAG;AACvC,2BAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,KAAK,eAAA,eAAA,CAAA,GACvB,aAAA,MAAK,KAAA,EAAM,IAAI,QAAQ,GAAG,CAAA,GAC1B,QAAQ,KAAA,CACZ;YACH;AACA;UACF,KAAK;AACH,gBAAI,aAAA,MAAK,aAAA,EAAc,IAAI,QAAQ,GAAG,GAAG;AACvC,2BAAA,MAAK,KAAA,EAAM,OAAO,QAAQ,GAAG;AAC7B,2BAAA,MAAK,aAAA,EAAc,OAAO,QAAQ,GAAG;YACvC;AACA;QACJ;MACF;IACF;AAEA,QAAI,iBAAiB,OAAO,GAAG;AAC7B,cAAQ,QAAQ,QAAQ,SAAS;QAC/B,KAAK;AACH,yBAAe,gBAAA,MAAK,kBAAA,oBAAA,EAAL,KAAA,MAAwB,YAAA;AACvC,cAAI,aAAA,MAAK,0BAAA,GAA4B;AACnC,yBAAA,MAAK,4BAA6B,KAAA;AAClC,iBAAK,gBAAA,MAAK,kBAAA,qBAAA,EAAL,KAAA,IAAA;UACP;AACA;QACF,KAAK;AACH,uBAAA,MAAK,KAAA,EAAM,MAAM;AACjB,uBAAA,MAAK,aAAA,EAAc,MAAM;AACzB,uBAAA,MAAKA,SAAS,KAAA;AACd,yBAAe,gBAAA,MAAK,kBAAA,oBAAA,EAAL,KAAA,MAAwB,SAAA;AAEvC,uBAAA,MAAK,4BAA6B,IAAA;AAClC;MACJ;IACF;EACF,CAAC;AAED,MAAI,aAAc,iBAAA,MAAK,kBAAA,SAAA,EAAL,KAAA,IAAA;AACpB;AAEM,wBAAmB,WAAkB;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AAEzC,UAAM,gBAAA,MAAK,kBAAA,gBAAA,EAAL,KAAA,IAAA;AAGN,UAAM,QAAQ;MACZ,MAAM,KAAK,aAAA,MAAK,sBAAA,CAAsB,EAAE,IAAI,CAAO,eAAe,QAAA,MAAA,MAAA,aAAA;AAChE,YAAI;AACF,gBAAM,WAAW,KAAK,MAAM,UAAU;AACtC,gBAAM,KAAK,OAAO,gBAAgB,QAAQ;QAC5C,SAAS,GAAG;QAEZ;MACF,CAAA,CAAC;IACH;EACF,CAAA;AAAA;AAEM,mBAAc,WAAkB;AAAA,SAAA,QAAA,MAAA,MAAA,aAAA;AACpC,QAAI,KAAK,OAAO,WAAY;AAC5B,UAAM,IAAI,QAAc,CAAC,YAAY;AACnC,YAAM,QAAQ,MAAM;AAClB,YAAI,KAAK,OAAO,YAAY;AAC1B,wBAAc,QAAQ;AACtB,gBAAM;AACN,kBAAQ;QACV;MACF;AACA,YAAM,WAAW,YAAY,OAAO,EAAE;AACtC,YAAM,QAAQ,KAAK,OAAO;QACxB,MAAM,MAAM;QACZ,MAAM,MAAM;MACd;AACA,YAAM;IACR,CAAC;EACH,CAAA;AAAA;AAEA,uBAAkB,SAAC,QAA8B;AAC/C,QAAM,eAAe,aAAA,MAAK,OAAA,MAAY;AACtC,eAAA,MAAK,SAAU,MAAA;AACf,SAAO,gBAAgB,WAAW;AACpC;AAEA,iBAAY,SAAC,GAAgB;AAC3B,MAAI,aAAa,YAAY;AAC3B,iBAAA,MAAKA,SAAS,CAAA;AACd,oBAAA,MAAK,kBAAA,SAAA,EAAL,KAAA,IAAA;EACF;AACF;AAEA,YAAO,WAAS;AACd,eAAA,MAAKD,aAAAA,EAAa,QAAQ,CAAC,aAAa;AACtC,aAAS,EAAE,OAAO,KAAK,cAAc,MAAM,KAAK,YAAY,CAAC;EAC/D,CAAC;AACH;;;ACjRK,IAAM,mBAAA,oBAAuB,QAAA;AAI7B,IAAM,mBAAA,oBAAuB,QAAA;AAK7B,IAAM,gCAAgC;EAC3C,SAAS,CAAA;AACX;AAEA,IAAI,eAAe;AACnB,IAAI,eAAe;AACnB,IAAM,mBAAA,oBAAuB,IAAA;AAE7B,IAAM,uBAAA,oBAA2B,IAAA;AAEjC,SAAS,kBAAkB,aAA8C;AACvE,aAAW,WAAW,aAAa;AACjC,QAAI,8BAA8B,QAAQ,SAAS,OAAO,GAAG;AAC3D;IACF;AAEA,kCAA8B,QAAQ,KAAK,OAAO;AAClD,YAAQ,UAAA;AAER,UAAM,SAAS,iBAAiB,IAAI,OAAO;AAC3C,QAAI,QAAQ;AACV,iBAAW,SAAS,QAAQ;AAC1B,cAAM,2BAA2B,iBAAiB,IAAI,KAAK;AAC3D,YAAI,EAAC,4BAAA,OAAA,SAAA,yBAA0B,QAAQ;AACvC,0BAAkB,wBAAwB;MAC5C;IACF;EACF;AACF;AAEA,SAAS,kBAAkB,OAAuB;AAChD,QAAM,QAAQ;IACZ,SAAS,MAAM;IACf,YAAY,MAAM;EAAA;AAEpB,aAAW,YAAY,MAAM,WAAW;AACtC,aAAS,KAAK;EAChB;AACF;AAEA,SAAS,yBAAyB,SAA2B;AAC3D,QAAM,QAAQ;IACZ,SAAS,QAAQ;IACjB,YAAY,QAAQ;EAAA;AAEtB,aAAW,YAAY,QAAQ,WAAW;AACxC,aAAS,KAAK;EAChB;AACF;AAKO,SAAS,QAAQ,OAAuB;AAE7C,MAAI,eAAe,KAAK,CAAC,qBAAqB,IAAI,KAAK,GAAG;AACxD,yBAAqB,IAAI,OAAO,MAAM,SAAS;EACjD;AAEA,mBAAiB,IAAI,KAAK;AAE1B,MAAI,eAAe,EAAG;AACtB,MAAI,aAAc;AAElB,MAAI;AACF,mBAAe;AAEf,WAAO,iBAAiB,OAAO,GAAG;AAChC,YAAM,SAAS,MAAM,KAAK,gBAAgB;AAC1C,uBAAiB,MAAA;AAGjB,iBAAWE,UAAS,QAAQ;AAE1B,cAAM,YAAY,qBAAqB,IAAIA,MAAK,KAAKA,OAAM;AAC3DA,eAAM,YAAY;AAClB,0BAAkBA,MAAK;MACzB;AAGA,iBAAWA,UAAS,QAAQ;AAC1B,cAAM,cAAc,iBAAiB,IAAIA,MAAK;AAC9C,YAAI,CAAC,YAAa;AAElB,sCAA8B,QAAQ,KAAKA,MAAK;AAChD,0BAAkB,WAAW;MAC/B;AAGA,iBAAWA,UAAS,QAAQ;AAC1B,cAAM,cAAc,iBAAiB,IAAIA,MAAK;AAC9C,YAAI,CAAC,YAAa;AAElB,mBAAW,WAAW,aAAa;AACjC,mCAAyB,OAAO;QAClC;MACF;IACF;EACF,UAAA;AACE,mBAAe;AACf,kCAA8B,UAAU,CAAA;AACxC,yBAAqB,MAAA;EACvB;AACF;;;ACxGO,SAAS,kBACd,SAC2B;AAC3B,SAAO,OAAO,YAAY;AAC5B;;;ACHO,IAAM,QAAN,MAGL;EAMA,YAAY,cAAsB,SAA0C;AAL5E,SAAA,YAAA,oBAAgB,IAAA;AAWhB,SAAA,YAAY,CAAC,aAA+B;;AAC1C,WAAK,UAAU,IAAI,QAAQ;AAC3B,YAAM,SAAQ,MAAA,KAAA,KAAK,YAAL,OAAA,SAAA,GAAc,gBAAd,OAAA,SAAA,GAAA,KAAA,IAA4B,UAAU,IAAA;AACpD,aAAO,MAAM;AACX,aAAK,UAAU,OAAO,QAAQ;AAC9B,iBAAA,OAAA,SAAA,MAAA;MACF;IACF;AAZE,SAAK,YAAY;AACjB,SAAK,QAAQ;AACb,SAAK,UAAU;EACjB;EAiBA,SAAS,SAA2C;;AAClD,SAAK,YAAY,KAAK;AAEtB,SAAI,KAAA,KAAK,YAAL,OAAA,SAAA,GAAc,UAAU;AAC1B,WAAK,QAAQ,KAAK,QAAQ,SAAS,KAAK,SAAS,EAAE,OAAmB;IACxE,OAAO;AACL,UAAI,kBAAkB,OAAO,GAAG;AAC9B,aAAK,QAAQ,QAAQ,KAAK,SAAS;MACrC,OAAO;AACL,aAAK,QAAQ;MACf;IACF;AAGA,KAAA,MAAA,KAAA,KAAK,YAAL,OAAA,SAAA,GAAc,aAAd,OAAA,SAAA,GAAA,KAAA,EAAA;AAGA,YAAQ,IAAa;EACvB;AACF;;;;;;ACzEO,IAAM,4BAAN,cAAwC,gBAAgB;EAC7D,YAAY,SAAiB,cAAuB;AAClD,UAAM,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE,GAAG,OAAO,EAAE;AAC7D,SAAK,OAAO;EACd;AACF;AAEO,IAAM,iCAAN,cAA6C,0BAA0B;EAC5E,YAAY,UAAkB,cAAuB;AACnD,UAAM,0CAA0C,QAAQ,IAAI,YAAY;AACxE,SAAK,OAAO;EACd;AACF;AAEO,IAAM,6BAAN,cAAyC,0BAA0B;EACxE,YAAY,MAAc,cAAuB;AAC/C,UAAM,6BAA6B,IAAI,IAAI,YAAY;AACvD,SAAK,OAAO;EACd;AACF;AAEO,IAAM,8BAAN,cAA0C,0BAA0B;EACzE,YAAY,cAAuB;AACjC,UAAM,6CAA6C,YAAY;AAC/D,SAAK,OAAO;EACd;AACF;AAEO,IAAM,qBAAN,cAAiC,0BAA0B;EAChE,YAAY,cAAuB;AACjC,UAAM,kBAAkB,YAAY;AACpC,SAAK,OAAO;EACd;AACF;;;ACzBO,SAAS,UAAU,OAAwB;AAGhD,MAAI,UAAU,QAAQ,UAAU,QAAW;AACzC,WAAO;EACT;AAGA,MAAI,OAAO,UAAU,UAAU;AAC7B,WAAO;EACT;AAGA,MAAI,OAAO,UAAU,UAAU;AAC7B,WAAO,MAAM,SAAA;EACf;AAGA,MAAI,OAAO,UAAU,WAAW;AAC9B,WAAO,QAAQ,SAAS;EAC1B;AAGA,MAAI,iBAAiB,MAAM;AACzB,WAAO,MAAM,YAAA;EACf;AAIA,MAAI,MAAM,QAAQ,KAAK,GAAG;AAExB,UAAM,WAAW,MAAM,IAAI,CAAC,SAAS;AACnC,UAAI,SAAS,QAAQ,SAAS,QAAW;AACvC,eAAO;MACT;AACA,UAAI,OAAO,SAAS,UAAU;AAE5B,cAAM,UAAU,KAAK,QAAQ,OAAO,MAAM,EAAE,QAAQ,MAAM,KAAK;AAC/D,eAAO,IAAI,OAAO;MACpB;AACA,aAAO,UAAU,IAAI;IACvB,CAAC;AACD,WAAO,IAAI,SAAS,KAAK,GAAG,CAAC;EAC/B;AAEA,QAAM,IAAI,MAAM,2BAA2B,KAAK,UAAU,KAAK,CAAC,EAAE;AACpE;;;ACjDO,SAAS,WAAc,SAA0C;AACtE,QAAM,EAAE,OAAO,SAAS,MAAA,IAAU;AAElC,QAAM,SAAmB,CAAA;AACzB,QAAM,cAAiC,EAAE,OAAA;AAEzC,MAAI,OAAO;AAGT,gBAAY,QAAQ,uBAAuB,OAAO,MAAM;EAC1D;AAEA,MAAI,SAAS;AACX,gBAAY,UAAU,eAAe,SAAS,MAAM;EACtD;AAEA,MAAI,OAAO;AACT,gBAAY,QAAQ;EACtB;AAKA,MAAI,CAAC,OAAO;AACV,gBAAY,QAAQ;EACtB;AAIA,QAAM,eAAe,OAAO;IAC1B,CAAC,KAAK,OAAO,UAAU;AACrB,YAAM,aAAa,UAAU,KAAK;AAGlC,UAAI,eAAe,IAAI;AACrB,YAAI,GAAG,QAAQ,CAAC,EAAE,IAAI;MACxB;AACA,aAAO;IACT;IACA,CAAA;EAAC;AAGH,SAAO;IACL,GAAG;IACH,QAAQ;EAAA;AAEZ;AAQA,SAAS,gBAAgB,MAAsB;AAC7C,SAAO,IAAI,IAAI;AACjB;AAQA,SAAS,uBACP,KACA,QACQ;AACR,UAAQ,IAAI,MAAA;IACV,KAAK;AACH,aAAO,KAAK,IAAI,KAAK;AACrB,aAAO,IAAI,OAAO,MAAM;IAC1B,KAAK;AAEH,UAAI,IAAI,KAAK,WAAW,GAAG;AACzB,cAAM,IAAI;UACR,4CAA4C,IAAI,KAAK,KAAK,GAAG,CAAC;QAAA;MAElE;AACA,aAAO,gBAAgB,IAAI,KAAK,CAAC,CAAE;IACrC,KAAK;AACH,aAAO,gBAAgB,KAAK,MAAM;IACpC;AACE,YAAM,IAAI,MAAM,yBAAyB;EAAA;AAE/C;AAEA,SAAS,eAAe,SAAqB,QAAgC;AAC3E,QAAM,yBAAyB,QAAQ;IAAI,CAAC,WAC1C,qBAAqB,QAAQ,MAAM;EAAA;AAErC,SAAO,uBAAuB,KAAK,GAAG;AACxC;AAEA,SAAS,qBACP,QACA,QACQ;AAGR,QAAM,EAAE,YAAY,eAAA,IAAmB;AACvC,MAAI,MAAM,uBAAuB,YAAY,MAAM;AAEnD,MAAI,eAAe,cAAc,QAAQ;AACvC,UAAM,GAAG,GAAG;EACd;AAEA,MAAI,eAAe,UAAU,SAAS;AACpC,UAAM,GAAG,GAAG;EACd;AAEA,MAAI,eAAe,UAAU,QAAQ;AACnC,UAAM,GAAG,GAAG;EACd;AAEA,SAAO;AACT;AAEA,SAAS,gBACP,KACA,SAAyB,CAAA,GACjB;AACR,QAAM,EAAE,MAAM,KAAA,IAAS;AAEvB,QAAM,SAAS,UAAU,IAAI;AAE7B,QAAM,eAAe,KAAK;IAAI,CAAC,QAC7B,uBAAuB,KAAK,MAAM;EAAA;AAIpC,MAAI,SAAS,YAAY,SAAS,eAAe;AAC/C,QAAI,aAAa,WAAW,GAAG;AAC7B,YAAM,IAAI,MAAM,GAAG,IAAI,qBAAqB;IAC9C;AACA,WAAO,GAAG,aAAa,CAAC,CAAC,IAAI,MAAM;EACrC;AAGA,MAAI,SAAS,OAAO;AAClB,QAAI,aAAa,WAAW,GAAG;AAC7B,YAAM,IAAI,MAAM,wBAAwB;IAC1C;AAEA,UAAM,MAAM,KAAK,CAAC;AAClB,QAAI,OAAO,IAAI,SAAS,QAAQ;AAC9B,YAAM,UAAU;AAChB,UAAI,QAAQ,SAAS,YAAY,QAAQ,SAAS,eAAe;AAC/D,cAAM,WAAW,uBAAuB,QAAQ,KAAK,CAAC,GAAI,MAAM;AAChE,eAAO,GAAG,QAAQ;MACpB;IACF;AACA,WAAO,GAAG,MAAM,KAAK,aAAa,CAAC,CAAC;EACtC;AAEA,MAAI,WAAW,IAAI,GAAG;AAEpB,SAAK,SAAS,SAAS,SAAS,SAAS,aAAa,SAAS,GAAG;AAEhE,aAAO,aAAa,IAAI,CAAC,QAAQ,IAAI,GAAG,GAAG,EAAE,KAAK,IAAI,MAAM,GAAG;IACjE;AAEA,QAAI,aAAa,WAAW,GAAG;AAC7B,YAAM,IAAI,MAAM,mBAAmB,IAAI,sBAAsB;IAC/D;AACA,UAAM,CAAC,KAAK,GAAG,IAAI;AAEnB,QAAI,SAAS,MAAM;AACjB,aAAO,GAAG,GAAG,IAAI,MAAM,IAAI,GAAG;IAChC;AACA,WAAO,GAAG,GAAG,IAAI,MAAM,IAAI,GAAG;EAChC;AAEA,SAAO,GAAG,MAAM,IAAI,aAAa,KAAK,GAAG,CAAC;AAC5C;AAEA,SAAS,WAAW,MAAuB;AACzC,QAAM,YAAY;IAChB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EAAA;AAEF,SAAO,UAAU,SAAS,IAAI;AAChC;AAEA,SAAS,UAAU,MAAsB;AACvC,QAAM,UAAU;IACd,IAAI;IACJ,IAAI;IACJ,KAAK;IACL,IAAI;IACJ,KAAK;IACL,KAAK;IACL,KAAK;IACL,IAAI;IACJ,KAAK;IACL,aAAa;IACb,QAAQ;IACR,IAAI;;IACJ,MAAM;IACN,OAAO;IACP,OAAO;IACP,OAAO;IACP,QAAQ;IACR,QAAQ;IACR,UAAU;EAAA;AAGZ,QAAM,SAAS,QAAQ,IAA4B;AAEnD,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,8BAA8B,IAAI,EAAE;EACtD;AAEA,SAAO;AACT;;;AC9LA,IAAM,QAAQ,aAAAC,QAAY,MAAM,gBAAgB;AAKzC,IAAM,sBAAsB,OAAO,mBAAmB;AA2M7D,SAASC,mBACP,SACkD;AAClD,SAAO,iBAAiB,OAAO,KAAK,QAAQ,QAAQ,YAAY;AAClE;AAEA,SAAS,qBACP,SACsE;AACtE,SAAO,iBAAiB,OAAO,KAAK,QAAQ,QAAQ,YAAY;AAClE;AAEA,SAAS,qBACP,SAC+B;AAC/B,SAAO,iBAAiB,OAAO,KAAK,QAAQ,QAAQ,YAAY;AAClE;AAEA,SAAS,qBAAqB,SAA+C;AAC3E,SAAO;IACL,MAAM,QAAQ,QAAQ;IACtB,MAAM,QAAQ,QAAQ;IACtB,UAAU,QAAQ,QAAQ;EAAA;AAE9B;AAGA,SAAS,SACP,SAC8D;AAC9D,SAAO,WAAW,QAAQ,WAAW,MAAM,QAAQ,QAAQ,QAAQ,KAAK;AAC1E;AAQA,SAAS,uBAA+C;EACtD;EACA;EACA;EACA;EACA;EACA;EACA;AACF,GAYkC;AAEhC,MAAI,aAAa,SAAS;AACxB,WAAO;EACT;AAEA,QAAM,aAAa,OAAO,SAA4B;AAEpD,QAAI,uBAAA,GAA0B;AAE5B,YAAM,iBAAiB,WAAc,IAAI;AACzC,UAAI;AACF,cAAM,EAAE,MAAM,KAAA,IAAS,MAAM,OAAO,cAAc,cAAc;AAIhE,YAAI,CAAC,uBAAA,GAA0B;AAC7B;YACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;UAAA;AAE7C;QACF;AAGA,YAAI,KAAK,SAAS,GAAG;AACnB,gBAAA;AACA,qBAAW,OAAO,MAAM;AACtB,kBAAM;cACJ,MAAM;cACN,OAAO,IAAI;cACX,UAAU;gBACR,GAAG,IAAI;cAAA;YACT,CACD;UACH;AACA,iBAAA;AAEA;YACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE,yBAAyB,KAAK,MAAM;UAAA;QAEnF;MACF,SAAS,OAAO;AACd;UACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;UAC3C;QAAA;AAEF,cAAM;MACR;IACF,WAAW,aAAa,eAAe;AAErC;IACF,OAAO;AAEL,YAAM,iBAAiB,WAAc,IAAI;AACzC,YAAM,OAAO,gBAAgB,cAAc;IAC7C;EACF;AAEA,SAAO,IAAI,uBAAuB,EAAE,WAAA,CAAY;AAClD;AAwDO,SAAS,0BACd,QAKA;AACA,QAAM,YAAY,IAAI,MAAA,oBAAqB,IAAI,CAAA,CAAE,CAAC;AAClD,QAAM,gBAAgB,IAAI,MAA+B,CAAA,CAAE;AAC3D,QAAM,mBAAmB,OAAO,YAAY;AAC5C,QAAM,gBACJ,qBAAqB,gBAAgB,cAAc;AACrD,QAAM,iBAAiB,IAAI,MAWzB,oBAAI,IAAA,CAAK;AAGX,QAAM,uBAAuB,IAAI,MAA2B,CAAA,CAAE;AAK9D,QAAM,uBAAuB,CAAC,aAA4B;AACxD,QAAI,SAAS,SAAS,GAAG;AACvB,qBAAe,SAAS,CAAC,YAAY;AACnC,cAAM,aAAa,IAAI,IAAI,OAAO;AAClC,iBAAS,QAAQ,CAAC,OAAO,WAAW,OAAO,EAAE,CAAC;AAC9C,eAAO;MACT,CAAC;IACH;EACF;AAKA,QAAM,+BAA+B,MAAM;AACzC,UAAM,mBAAkC,CAAA;AACxC,mBAAe,MAAM,QAAQ,CAAC,OAAO,YAAY;AAC/C,UAAI,MAAM,SAAS;AACjB,qBAAa,MAAM,SAAS;AAC5B,cAAM,QAAQ,IAAI;AAClB,yBAAiB,KAAK,OAAO;AAC7B;UACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;UACrC;QAAA;MAEJ;IACF,CAAC;AACD,yBAAqB,gBAAgB;EACvC;AACA,QAAM,OAAO,mBAAwB,OAAO,cAAc;IACxD;IACA;IACA,UAAU;IACV;IACA;IACA;IACA;IACA,cAAc,OAAO;IACrB,WAAW,OAAO,mBAAmB;EAAA,CACtC;AAQD,QAAM,YAAyB,OAC7B,MACA,UAAkB,QACG;AACrB;MACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;MACrC;IAAA;AAEF,QAAI,OAAO,SAAS,UAAU;AAC5B,YAAM,IAAI,+BAA+B,OAAO,MAAM,OAAO,EAAE;IACjE;AAGA,UAAM,UAAU,UAAU,MAAM,IAAI,IAAI;AACxC,QAAI,QAAS,QAAO;AAGpB,UAAM,cAAc,cAAc,MAAM;MAAK,CAAC,aAC5C,oBAAoB,MAAM,QAAQ;IAAA;AAEpC,QAAI,YAAa,QAAO;AAExB,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,YAAM,YAAY,WAAW,MAAM;AACjC,6BAAA;AACA,iCAAA;AACA,eAAO,IAAI,2BAA2B,MAAM,OAAO,EAAE,CAAC;MACxD,GAAG,OAAO;AAEV,YAAM,uBAAuB,UAAU,UAAU,MAAM;AACrD,YAAI,UAAU,MAAM,IAAI,IAAI,GAAG;AAC7B;YACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;YACrC;UAAA;AAEF,uBAAa,SAAS;AACtB,+BAAA;AACA,mCAAA;AACA,kBAAQ,IAAI;QACd;MACF,CAAC;AAED,YAAM,2BAA2B,cAAc,UAAU,MAAM;AAC7D,cAAM,kBAAkB,cAAc,MAAM;UAAK,CAAC,aAChD,oBAAoB,MAAM,QAAQ;QAAA;AAEpC,YAAI,iBAAiB;AACnB;YACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;YACrC;YACA;UAAA;AAEF,uBAAa,SAAS;AACtB,mCAAA;AACA,+BAAA;AACA,kBAAQ,IAAI;QACd;MACF,CAAC;IACH,CAAC;EACH;AAQA,QAAM,aAAgC,OACpC,SACA,UAAkB,QACG;AACrB;MACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;IAAA;AAGvC,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,YAAM,UAAU,KAAK,OAAA,EAAS,SAAS,EAAE;AAEzC,YAAM,eAAe,MAAM;AACzB,uBAAe,SAAS,CAAC,YAAY;AACnC,gBAAM,aAAa,IAAI,IAAI,OAAO;AAClC,qBAAW,OAAO,OAAO;AACzB,iBAAO;QACT,CAAC;MACH;AAEA,YAAM,YAAY,MAAM;AACtB,qBAAA;AACA,eAAO,IAAI,4BAA4B,OAAO,EAAE,CAAC;MACnD;AAEA,YAAM,YAAY,WAAW,WAAW,OAAO;AAI/C,YAAM,aAAa,CAAC,YAA0B;AAC5C,YAAI,QAAQ,OAAO,GAAG;AACpB;YACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;UAAA;AAGvC,yBAAe,SAAS,CAAC,YAAY;AACnC,kBAAM,aAAa,IAAI,IAAI,OAAO;AAClC,kBAAM,WAAW,WAAW,IAAI,OAAO;AACvC,gBAAI,UAAU;AACZ,yBAAW,IAAI,SAAS,EAAE,GAAG,UAAU,SAAS,KAAA,CAAM;YACxD;AACA,mBAAO;UACT,CAAC;AACD,iBAAO;QACT;AACA,eAAO;MACT;AAGA,iBAAW,WAAW,qBAAqB,OAAO;AAChD,YAAI,QAAQ,OAAO,GAAG;AACpB;YACE,GAAG,OAAO,KAAK,IAAI,OAAO,EAAE,OAAO,EAAE;UAAA;AAGvC,yBAAe,SAAS,CAAC,YAAY;AACnC,kBAAM,aAAa,IAAI,IAAI,OAAO;AAClC,uBAAW,IAAI,SAAS;cACtB,SAAS;cACT;cACA;cACA;cACA,SAAS;;YAAA,CACV;AACD,mBAAO;UACT,CAAC;AACD;QACF;MACF;AAIA,qBAAe,SAAS,CAAC,YAAY;AACnC,cAAM,aAAa,IAAI,IAAI,OAAO;AAClC,mBAAW,IAAI,SAAS;UACtB,SAAS;UACT;UACA;UACA;UACA,SAAS;QAAA,CACV;AACD,eAAO;MACT,CAAC;IACH,CAAC;EACH;AAKA,QAAM,0BAA0B,OAC9B,WACkB;AAElB,QAAI,UAAU,UAAU,QAAQ;AAC9B,YAAM,UAAU,OAAO;AAEvB,UAAI,MAAM,QAAQ,OAAO,IAAI,GAAG;AAC9B,cAAM,QAAQ,IAAI,OAAO,KAAK,IAAI,CAAC,SAAS,UAAU,MAAM,OAAO,CAAC,CAAC;MACvE,OAAO;AACL,cAAM,UAAU,OAAO,MAAM,OAAO;MACtC;IACF;EAEF;AAGA,QAAM,kBAAkB,OAAO,WAC3B,OAAO,WAAwC;AAC7C,UAAM,gBAAgB,MAAM,OAAO,SAAU,MAAM;AACnD,UAAM,wBAAwB,aAAa;AAC3C,WAAO;EACT,IACA;AAEJ,QAAM,kBAAkB,OAAO,WAC3B,OAAO,WAAwC;AAC7C,UAAM,gBAAgB,MAAM,OAAO,SAAU,MAAM;AACnD,UAAM,wBAAwB,aAAa;AAC3C,WAAO;EACT,IACA;AAEJ,QAAM,kBAAkB,OAAO,WAC3B,OAAO,WAAwC;AAC7C,UAAM,gBAAgB,MAAM,OAAO,SAAU,MAAM;AACnD,UAAM,wBAAwB,aAAa;AAC3C,WAAO;EACT,IACA;AAGJ,QAAM;IACJ,cAAc;IACd,UAAU;IACV,UAAU;IACV,UAAU;IACV,GAAG;EAAA,IACD;AAEJ,SAAO;IACL,GAAG;IACH,UAAU;IACV;IACA,UAAU;IACV,UAAU;IACV,UAAU;IACV,OAAO;MACL;MACA;IAAA;EACF;AAEJ;AAKA,SAAS,mBACP,cACA,SAsBe;AACf,QAAM;IACJ;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EAAA,IACE;AACJ,QAAM,qBAAqB;AAG3B,QAAM,iBAAiB,IAAI,MAA0B,MAAS;AAM9D,QAAM,kBAAkB,MAA+B;;AAErD,UAAM,SAAS,eAAe,SAAS;AAEvC,WAAO;MACL,YAAU,kBAAa,WAAb,mBAAqB,SAC3B,CAAC,QAAQ,aAAa,OAAO,KAAK,IAClC;IAAA;EAER;AAEA,MAAI;AAEJ,SAAO;IACL,MAAM,CAAC,WAAiD;AACtD,YAAM,EAAE,OAAO,OAAO,QAAQ,WAAW,UAAU,WAAA,IAAe;AAGlE,UAAI,uBAA6C;AACjD,YAAM,mBAAmB,CAAC,gBAAyB;AAEjD,YACE,eACA,aAAa,kBACb,uCAAW,qBACX;AAEA,iCAAuB,UAAU,mBAAA;AACjC,+BAAqB,KAAK,MAAM;AAC9B,sBAAA;UACF,CAAC;QACH,OAAO;AAEL,oBAAA;QACF;MACF;AAGA,YAAM,kBAAkB,IAAI,gBAAA;AAE5B,UAAI,aAAa,QAAQ;AACvB,qBAAa,OAAO;UAClB;UACA,MAAM;AACJ,4BAAgB,MAAA;UAClB;UACA;YACE,MAAM;UAAA;QACR;AAEF,YAAI,aAAa,OAAO,SAAS;AAC/B,0BAAgB,MAAA;QAClB;MACF;AAGA,sBAAgB,OAAO,iBAAiB,SAAS,MAAM;AACrD,uBAAe,SAAS,CAAC,YAAY;AACnC,kBAAQ,QAAQ,CAAC,UAAU;AACzB,yBAAa,MAAM,SAAS;AAC5B,kBAAM,OAAO,IAAI,mBAAA,CAAoB;UACvC,CAAC;AACD,iBAAA,oBAAW,IAAA;QACb,CAAC;MACH,CAAC;AAED,YAAM,SAAS,IAAI,YAAY;QAC7B,GAAG;;QAEH,KAAK,aAAa,cAAc,iBAAiB;;;QAGjD,QACE,aAAa,WAAW,aAAa,cAAc,QAAQ;QAC7D,QAAQ,gBAAgB;QACxB,SAAS,CAAC,gBAAgB;AAMxB,oBAAA;AAEA,cAAI,aAAa,SAAS;AACxB,mBAAO,aAAa,QAAQ,WAAW;UACzC,OAAO;AACL,oBAAQ;cACN,+CAA+C,WAAW,EAAE;;;cAG5D;YAAA;UAEJ;AAEA;QACF;MAAA,CACD;AACD,UAAI,qBAAqB;AACzB,YAAM,WAAA,oBAAe,IAAA;AACrB,YAAM,eAAwC,CAAA;AAC9C,UAAI,sBAAsB;AAI1B,YAAM,yBAAyB,MAC7B,aAAa,iBAAiB,CAAC;AACjC,YAAM,mBAAsC,CAAA;AAK5C,YAAM,mBAAmB,uBAAuB;QAC9C;QACA;QACA;QACA;QACA;QACA;QACA;MAAA,CACD;AAED,0BAAoB,OAAO,UAAU,CAAC,aAAgC;;AACpE,YAAI,cAAc;AAClB,YAAI,iBAAiB;AAErB,mBAAW,WAAW,UAAU;AAE9B,cAAI,gBAAgB,OAAO,GAAG;AAC5B,iCAAqB,SAAS,CAAC,kBAAkB;AAC/C,oBAAM,YAAY,CAAC,GAAG,eAAe,OAAO;AAE5C,kBAAI,UAAU,SAAS,oBAAoB;AACzC,0BAAU,OAAO,GAAG,UAAU,SAAS,kBAAkB;cAC3D;AACA,qBAAO;YACT,CAAC;UACH;AAIA,cAAI,SAAS,OAAO,KAAK,CAAC,uBAAA,GAA0B;AAClD,0BAAQ,QAAQ,UAAhB,mBAAuB,QAAQ,CAAC,SAAS,SAAS,IAAI,IAAI;UAC5D;AAIA,gBAAM,kBAAiC,CAAA;AACvC,yBAAe,MAAM,QAAQ,CAAC,OAAO,YAAY;AAC/C,gBAAI,CAAC,MAAM,SAAS;AAClB,kBAAI;AACF,sBAAM,QAAQ,OAAO;cACvB,SAAS,KAAK;AAEZ,6BAAa,MAAM,SAAS;AAC5B,sBAAM;kBACJ,eAAe,QAAQ,MAAM,IAAI,MAAM,OAAO,GAAG,CAAC;gBAAA;AAEpD,gCAAgB,KAAK,OAAO;AAC5B,sBAAM,qBAAqB,GAAG;cAChC;YACF;UACF,CAAC;AAGD,+BAAqB,eAAe;AAEpC,cAAI,gBAAgB,OAAO,GAAG;AAE5B,kBAAM,SAAS,QAAQ,QAAQ;AAC/B,gBAAI,UAAU,OAAO,WAAW,UAAU;AAExC,6BAAe,SAAS,MAAM,MAAM;YACtC;AAGA,gBAAI,uBAAA,GAA0B;AAC5B,+BAAiB,KAAK,OAAO;YAC/B,OAAO;AAEL,kBAAI,CAAC,oBAAoB;AACvB,sBAAA;AACA,qCAAqB;cACvB;AAEA,oBAAM;gBACJ,MAAM,QAAQ,QAAQ;gBACtB,OAAO,QAAQ;;gBAEf,UAAU;kBACR,GAAG,QAAQ;gBAAA;cACb,CACD;YACH;UACF,WAAW,qBAAqB,OAAO,GAAG;AAExC,gBAAI,CAAC,uBAAA,GAA0B;AAC7B,2BAAa,KAAK,qBAAqB,OAAO,CAAC;YACjD;AACA,6BAAiB;UACnB,WAAWA,mBAAkB,OAAO,GAAG;AACrC,0BAAc;UAChB,WAAW,qBAAqB,OAAO,GAAG;AACxC;cACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;YAAA;AAI7C,gBAAI,CAAC,oBAAoB;AACvB,oBAAA;AACA,mCAAqB;YACvB;AAEA,qBAAA;AAIA,iEAAkB;AAGlB,0BAAc;AACd,6BAAiB;AACjB,kCAAsB;AACtB,6BAAiB,SAAS;UAC5B;QACF;AAEA,YAAI,eAAe,gBAAgB;AAEjC,cAAI,uBAAA,KAA4B,aAAa;AAC3C;cACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE,iDAAiD,iBAAiB,MAAM;YAAA;AAIrH,kBAAA;AAGA,qBAAA;AAGA,uBAAW,eAAe,kBAAkB;AAC1C,kBAAI,gBAAgB,WAAW,GAAG;AAChC,sBAAM;kBACJ,MAAM,YAAY,QAAQ;kBAC1B,OAAO,YAAY;kBACnB,UAAU;oBACR,GAAG,YAAY;kBAAA;gBACjB,CACD;AAGD,oBAAI,SAAS,WAAW,GAAG;AACzB,oCAAY,QAAQ,UAApB,mBAA2B;oBAAQ,CAAC,SAClC,SAAS,IAAI,IAAI;;gBAErB;cACF,WAAW,qBAAqB,WAAW,GAAG;AAE5C,6BAAa,KAAK,qBAAqB,WAAW,CAAC;cACrD;YACF;AAGA,mBAAA;AAIA,6BAAiB,SAAS;AAE1B;cACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;YAAA;UAE/C,OAAO;AAEL,gBAAI,oBAAoB;AACtB,qBAAA;AACA,mCAAqB;YACvB;UACF;AAGA,+BAAqB,SAAS,MAAM,CAAA,CAAE;AAEtC,cAAI,eAAgB,kBAAkB,aAAa,aAAc;AAE/D,6BAAiB,uBAAA,CAAwB;UAC3C;AAGA,cAAI,aAAa;AACf,kCAAsB;UACxB;AAGA,oBAAU,SAAS,CAAC,iBAAiB;AACnC,kBAAM,aAAa,IAAI,IAAU,YAAY;AAC7C,gBAAI,SAAS,OAAO,GAAG;AACrB;gBACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;gBAC3C,MAAM,KAAK,QAAQ;cAAA;YAEvB;AACA,qBAAS,QAAQ,CAAC,SAAS,WAAW,IAAI,IAAI,CAAC;AAC/C,qBAAS,MAAA;AACT,mBAAO;UACT,CAAC;AAGD,wBAAc,SAAS,CAAC,qBAAqB;AAC3C,kBAAM,OAAO,CAAC,GAAG,kBAAkB,GAAG,YAAY;AAClD,yBAAa;cAAQ,CAAC,aACpB;gBACE,GAAG,eAAe,IAAI,YAAY,OAAO,EAAE;gBAC3C;cAAA;YACF;AAEF,yBAAa,SAAS;AACtB,mBAAO;UACT,CAAC;AAGD,uCAAA;QACF;MACF,CAAC;AAID,aAAO;QACL,YAAY,qDAAkB;QAC9B,SAAS,MAAM;AAEb,4BAAA;AAEA,0BAAgB,MAAA;AAEhB,+DAAkB;QACpB;MAAA;IAEJ;;IAEA;EAAA;AAEJ;",
  "names": ["fetch", "_a", "value", "pos", "debug", "_fetchClient", "_a", "_b", "batch", "fetch", "_subscribers", "_error", "_subscribers", "_error", "store", "DebugModule", "isUpToDateMessage"]
}
